{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UVAZt6s-Fu41"
   },
   "source": [
    "# AI6126 ACV Project 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 1038,
     "status": "ok",
     "timestamp": 1601175331072,
     "user": {
      "displayName": "Jia Hui Ong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKvHQmYQfzydylrU8HXZxYxJP3L6kGAQ94P-sS=s64",
      "userId": "05957301376516334331"
     },
     "user_tz": -480
    },
    "id": "jzjCg15BeR43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ai6126-p1-train-v1.4\n",
      "46\n"
     ]
    }
   ],
   "source": [
    "nb_ver = 1.4\n",
    "title = f'ai6126-p1-train-v{nb_ver}'\n",
    "print(title)\n",
    "comments = \"46\"\n",
    "print(comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Versioning & References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4c2s81g4d5PE"
   },
   "source": [
    "### Changelogs\n",
    "+ V0.1 - Setup codes to download and unzip celeba to gDrive\n",
    "+ V0.2 - Added training loop \n",
    "+ V0.3 - Added seeding + save/ load checkpoint\n",
    "+ V0.4 - Added time taken + save output\n",
    "+ V0.5 - Added RandomErasing to transforms\n",
    "+ V0.6 - Added get_criterion (FocalLoss) \n",
    "+ V0.7 - Added FaceAttrMobileNetV2 & FaceAttrResNeXt\n",
    "+ V0.8 - Added Albumentations\n",
    "+ V0.9 - Updated Optimizer (SGD, AdamW works well)\n",
    "+ V0.91 - Added ModelTimer() + Added more augmentations\n",
    "+ V1.0 - Added ReduceLROnPlateau Scheduler\n",
    "+ V1.1 - Updated Augmentations to more closely follow Tricks paper + Added OneCycleLR Scheduler + No bias decay\n",
    "+ V1.2 - Added Early Stopping\n",
    "+ V1.3 - Code Clean\n",
    "+ V1.4 - Added LabelSmoothing to CrossEntropyLoss and FocalLoss\n",
    "+ V1.5 - Added MixedUp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ToDo:\n",
    "+ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "+ [Face Attribute Prediction on CelebA benchmark with PyTorch Implementation](https://github.com/d-li14/face-attribute-prediction)\n",
    "+ [PyTorch Transfer Learning](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html)\n",
    "+ [Albumentations](https://albumentations.ai/)\n",
    "+ [Focal Loss](https://github.com/kornia/kornia/blob/master/kornia/losses/focal.py)\n",
    "+ [Bag of Tricks](https://arxiv.org/abs/1812.01187)\n",
    "+ [Torch ToolBox](https://github.com/PistonY/torch-toolbox)\n",
    "+ [Fastai Course](https://www.youtube.com/watch?v=vnOpEwmtFJ8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install pytorch torchvision cudatoolkit=10.2 -c pytorch\n",
    "# conda install matplotlib\n",
    "# conda install pandas\n",
    "# conda install tqdm\n",
    "# conda install -c conda-forge jupyterlab\n",
    "# conda install -c conda-forge tensorboard\n",
    "# conda install -c conda-forge protobuf # for tensorboard\n",
    "# conda install nb_conda_kernels # auto add kernels\n",
    "\n",
    "# conda install -c conda-forge imgaug\n",
    "# conda install albumentations -c conda-forge\n",
    "# conda install seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UmjjrIheF0u5"
   },
   "source": [
    "## Setup/ Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "executionInfo": {
     "elapsed": 4455,
     "status": "error",
     "timestamp": 1601175336681,
     "user": {
      "displayName": "Jia Hui Ong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKvHQmYQfzydylrU8HXZxYxJP3L6kGAQ94P-sS=s64",
      "userId": "05957301376516334331"
     },
     "user_tz": -480
    },
    "id": "7mTWwwivDNy3",
    "outputId": "9f87be63-e615-42bf-b306-8a2ec7e2458d"
   },
   "outputs": [],
   "source": [
    "# you can choose to mount your Google Drive (optional)\n",
    "import sys, os\n",
    "if 'google.colab' in sys.modules:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    file_name = f'ai6126-project1-colab-v{nb_ver}.ipynb'\n",
    "    print(file_name)\n",
    "    import subprocess\n",
    "    path_to_file = subprocess.check_output('find . -type f -name ' + str(file_name), shell=True).decode(\"utf-8\")\n",
    "    print(path_to_file)\n",
    "    path_to_file = path_to_file.replace(file_name,\"\").replace('\\n',\"\")\n",
    "    os.chdir(path_to_file)\n",
    "    !pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Dataset (JUPYTER ONLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download celeba dataset: False\n"
     ]
    }
   ],
   "source": [
    "import os, glob\n",
    "local_download_path = '../data/celeba/img_align_celeba'\n",
    "download_dataset = True\n",
    "if os.path.exists(local_download_path):\n",
    "    images = glob.glob(local_download_path + '/*.jpg')\n",
    "    if len(images) == 202599:\n",
    "        download_dataset = False\n",
    "print(f\"download celeba dataset: {download_dataset}\")\n",
    "\n",
    "if download_dataset:\n",
    "    # create dataset root and enter it\n",
    "    !mkdir -p data/celeba\n",
    "    %cd data/celeba\n",
    "\n",
    "    # we have prepared a backup of `img_align_celeba.zip` of Celeb-A dataset in the Dropbox\n",
    "    # download it directly, or manually download the original file from Google Drive above\n",
    "    !wget https://www.dropbox.com/s/8kzo40fqx7nodat/img_align_celeba.zip\n",
    "\n",
    "    # unzip the downloaded file\n",
    "    !unzip -qq img_align_celeba.zip\n",
    "    !rm -f img_align_celeba.zip\n",
    "\n",
    "    # change the directory back to the root\n",
    "    %cd ../..\n",
    "    !ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "tEkTpN_qDN5u"
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import shutil\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import copy\n",
    "from datetime import datetime\n",
    "from distutils.dir_util import copy_tree #for recursive filecopying\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import config\n",
    "from celeba_dataset import CelebaDataset\n",
    "import models\n",
    "import losses\n",
    "from utils import Logger, AverageMeter, Bar, ModelTimer, savefig, adjust_learning_rate, accuracy, print_attribute_acc, create_dir_ifne, add_weight_decay, mixup_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "DCjPfxzUDN3Y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.0 True\n",
      "cuda:0\n",
      "disable_tqdm: False\n"
     ]
    }
   ],
   "source": [
    "# check PyTorch version and cuda status\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "\n",
    "# define device\n",
    "device = torch.device(\"cuda:\"+config.gpu_id if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "ISJUPYTER = False\n",
    "if 'ipykernel' in sys.modules:\n",
    "    ISJUPYTER = True\n",
    "    # set the backend of matplotlib to the 'inline' backend\n",
    "    %matplotlib inline\n",
    "    config.disable_tqdm = False\n",
    "    \n",
    "print(f\"disable_tqdm: {config.disable_tqdm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "executionInfo": {
     "elapsed": 4483,
     "status": "ok",
     "timestamp": 1601174828368,
     "user": {
      "displayName": "Jia Hui Ong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKvHQmYQfzydylrU8HXZxYxJP3L6kGAQ94P-sS=s64",
      "userId": "05957301376516334331"
     },
     "user_tz": -480
    },
    "id": "9Te1EuMyDN7-",
    "outputId": "e1a9321b-0c11-476e-dea5-57b3fa33f732"
   },
   "outputs": [],
   "source": [
    "# set random seed for reproducibility\n",
    "def seed_everything(seed=None):\n",
    "    if seed is None:\n",
    "        seed = random.randint(1, 10000) # create random seed\n",
    "        print(f'random seed used: {seed}')\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    if 'torch' in sys.modules:\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "seed_everything(seed=config.manual_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 7867,
     "status": "ok",
     "timestamp": 1601174831763,
     "user": {
      "displayName": "Jia Hui Ong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKvHQmYQfzydylrU8HXZxYxJP3L6kGAQ94P-sS=s64",
      "userId": "05957301376516334331"
     },
     "user_tz": -480
    },
    "id": "UeTJbZQ5b_ea",
    "outputId": "de5f0be8-65fe-4648-e719-ff92f2642235",
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "### Data Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation and testing\n",
    "def load_dataloaders(print_info=True, albu_transforms = True):\n",
    "    if config.evaluate:\n",
    "        phases = ['test']\n",
    "    else:\n",
    "        phases = ['train', 'val']\n",
    "\n",
    "    attribute_names = ['5_o_Clock_Shadow', 'Arched_Eyebrows', 'Attractive', 'Bags_Under_Eyes', 'Bald', \n",
    "                       'Bangs', 'Big_Lips', 'Big_Nose', 'Black_Hair', 'Blond_Hair', 'Blurry', 'Brown_Hair', \n",
    "                       'Bushy_Eyebrows', 'Chubby', 'Double_Chin', 'Eyeglasses', 'Goatee', 'Gray_Hair',\n",
    "                       'Heavy_Makeup', 'High_Cheekbones', 'Male', 'Mouth_Slightly_Open', 'Mustache', \n",
    "                       'Narrow_Eyes', 'No_Beard', 'Oval_Face', 'Pale_Skin', 'Pointy_Nose', 'Receding_Hairline',\n",
    "                       'Rosy_Cheeks', 'Sideburns', 'Smiling', 'Straight_Hair', 'Wavy_Hair', 'Wearing_Earrings', \n",
    "                       'Wearing_Hat', 'Wearing_Lipstick', 'Wearing_Necklace', 'Wearing_Necktie', 'Young']\n",
    "    \n",
    "    attributes_list = {\n",
    "        'train': config.TRAIN_ATTRIBUTE_LIST,\n",
    "        'val': config.VAL_ATTRIBUTE_LIST,\n",
    "        'test': config.TEST_ATTRIBUTE_LIST\n",
    "    }\n",
    "\n",
    "    batch_sizes = {\n",
    "        'train': config.train_batch,\n",
    "        'val': config.test_batch,\n",
    "        'test': config.test_batch\n",
    "    }\n",
    "\n",
    "    if not albu_transforms:\n",
    "        normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                                         std=[0.229, 0.224, 0.225])\n",
    "        data_transforms = {\n",
    "            'train': transforms.Compose([\n",
    "                transforms.CenterCrop(148), #new\n",
    "                transforms.RandomHorizontalFlip(p=0.5),\n",
    "                transforms.RandomRotation(degrees=10), #new\n",
    "                transforms.ToTensor(),\n",
    "                normalize,\n",
    "                transforms.RandomErasing()\n",
    "            ]),\n",
    "            'val': transforms.Compose([\n",
    "                transforms.Resize(178), #new\n",
    "                transforms.CenterCrop(148),\n",
    "                transforms.ToTensor(),\n",
    "                normalize\n",
    "            ]),\n",
    "            'test': transforms.Compose([\n",
    "                transforms.Resize(178), #new\n",
    "                transforms.CenterCrop(148),\n",
    "                transforms.ToTensor(),\n",
    "                normalize\n",
    "            ])\n",
    "        }\n",
    "    else:\n",
    "        normalize_A = A.Normalize(mean=(0.485, 0.456, 0.406), \n",
    "                                  std=(0.229, 0.224, 0.225))\n",
    "        data_transforms = {\n",
    "            'train': A.Compose([\n",
    "                #A.RandomResizedCrop(148, 148), # cuts out too much attributes, use centercrop instead\n",
    "                A.CenterCrop(height=148, width=148),\n",
    "                A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, \n",
    "                                 rotate_limit=15, p=0.5), # AFFACT https://arxiv.org/pdf/1611.06158.pdf\n",
    "                A.HorizontalFlip(p=0.5),\n",
    "                #A.HueSaturationValue(hue_shift_limit=14, sat_shift_limit=14, val_shift_limit=14, p=0.5),\n",
    "                #A.FancyPCA(alpha=0.1, p=0.5), #http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf\n",
    "                A.RandomBrightnessContrast(p=0.5),\n",
    "                A.GaussNoise(var_limit=10.0, p=0.5), \n",
    "                #A.GaussianBlur(p=0.1), # AFFACT https://arxiv.org/pdf/1611.06158.pdf\n",
    "                A.CoarseDropout(max_holes=1, max_height=74, max_width=74, \n",
    "                               min_height=49, min_width=49, fill_value=0, p=0.2), #https://arxiv.org/pdf/1708.04896.pdf\n",
    "                normalize_A,\n",
    "                ToTensorV2(),\n",
    "                \n",
    "            ]),\n",
    "            'val': A.Compose([\n",
    "                #Rescale an image so that minimum side is equal to max_size 178 (shortest edge of Celeba)\n",
    "                A.SmallestMaxSize(max_size=178), \n",
    "                A.CenterCrop(height=148, width=148),\n",
    "                normalize_A,\n",
    "                ToTensorV2(),\n",
    "            ]),\n",
    "            'test': A.Compose([\n",
    "                A.SmallestMaxSize(max_size=178),\n",
    "                A.CenterCrop(height=148, width=148),\n",
    "                normalize_A,\n",
    "                ToTensorV2(),\n",
    "            ])\n",
    "        }\n",
    "\n",
    "    image_datasets = {x: CelebaDataset(config.IMG_DIR, attributes_list[x], \n",
    "                                       data_transforms[x]) \n",
    "                      for x in phases}\n",
    "    dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], \n",
    "                                                  batch_size=batch_sizes[x],\n",
    "                                                  pin_memory=True, shuffle=(x == 'train'), \n",
    "                                                  num_workers=config.dl_workers) \n",
    "                   for x in phases}\n",
    "    if print_info:\n",
    "        dataset_sizes = {x: len(image_datasets[x]) for x in phases}\n",
    "        print(f\"Dataset sizes: {dataset_sizes}\")\n",
    "        \n",
    "    if config.evaluate:\n",
    "        class_names = image_datasets['test'].targets\n",
    "    else:\n",
    "        class_names = image_datasets['train'].targets\n",
    "    print(f\"Class Labels: {len(class_names[0])}\")\n",
    "    assert len(attribute_names) == len(class_names[0])\n",
    "    return dataloaders, attribute_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qtfDq7Z2F6Nh",
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "### Model Architecture Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Models: ['FaceAttrMobileNetV2', 'FaceAttrResNeXt', 'FaceAttrResNet']\n"
     ]
    }
   ],
   "source": [
    "model_names = sorted(name for name in models.__dict__\n",
    "                     if callable(models.__dict__[name])) # and name.islower() and not name.startswith(\"__\"))\n",
    "print(f\"Available Models: {model_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> creating model 'FaceAttrResNet'\n"
     ]
    }
   ],
   "source": [
    "def create_model(arch, layers, device):\n",
    "    print(\"=> creating model '{}'\".format(config.arch))\n",
    "    if arch.startswith('FaceAttrResNet'):\n",
    "        model = models.__dict__[arch](resnet_layers = layers)\n",
    "    elif arch.startswith('FaceAttrResNeXt'):\n",
    "        model = models.__dict__[arch](resnet_layers = layers)\n",
    "    elif arch.startswith('FaceAttrMobileNetV2'):\n",
    "        model = models.__dict__[arch]()\n",
    "    model = model.to(device)\n",
    "    return model\n",
    "\n",
    "model = create_model(config.arch, config.pt_layers, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criterion & Optimizer & Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def get_criterion():\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    if config.criterion == 'CE' and config.label_smoothing:\n",
    "        criterion = losses.LabelSmoothingCrossEntropy(ls=config.label_smoothing).to(device) \n",
    "    elif config.criterion == 'FocalLoss':\n",
    "        criterion = losses.FocalLossLS(alpha=0.25, gamma=3, reduction='mean', ls=config.label_smoothing).to(device) \n",
    "        \n",
    "    if config.mixed_up > 0:\n",
    "        criterion = losses.MixedUp(criterion).to(device) \n",
    "        \n",
    "    return criterion\n",
    "\n",
    "criterion = get_criterion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(model, opt_name=config.optimizer, no_bias_bn_decay=config.no_bias_bn_decay):\n",
    "    weight_decay = config.weight_decay\n",
    "    if no_bias_bn_decay: #bag of tricks paper\n",
    "        parameters = add_weight_decay(model, weight_decay)\n",
    "        weight_decay = 0.\n",
    "    else:\n",
    "        parameters = model.parameters()\n",
    "    \n",
    "    optimizer = None\n",
    "    if opt_name == 'SGD':\n",
    "        optimizer = torch.optim.SGD(parameters, config.lr,\n",
    "                                momentum=config.momentum,\n",
    "                                weight_decay=weight_decay)\n",
    "    elif opt_name == 'Adam':\n",
    "        optimizer = torch.optim.Adam(parameters, config.lr,\n",
    "                            weight_decay=weight_decay)\n",
    "    elif opt_name == 'AdamW':\n",
    "        optimizer = torch.optim.AdamW(parameters, config.lr,\n",
    "                            weight_decay=weight_decay)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scheduler(optimizer, steps_per_epoch, epochs):\n",
    "    scheduler = None # Manual\n",
    "    if config.scheduler == 'ReduceLROnPlateau':\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min',\n",
    "                                                               factor=0.1,\n",
    "                                                               patience=config.patience)\n",
    "    elif config.scheduler == 'OneCycleLR': \n",
    "        scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.1, epochs=epochs,\n",
    "                                                        steps_per_epoch=int(steps_per_epoch), \n",
    "                                                        anneal_strategy='cos') #https://arxiv.org/pdf/1708.07120.pdf\n",
    "    return scheduler    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resume Checkpoint if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_checkpoint(modelname, opt_name, bias_decay=False, ckp_resume=None):\n",
    "    best_prec1 = 0\n",
    "\n",
    "    if ckp_resume and os.path.isfile(ckp_resume): \n",
    "        print(f\"=> formatting model: {ckp_resume}\")\n",
    "        checkpoint = torch.load(ckp_resume)\n",
    "        print(checkpoint['arch'])\n",
    "        try:\n",
    "            total_time = checkpoint['total_time']\n",
    "        except:\n",
    "            total_time = 0\n",
    "        \n",
    "        state = {\n",
    "            'epoch': checkpoint['epoch'],\n",
    "            'arch': modelname,\n",
    "            'state_dict': checkpoint['state_dict'],\n",
    "            'best_prec1': checkpoint['best_prec1'],\n",
    "            'opt_name': opt_name,\n",
    "            'optimizer' : checkpoint['optimizer'],\n",
    "            'lr': checkpoint['lr'],\n",
    "            'total_time': total_time,\n",
    "            'bias_decay': bias_decay\n",
    "        }\n",
    "        torch.save(state, ckp_resume)\n",
    "        \n",
    "    else:\n",
    "        raise\n",
    "        \n",
    "#format_checkpoint('FaceAttrResNeXt_50', 'SGD', True, ckp_resume=config.bestmodel_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resume_checkpoint(device, ckp_logger_fname, ckp_resume=None):\n",
    "    if not ckp_logger_fname:\n",
    "        print(\"[W] Logger path not found.\")\n",
    "        raise\n",
    "\n",
    "    start_epoch = 0\n",
    "    best_prec1 = 0\n",
    "    lr = config.lr\n",
    "    \n",
    "    if ckp_resume == '':\n",
    "        ckp_resume = None\n",
    "    \n",
    "    if ckp_resume and os.path.isfile(ckp_resume): \n",
    "        print(f\"=> resuming checkpoint: {ckp_resume}\")\n",
    "        checkpoint = torch.load(ckp_resume)\n",
    "        \n",
    "        try:\n",
    "            total_time = checkpoint['total_time']\n",
    "            model_timer = ModelTimer(total_time)\n",
    "            print(f\"=> model trained time: {model_timer}\")\n",
    "        except:\n",
    "            print(f\"=> old model\")\n",
    "            model_timer = ModelTimer()\n",
    "        best_prec1 = checkpoint['best_prec1']\n",
    "        print(f\"=> model best val: {best_prec1}\")\n",
    "        \n",
    "        start_epoch = checkpoint['epoch']\n",
    "        print(f\"=> model epoch: {start_epoch}\")\n",
    "        lr = checkpoint['lr']\n",
    "\n",
    "        print(f\"=> resuming model: {checkpoint['arch']}\")\n",
    "        model = create_model(checkpoint['arch'].split('_')[0], \n",
    "                             int(checkpoint['arch'].split('_')[1]), \n",
    "                             device)\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        \n",
    "        print(f\"=> resuming optimizer: {checkpoint['opt_name']}\")\n",
    "        bias_decay = True\n",
    "        if checkpoint['bias_decay']:\n",
    "            bias_decay = checkpoint['bias_decay']\n",
    "            \n",
    "        optimizer = get_optimizer(model, checkpoint['opt_name'], bias_decay)\n",
    "        if optimizer:\n",
    "            optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        logger = Logger(ckp_logger_fname, title=model.name, resume=True)\n",
    "        \n",
    "    else:\n",
    "        print(f\"=> restarting training: {ckp_resume}\")\n",
    "        model_timer = ModelTimer()\n",
    "        model = create_model(config.arch, config.pt_layers, device)\n",
    "        optimizer = get_optimizer(model)\n",
    "        logger = Logger(ckp_logger_fname, title=model.name)\n",
    "        logger.set_names(['Learning Rate', 'Train Loss', 'Valid Loss', 'Train Acc.', 'Valid Acc.'])\n",
    "              \n",
    "    return best_prec1, model_timer, lr, start_epoch, logger, model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_inference_model(device, ckp_resume):\n",
    "    if not (ckp_resume and os.path.isfile(ckp_resume)):\n",
    "        print(\"[W] Checkpoint not found for inference.\")\n",
    "        raise \n",
    "    \n",
    "    print(f\"=> loading checkpoint: {ckp_resume}\")\n",
    "    checkpoint = torch.load(ckp_resume)\n",
    "    try:\n",
    "        total_time = checkpoint['total_time']\n",
    "        model_timer = ModelTimer(total_time)\n",
    "        print(f\"=> model trained time: {model_timer}\")\n",
    "    except:\n",
    "        print(f\"=> old model\")\n",
    "    best_prec1 = checkpoint['best_prec1']\n",
    "    print(f\"=> model best val: {best_prec1}\")\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    print(f\"=> model epoch: {start_epoch}\")\n",
    "\n",
    "    print(f\"=> resuming model: {checkpoint['arch']}\")\n",
    "    model = create_model(checkpoint['arch'].split('_')[0], \n",
    "                         int(checkpoint['arch'].split('_')[1]), \n",
    "                         device)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "              \n",
    "    return best_prec1, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Validate Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer):\n",
    "    bar = Bar('Processing', max=len(train_loader))\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = [AverageMeter() for _ in range(40)]\n",
    "    top1 = [AverageMeter() for _ in range(40)]\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (X, y) in enumerate(tqdm(train_loader, disable=config.disable_tqdm)):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        # Overlapping transfer if pinned memory\n",
    "        X = X.to(device, non_blocking=True)\n",
    "        y = y.to(device, non_blocking=True)\n",
    "        \n",
    "        if config.mixed_up > 0:\n",
    "            X, y, lam = mixup_data(X, y, alpha=config.mixed_up)\n",
    "            criterion.set_lambda(lam)\n",
    "    \n",
    "        # compute output\n",
    "        output = model(X)\n",
    "        # measure accuracy and record loss\n",
    "        loss = []\n",
    "        prec1 = []\n",
    "        for j in range(len(output)): \n",
    "            crit = criterion(output[j], y[:, j])\n",
    "            loss.append(crit)\n",
    "            prec1.append(accuracy(output[j], y[:, j], topk=(1,)))\n",
    "            losses[j].update(loss[j].detach().item(), X.size(0))\n",
    "            top1[j].update(prec1[j][0].item(), X.size(0))\n",
    "            \n",
    "        losses_avg = [losses[k].avg for k in range(len(losses))]\n",
    "        top1_avg = [top1[k].avg for k in range(len(top1))]\n",
    "        loss_avg = sum(losses_avg) / len(losses_avg)\n",
    "        prec1_avg = sum(top1_avg) / len(top1_avg)\n",
    "\n",
    "        # compute gradient and do optimizer step\n",
    "        optimizer.zero_grad()\n",
    "        loss_sum = sum(loss)\n",
    "        loss_sum.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # plot progress\n",
    "        print_line = '({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | Loss: {loss:.4f} | top1: {top1: .4f}'.format(\n",
    "                        batch=i + 1,\n",
    "                        size=len(train_loader),\n",
    "                        data=data_time.avg,\n",
    "                        bt=batch_time.avg,\n",
    "                        total=bar.elapsed_td,\n",
    "                        eta=bar.eta_td,\n",
    "                        loss=loss_avg,\n",
    "                        top1=prec1_avg,\n",
    "                        )\n",
    "        if not config.disable_tqdm and (i+1)% 100 == 0:\n",
    "            print(print_line)\n",
    "        bar.suffix  = print_line\n",
    "        bar.next()\n",
    "    bar.finish()\n",
    "    return (loss_avg, prec1_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion):\n",
    "    bar = Bar('Processing', max=len(val_loader))\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = [AverageMeter() for _ in range(40)]\n",
    "    top1 = [AverageMeter() for _ in range(40)]\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (X, y) in enumerate(tqdm(val_loader, disable=config.disable_tqdm)):\n",
    "            # measure data loading time\n",
    "            data_time.update(time.time() - end)\n",
    "\n",
    "            # Overlapping transfer if pinned memory\n",
    "            X = X.to(device, non_blocking=True)\n",
    "            y = y.to(device, non_blocking=True)\n",
    "\n",
    "            # compute output\n",
    "            output = model(X)\n",
    "            # measure accuracy and record loss\n",
    "            loss = []\n",
    "            prec1 = []\n",
    "            for j in range(len(output)):\n",
    "                loss.append(criterion(output[j], y[:, j]))\n",
    "                prec1.append(accuracy(output[j], y[:, j], topk=(1,)))\n",
    "                \n",
    "                losses[j].update(loss[j].detach().item(), X.size(0))\n",
    "                top1[j].update(prec1[j][0].item(), X.size(0))\n",
    "            losses_avg = [losses[k].avg for k in range(len(losses))]\n",
    "            top1_avg = [top1[k].avg for k in range(len(top1))]\n",
    "            loss_avg = sum(losses_avg) / len(losses_avg)\n",
    "            prec1_avg = sum(top1_avg) / len(top1_avg)\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "            \n",
    "            # plot progress\n",
    "            print_line = '({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | Loss: {loss:.4f} | top1: {top1: .4f}'.format(\n",
    "                            batch=i + 1,\n",
    "                            size=len(val_loader),\n",
    "                            data=data_time.avg,\n",
    "                            bt=batch_time.avg,\n",
    "                            total=bar.elapsed_td,\n",
    "                            eta=bar.eta_td,\n",
    "                            loss=loss_avg,\n",
    "                            top1=prec1_avg,\n",
    "                            )\n",
    "\n",
    "            bar.suffix  = print_line\n",
    "            bar.next()  \n",
    "\n",
    "    if not config.disable_tqdm:\n",
    "        print(print_line)        \n",
    "    bar.finish()\n",
    "    return (loss_avg, prec1_avg, top1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(dataloaders, model, criterion, optimizer, logger, start_epoch, best_prec1, run_name, model_timer):\n",
    "    # visualization\n",
    "    writer = SummaryWriter(os.path.join(config.tensorboard_dir, run_name))\n",
    "    \n",
    "    scheduler = get_scheduler(optimizer, len(dataloaders['train']), config.epochs-start_epoch)\n",
    "    \n",
    "    stagnant_val_loss_ctr = 0\n",
    "    min_val_loss = 1.\n",
    "    \n",
    "    for epoch in range(start_epoch, config.epochs):\n",
    "        model_timer.start_epoch_timer()\n",
    "        if not scheduler:\n",
    "            lr = adjust_learning_rate(optimizer, config.lr_decay, epoch, gamma=config.gamma, step=config.step,\n",
    "                                     total_epochs=config.epochs, turning_point=config.turning_point,\n",
    "                                     schedule=config.schedule)\n",
    "        else:\n",
    "            lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "        print('\\nEpoch: [%d | %d] LR: %.16f' % (epoch + 1, config.epochs, lr))\n",
    "\n",
    "        # train for one epoch\n",
    "        train_loss, train_acc = train(dataloaders['train'], model, criterion, optimizer)\n",
    "\n",
    "        # evaluate on validation set\n",
    "        val_loss, prec1, _ = validate(dataloaders['val'], model, criterion)\n",
    "        \n",
    "        if scheduler:\n",
    "            scheduler.step(None if config.scheduler != 'ReduceLROnPlateau' else val_loss)\n",
    "            \n",
    "        # append logger file\n",
    "        logger.append([lr, train_loss, val_loss, train_acc, prec1])\n",
    "\n",
    "        # tensorboardX\n",
    "        writer.add_scalar('learning rate', lr, epoch + 1)\n",
    "        writer.add_scalars('loss', {'train loss': train_loss, 'validation loss': val_loss}, epoch + 1)\n",
    "        writer.add_scalars('accuracy', {'train accuracy': train_acc, 'validation accuracy': prec1}, epoch + 1)\n",
    "\n",
    "        is_best = prec1 > best_prec1\n",
    "        best_prec1 = max(prec1, best_prec1)\n",
    "        model_timer.stop_epoch_timer()\n",
    "        model.save_ckp({\n",
    "            'epoch': epoch + 1,\n",
    "            'arch': model.name,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'best_prec1': best_prec1,\n",
    "            'opt_name': config.optimizer,\n",
    "            'optimizer' : optimizer.state_dict(),\n",
    "            'lr': lr,\n",
    "            'total_time': model_timer.total_time,\n",
    "            'bias_decay': config.no_bias_bn_decay,\n",
    "        }, is_best, config.checkpoint_fname,config.bestmodel_fname)\n",
    "        \n",
    "        if config.early_stopping:\n",
    "            if val_loss >= min_val_loss:\n",
    "                stagnant_val_loss_ctr += 1\n",
    "                if (epoch+1) > config.es_min and stagnant_val_loss_ctr >= config.es_patience: \n",
    "                    break\n",
    "            else:\n",
    "                stagnant_val_loss_ctr = 0\n",
    "                min_val_loss = val_loss\n",
    "\n",
    "    logger.close()\n",
    "    logger.plot()\n",
    "    save_path = None\n",
    "    if config.train_saveplot:\n",
    "        save_path = os.path.join(config.CHECKPOINT_DIR, \"losses.jpg\")\n",
    "    logger.plot_special(save_path)\n",
    "    savefig(config.train_plotfig)\n",
    "    writer.close()\n",
    "\n",
    "    print('Best accuracy:')\n",
    "    print(best_prec1)\n",
    "    return model_timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_run_name_time(model, criterion, optimizer, comments):\n",
    "    try:\n",
    "        if criterion.name:\n",
    "            p_criterion = criterion.name\n",
    "    except:\n",
    "        p_criterion = 'CE'\n",
    "\n",
    "    p_optimizer = f'{str(optimizer).split(\"(\")[0].strip()}'\n",
    "    p_scheduler = f'lr{config.lr}_wd{config.weight_decay}'\n",
    "    if config.scheduler == 'Manual':\n",
    "        p_scheduler += f'_{config.lr_decay}'\n",
    "        if config.lr_decay == 'step':\n",
    "            p_scheduler += f'_g{config.gamma}_sp{config.step}'\n",
    "        elif config.lr_decay == 'linear2exp':\n",
    "            p_scheduler += f'_g{config.gamma}_tp{config.turning_point}'\n",
    "        elif config.lr_decay == 'schedule':\n",
    "            p_scheduler += f'_g{config.gamma}_sch{config.schedule}'\n",
    "    else: \n",
    "        p_scheduler += f'_{config.scheduler}'\n",
    "    \n",
    "    run_name = f'{model.name}_{config.manual_seed}_s{start_epoch}e{config.epochs}_' \\\n",
    "                + f'tb{config.train_batch}_vb{config.test_batch}_' \\\n",
    "                + f'{p_criterion}_{p_optimizer}_' \\\n",
    "                + f'{comments}_' \\\n",
    "                + f'{p_scheduler}'\n",
    "    \n",
    "    run_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    print(run_name, run_time)\n",
    "    return run_name, run_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "PWCHnDeVD4WT",
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset sizes: {'train': 162770, 'val': 19867}\n",
      "Class Labels: 40\n",
      "=> Training model: True\n",
      "=> restarting training: None\n",
      "=> creating model 'FaceAttrResNet'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/1272 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FaceAttrResNet_50_42_s0e80_tb128_vb128_CELS_SGD_46_lr0.01_wd0.0001_ReduceLROnPlateau 20201018_100345\n",
      "\n",
      "Epoch: [1 | 80] LR: 0.0100000000000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████▏                                                                        | 100/1272 [01:21<13:07,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100/1272) Data: 0.105s | Batch: 0.817s | Total: 0:01:21 | ETA: 0:13:09 | Loss: 0.4040 | top1:  87.1947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████████▍                                                                  | 200/1272 [02:29<12:52,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200/1272) Data: 0.053s | Batch: 0.748s | Total: 0:02:29 | ETA: 0:12:34 | Loss: 0.3817 | top1:  88.4200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██████████████████▋                                                            | 300/1272 [03:39<10:55,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300/1272) Data: 0.036s | Batch: 0.730s | Total: 0:03:39 | ETA: 0:10:57 | Loss: 0.3725 | top1:  88.9299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|████████████████████████▊                                                      | 400/1272 [04:47<10:06,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400/1272) Data: 0.027s | Batch: 0.719s | Total: 0:04:47 | ETA: 0:10:02 | Loss: 0.3665 | top1:  89.2657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███████████████████████████████                                                | 500/1272 [05:56<08:56,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500/1272) Data: 0.022s | Batch: 0.714s | Total: 0:05:56 | ETA: 0:09:00 | Loss: 0.3627 | top1:  89.4893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|█████████████████████████████████████▎                                         | 600/1272 [07:05<07:35,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600/1272) Data: 0.019s | Batch: 0.710s | Total: 0:07:05 | ETA: 0:07:47 | Loss: 0.3597 | top1:  89.6603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|███████████████████████████████████████████▍                                   | 700/1272 [08:14<06:28,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700/1272) Data: 0.016s | Batch: 0.706s | Total: 0:08:14 | ETA: 0:06:30 | Loss: 0.3575 | top1:  89.7968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|█████████████████████████████████████████████████▋                             | 800/1272 [09:22<05:17,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800/1272) Data: 0.014s | Batch: 0.703s | Total: 0:09:22 | ETA: 0:05:19 | Loss: 0.3556 | top1:  89.9097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████████████████████████████████████████████████████▉                       | 900/1272 [10:30<04:10,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900/1272) Data: 0.013s | Batch: 0.700s | Total: 0:10:30 | ETA: 0:04:12 | Loss: 0.3540 | top1:  90.0054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|█████████████████████████████████████████████████████████████▎                | 1000/1272 [11:37<03:02,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000/1272) Data: 0.012s | Batch: 0.697s | Total: 0:11:37 | ETA: 0:03:03 | Loss: 0.3527 | top1:  90.0811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|███████████████████████████████████████████████████████████████████▍          | 1100/1272 [12:44<01:55,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1100/1272) Data: 0.011s | Batch: 0.695s | Total: 0:12:44 | ETA: 0:01:56 | Loss: 0.3515 | top1:  90.1587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████████████████████████████████████████████████████████████████████▌    | 1200/1272 [13:51<00:48,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200/1272) Data: 0.010s | Batch: 0.693s | Total: 0:13:51 | ETA: 0:00:49 | Loss: 0.3504 | top1:  90.2254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1272/1272 [14:42<00:00,  1.44it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 156/156 [00:40<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156/156) Data: 0.047s | Batch: 0.257s | Total: 0:00:40 | ETA: 0:00:01 | Loss: 0.3345 | top1:  91.2311\n",
      "=> saving checkpoint 'checkpoints\\checkpoint.pth.tar'\n",
      "=> saving best model 'checkpoints\\model_best.pth.tar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/1272 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [2 | 80] LR: 0.0100000000000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████▏                                                                        | 100/1272 [01:16<13:04,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100/1272) Data: 0.099s | Batch: 0.763s | Total: 0:01:16 | ETA: 0:13:06 | Loss: 0.3350 | top1:  91.1719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████████▍                                                                  | 200/1272 [02:23<11:57,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200/1272) Data: 0.050s | Batch: 0.716s | Total: 0:02:23 | ETA: 0:11:58 | Loss: 0.3359 | top1:  91.1325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██████████████████▋                                                            | 300/1272 [03:30<10:49,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300/1272) Data: 0.034s | Batch: 0.700s | Total: 0:03:30 | ETA: 0:10:51 | Loss: 0.3357 | top1:  91.1484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|████████████████████████▊                                                      | 400/1272 [04:37<09:43,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400/1272) Data: 0.026s | Batch: 0.693s | Total: 0:04:37 | ETA: 0:09:44 | Loss: 0.3358 | top1:  91.1396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███████████████████████████████                                                | 500/1272 [05:43<08:37,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500/1272) Data: 0.021s | Batch: 0.688s | Total: 0:05:43 | ETA: 0:08:38 | Loss: 0.3356 | top1:  91.1500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|█████████████████████████████████████▎                                         | 600/1272 [06:50<07:29,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600/1272) Data: 0.018s | Batch: 0.685s | Total: 0:06:50 | ETA: 0:07:31 | Loss: 0.3353 | top1:  91.1673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|███████████████████████████████████████████▍                                   | 700/1272 [07:57<06:26,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700/1272) Data: 0.015s | Batch: 0.683s | Total: 0:07:57 | ETA: 0:06:35 | Loss: 0.3352 | top1:  91.1747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|█████████████████████████████████████████████████▋                             | 800/1272 [09:07<05:37,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800/1272) Data: 0.014s | Batch: 0.685s | Total: 0:09:07 | ETA: 0:05:34 | Loss: 0.3350 | top1:  91.1808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████████████████████████████████████████████████████▉                       | 900/1272 [10:16<04:15,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900/1272) Data: 0.012s | Batch: 0.686s | Total: 0:10:16 | ETA: 0:04:15 | Loss: 0.3349 | top1:  91.1889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|█████████████████████████████████████████████████████████████▎                | 1000/1272 [11:27<03:11,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000/1272) Data: 0.011s | Batch: 0.687s | Total: 0:11:27 | ETA: 0:03:13 | Loss: 0.3347 | top1:  91.2026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|███████████████████████████████████████████████████████████████████▍          | 1100/1272 [12:36<01:55,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1100/1272) Data: 0.010s | Batch: 0.687s | Total: 0:12:36 | ETA: 0:01:57 | Loss: 0.3345 | top1:  91.2101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████████████████████████████████████████████████████████████████████▌    | 1200/1272 [13:45<00:49,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200/1272) Data: 0.009s | Batch: 0.688s | Total: 0:13:45 | ETA: 0:00:50 | Loss: 0.3345 | top1:  91.2102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1272/1272 [14:36<00:00,  1.45it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 156/156 [00:42<00:00,  3.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156/156) Data: 0.051s | Batch: 0.271s | Total: 0:00:42 | ETA: 0:00:01 | Loss: 0.3263 | top1:  91.6928\n",
      "=> saving checkpoint 'checkpoints\\checkpoint.pth.tar'\n",
      "=> saving best model 'checkpoints\\model_best.pth.tar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/1272 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [3 | 80] LR: 0.0100000000000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████▏                                                                        | 100/1272 [01:17<13:13,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100/1272) Data: 0.103s | Batch: 0.775s | Total: 0:01:17 | ETA: 0:13:16 | Loss: 0.3302 | top1:  91.5027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████████▍                                                                  | 200/1272 [02:25<12:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200/1272) Data: 0.052s | Batch: 0.728s | Total: 0:02:25 | ETA: 0:12:06 | Loss: 0.3308 | top1:  91.4607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██████████████████▋                                                            | 300/1272 [03:35<11:09,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300/1272) Data: 0.035s | Batch: 0.718s | Total: 0:03:35 | ETA: 0:11:07 | Loss: 0.3307 | top1:  91.4473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|████████████████████████▊                                                      | 400/1272 [04:43<10:04,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400/1272) Data: 0.027s | Batch: 0.708s | Total: 0:04:43 | ETA: 0:09:51 | Loss: 0.3307 | top1:  91.4323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███████████████████████████████                                                | 500/1272 [05:52<08:47,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500/1272) Data: 0.022s | Batch: 0.705s | Total: 0:05:52 | ETA: 0:08:52 | Loss: 0.3306 | top1:  91.4476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|█████████████████████████████████████▎                                         | 600/1272 [07:00<07:30,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600/1272) Data: 0.018s | Batch: 0.700s | Total: 0:07:00 | ETA: 0:07:31 | Loss: 0.3306 | top1:  91.4455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|███████████████████████████████████████████▍                                   | 700/1272 [08:08<06:33,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700/1272) Data: 0.016s | Batch: 0.698s | Total: 0:08:08 | ETA: 0:06:39 | Loss: 0.3305 | top1:  91.4597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|█████████████████████████████████████████████████▋                             | 800/1272 [09:17<05:17,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800/1272) Data: 0.014s | Batch: 0.697s | Total: 0:09:17 | ETA: 0:05:18 | Loss: 0.3304 | top1:  91.4666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████████████████████████████████████████████████████▉                       | 900/1272 [10:28<04:14,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900/1272) Data: 0.013s | Batch: 0.698s | Total: 0:10:28 | ETA: 0:04:19 | Loss: 0.3303 | top1:  91.4719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|█████████████████████████████████████████████████████████████▎                | 1000/1272 [11:37<03:04,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000/1272) Data: 0.012s | Batch: 0.698s | Total: 0:11:37 | ETA: 0:03:06 | Loss: 0.3303 | top1:  91.4705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|███████████████████████████████████████████████████████████████████▍          | 1100/1272 [12:46<01:55,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1100/1272) Data: 0.011s | Batch: 0.697s | Total: 0:12:46 | ETA: 0:01:57 | Loss: 0.3302 | top1:  91.4728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████████████████████████████████████████████████████████████████████▌    | 1200/1272 [13:54<00:49,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200/1272) Data: 0.010s | Batch: 0.695s | Total: 0:13:54 | ETA: 0:00:50 | Loss: 0.3303 | top1:  91.4688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1272/1272 [14:44<00:00,  1.44it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 156/156 [00:41<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156/156) Data: 0.045s | Batch: 0.262s | Total: 0:00:40 | ETA: 0:00:01 | Loss: 0.3301 | top1:  91.4215\n",
      "=> saving checkpoint 'checkpoints\\checkpoint.pth.tar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/1272 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [4 | 80] LR: 0.0100000000000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████▏                                                                        | 100/1272 [01:18<13:07,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100/1272) Data: 0.100s | Batch: 0.784s | Total: 0:01:18 | ETA: 0:13:20 | Loss: 0.3270 | top1:  91.6424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████████▍                                                                  | 200/1272 [02:26<12:06,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200/1272) Data: 0.051s | Batch: 0.731s | Total: 0:02:26 | ETA: 0:12:23 | Loss: 0.3273 | top1:  91.6506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██████████████████▋                                                            | 300/1272 [03:33<10:48,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300/1272) Data: 0.034s | Batch: 0.711s | Total: 0:03:33 | ETA: 0:10:54 | Loss: 0.3274 | top1:  91.6419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|████████████████████████▊                                                      | 400/1272 [04:40<09:43,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400/1272) Data: 0.026s | Batch: 0.701s | Total: 0:04:40 | ETA: 0:09:44 | Loss: 0.3273 | top1:  91.6468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███████████████████████████████                                                | 500/1272 [05:47<08:35,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500/1272) Data: 0.021s | Batch: 0.694s | Total: 0:05:47 | ETA: 0:08:36 | Loss: 0.3272 | top1:  91.6544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|█████████████████████████████████████▎                                         | 600/1272 [06:53<07:28,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600/1272) Data: 0.018s | Batch: 0.690s | Total: 0:06:53 | ETA: 0:07:30 | Loss: 0.3273 | top1:  91.6459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|███████████████████████████████████████████▍                                   | 700/1272 [08:00<06:21,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700/1272) Data: 0.015s | Batch: 0.687s | Total: 0:08:00 | ETA: 0:06:22 | Loss: 0.3273 | top1:  91.6401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|█████████████████████████████████████████████████▋                             | 800/1272 [09:07<05:15,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800/1272) Data: 0.014s | Batch: 0.684s | Total: 0:09:07 | ETA: 0:05:16 | Loss: 0.3275 | top1:  91.6303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████████████████████████████████████████████████████▉                       | 900/1272 [10:14<04:08,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900/1272) Data: 0.012s | Batch: 0.682s | Total: 0:10:14 | ETA: 0:04:10 | Loss: 0.3274 | top1:  91.6355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|█████████████████████████████████████████████████████████████▎                | 1000/1272 [11:20<03:01,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000/1272) Data: 0.011s | Batch: 0.681s | Total: 0:11:20 | ETA: 0:03:03 | Loss: 0.3274 | top1:  91.6396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|███████████████████████████████████████████████████████████████████▍          | 1100/1272 [12:27<01:54,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1100/1272) Data: 0.010s | Batch: 0.680s | Total: 0:12:27 | ETA: 0:01:56 | Loss: 0.3274 | top1:  91.6381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████████████████████████████████████████████████████████████████████▌    | 1200/1272 [13:34<00:47,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200/1272) Data: 0.009s | Batch: 0.679s | Total: 0:13:34 | ETA: 0:00:49 | Loss: 0.3273 | top1:  91.6460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1272/1272 [14:23<00:00,  1.47it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 156/156 [00:39<00:00,  3.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156/156) Data: 0.045s | Batch: 0.251s | Total: 0:00:39 | ETA: 0:00:01 | Loss: 0.3254 | top1:  91.7808\n",
      "=> saving checkpoint 'checkpoints\\checkpoint.pth.tar'\n",
      "=> saving best model 'checkpoints\\model_best.pth.tar'\n",
      "\n",
      "Epoch: [5 | 80] LR: 0.0100000000000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████▏                                                                        | 100/1272 [01:15<13:01,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100/1272) Data: 0.095s | Batch: 0.758s | Total: 0:01:15 | ETA: 0:13:04 | Loss: 0.3255 | top1:  91.7619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████████▍                                                                  | 200/1272 [02:22<11:56,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200/1272) Data: 0.048s | Batch: 0.713s | Total: 0:02:22 | ETA: 0:11:58 | Loss: 0.3253 | top1:  91.7666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██████████████████▋                                                            | 300/1272 [03:29<10:48,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300/1272) Data: 0.033s | Batch: 0.698s | Total: 0:03:29 | ETA: 0:10:50 | Loss: 0.3253 | top1:  91.7669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|████████████████████████▊                                                      | 400/1272 [04:36<09:41,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400/1272) Data: 0.025s | Batch: 0.691s | Total: 0:04:36 | ETA: 0:09:44 | Loss: 0.3252 | top1:  91.7761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███████████████████████████████                                                | 500/1272 [05:43<09:15,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500/1272) Data: 0.020s | Batch: 0.688s | Total: 0:05:43 | ETA: 0:09:11 | Loss: 0.3252 | top1:  91.7689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|█████████████████████████████████████▎                                         | 600/1272 [06:52<07:48,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600/1272) Data: 0.017s | Batch: 0.688s | Total: 0:06:52 | ETA: 0:07:49 | Loss: 0.3252 | top1:  91.7704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|███████████████████████████████████████████▍                                   | 700/1272 [08:01<06:37,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700/1272) Data: 0.015s | Batch: 0.688s | Total: 0:08:01 | ETA: 0:06:36 | Loss: 0.3251 | top1:  91.7687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|█████████████████████████████████████████████████▋                             | 800/1272 [09:10<05:18,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800/1272) Data: 0.013s | Batch: 0.688s | Total: 0:09:10 | ETA: 0:05:19 | Loss: 0.3251 | top1:  91.7720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████████████████████████████████████████████████████▉                       | 900/1272 [10:18<04:15,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900/1272) Data: 0.012s | Batch: 0.687s | Total: 0:10:18 | ETA: 0:04:12 | Loss: 0.3252 | top1:  91.7685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|█████████████████████████████████████████████████████████████▎                | 1000/1272 [11:26<03:04,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000/1272) Data: 0.011s | Batch: 0.687s | Total: 0:11:26 | ETA: 0:03:11 | Loss: 0.3252 | top1:  91.7630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|███████████████████████████████████████████████████████████████████▍          | 1100/1272 [12:34<01:56,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1100/1272) Data: 0.010s | Batch: 0.686s | Total: 0:12:34 | ETA: 0:01:58 | Loss: 0.3251 | top1:  91.7705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████████████████████████████████████████████████████████████████████▌    | 1200/1272 [13:44<00:48,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200/1272) Data: 0.009s | Batch: 0.687s | Total: 0:13:44 | ETA: 0:00:50 | Loss: 0.3251 | top1:  91.7748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1272/1272 [14:35<00:00,  1.45it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 156/156 [00:44<00:00,  3.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156/156) Data: 0.066s | Batch: 0.286s | Total: 0:00:44 | ETA: 0:00:01 | Loss: 0.3260 | top1:  91.7360\n",
      "=> saving checkpoint 'checkpoints\\checkpoint.pth.tar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/1272 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [6 | 80] LR: 0.0100000000000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████▏                                                                        | 100/1272 [01:18<13:13,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100/1272) Data: 0.107s | Batch: 0.790s | Total: 0:01:18 | ETA: 0:13:17 | Loss: 0.3232 | top1:  91.9305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████████▍                                                                  | 200/1272 [02:28<11:57,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200/1272) Data: 0.054s | Batch: 0.740s | Total: 0:02:28 | ETA: 0:12:01 | Loss: 0.3227 | top1:  91.9482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██████████████████▋                                                            | 300/1272 [03:36<11:15,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300/1272) Data: 0.037s | Batch: 0.722s | Total: 0:03:36 | ETA: 0:11:13 | Loss: 0.3227 | top1:  91.9293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|████████████████████████▊                                                      | 400/1272 [04:44<10:05,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400/1272) Data: 0.028s | Batch: 0.712s | Total: 0:04:44 | ETA: 0:10:06 | Loss: 0.3229 | top1:  91.9107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███████████████████████████████                                                | 500/1272 [05:54<08:36,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500/1272) Data: 0.023s | Batch: 0.709s | Total: 0:05:54 | ETA: 0:08:38 | Loss: 0.3230 | top1:  91.9014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|█████████████████████████████████████▎                                         | 600/1272 [07:04<07:57,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600/1272) Data: 0.019s | Batch: 0.707s | Total: 0:07:04 | ETA: 0:08:09 | Loss: 0.3230 | top1:  91.9029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|███████████████████████████████████████████▍                                   | 700/1272 [08:11<06:22,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700/1272) Data: 0.017s | Batch: 0.703s | Total: 0:08:11 | ETA: 0:06:27 | Loss: 0.3231 | top1:  91.9007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|█████████████████████████████████████████████████▋                             | 800/1272 [09:20<05:33,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800/1272) Data: 0.015s | Batch: 0.700s | Total: 0:09:20 | ETA: 0:05:24 | Loss: 0.3231 | top1:  91.8932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████████████████████████████████████████████████████▉                       | 900/1272 [10:29<04:09,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900/1272) Data: 0.013s | Batch: 0.699s | Total: 0:10:29 | ETA: 0:04:12 | Loss: 0.3233 | top1:  91.8864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|█████████████████████████████████████████████████████████████▎                | 1000/1272 [11:37<03:07,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000/1272) Data: 0.012s | Batch: 0.698s | Total: 0:11:37 | ETA: 0:03:08 | Loss: 0.3233 | top1:  91.8834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|███████████████████████████████████████████████████████████████████▍          | 1100/1272 [12:45<01:57,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1100/1272) Data: 0.011s | Batch: 0.696s | Total: 0:12:45 | ETA: 0:01:59 | Loss: 0.3233 | top1:  91.8811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████████████████████████████████████████████████████████████████████▌    | 1200/1272 [13:54<00:48,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200/1272) Data: 0.010s | Batch: 0.695s | Total: 0:13:54 | ETA: 0:00:50 | Loss: 0.3233 | top1:  91.8777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1272/1272 [14:44<00:00,  1.44it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 156/156 [00:42<00:00,  3.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156/156) Data: 0.052s | Batch: 0.271s | Total: 0:00:42 | ETA: 0:00:01 | Loss: 0.3246 | top1:  91.8390\n",
      "=> saving checkpoint 'checkpoints\\checkpoint.pth.tar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/1272 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving best model 'checkpoints\\model_best.pth.tar'\n",
      "\n",
      "Epoch: [7 | 80] LR: 0.0100000000000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████▏                                                                        | 100/1272 [01:18<13:10,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100/1272) Data: 0.098s | Batch: 0.786s | Total: 0:01:18 | ETA: 0:13:27 | Loss: 0.3206 | top1:  92.0453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████████▍                                                                  | 200/1272 [02:26<12:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200/1272) Data: 0.050s | Batch: 0.735s | Total: 0:02:26 | ETA: 0:12:08 | Loss: 0.3208 | top1:  92.0315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██████████████████▋                                                            | 300/1272 [03:35<11:04,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300/1272) Data: 0.033s | Batch: 0.717s | Total: 0:03:35 | ETA: 0:10:57 | Loss: 0.3210 | top1:  92.0165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|████████████████████████▊                                                      | 400/1272 [04:43<10:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400/1272) Data: 0.025s | Batch: 0.708s | Total: 0:04:43 | ETA: 0:09:48 | Loss: 0.3212 | top1:  92.0094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███████████████████████████████                                                | 500/1272 [05:51<08:55,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500/1272) Data: 0.021s | Batch: 0.703s | Total: 0:05:51 | ETA: 0:08:47 | Loss: 0.3211 | top1:  92.0105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|█████████████████████████████████████▎                                         | 600/1272 [06:59<07:31,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600/1272) Data: 0.017s | Batch: 0.700s | Total: 0:06:59 | ETA: 0:07:32 | Loss: 0.3211 | top1:  92.0161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|███████████████████████████████████████████▍                                   | 700/1272 [08:08<06:38,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700/1272) Data: 0.015s | Batch: 0.698s | Total: 0:08:08 | ETA: 0:06:39 | Loss: 0.3214 | top1:  92.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|█████████████████████████████████████████████████▋                             | 800/1272 [09:16<05:36,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800/1272) Data: 0.013s | Batch: 0.696s | Total: 0:09:16 | ETA: 0:05:34 | Loss: 0.3215 | top1:  91.9924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████████████████████████████████████████████████████▉                       | 900/1272 [10:25<04:12,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900/1272) Data: 0.012s | Batch: 0.695s | Total: 0:10:25 | ETA: 0:04:15 | Loss: 0.3215 | top1:  91.9938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|█████████████████████████████████████████████████████████████▎                | 1000/1272 [11:33<03:07,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000/1272) Data: 0.011s | Batch: 0.694s | Total: 0:11:33 | ETA: 0:03:12 | Loss: 0.3215 | top1:  92.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|███████████████████████████████████████████████████████████████████▍          | 1100/1272 [12:42<01:56,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1100/1272) Data: 0.010s | Batch: 0.693s | Total: 0:12:42 | ETA: 0:01:56 | Loss: 0.3215 | top1:  91.9976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████████████████████████████████████████████████████████████████████▌    | 1200/1272 [13:49<00:48,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200/1272) Data: 0.009s | Batch: 0.692s | Total: 0:13:49 | ETA: 0:00:50 | Loss: 0.3216 | top1:  91.9941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1272/1272 [14:39<00:00,  1.45it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 156/156 [00:41<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156/156) Data: 0.048s | Batch: 0.260s | Total: 0:00:40 | ETA: 0:00:01 | Loss: 0.3244 | top1:  91.7613\n",
      "=> saving checkpoint 'checkpoints\\checkpoint.pth.tar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/1272 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [8 | 80] LR: 0.0100000000000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████▏                                                                        | 100/1272 [01:17<13:13,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100/1272) Data: 0.095s | Batch: 0.772s | Total: 0:01:17 | ETA: 0:13:14 | Loss: 0.3198 | top1:  92.1063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████████▍                                                                  | 200/1272 [02:26<11:57,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200/1272) Data: 0.048s | Batch: 0.730s | Total: 0:02:26 | ETA: 0:11:59 | Loss: 0.3199 | top1:  92.1009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██████████████████▋                                                            | 300/1272 [03:34<10:55,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300/1272) Data: 0.033s | Batch: 0.716s | Total: 0:03:34 | ETA: 0:10:56 | Loss: 0.3200 | top1:  92.0967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|████████████████████████▊                                                      | 400/1272 [04:43<09:54,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400/1272) Data: 0.025s | Batch: 0.710s | Total: 0:04:43 | ETA: 0:09:57 | Loss: 0.3202 | top1:  92.0719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███████████████████████████████                                                | 500/1272 [05:53<08:42,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500/1272) Data: 0.020s | Batch: 0.707s | Total: 0:05:53 | ETA: 0:09:02 | Loss: 0.3203 | top1:  92.0647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|█████████████████████████████████████▎                                         | 600/1272 [07:03<07:41,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600/1272) Data: 0.017s | Batch: 0.705s | Total: 0:07:03 | ETA: 0:08:07 | Loss: 0.3203 | top1:  92.0674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|███████████████████████████████████████████▍                                   | 700/1272 [08:11<06:27,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700/1272) Data: 0.015s | Batch: 0.703s | Total: 0:08:11 | ETA: 0:06:35 | Loss: 0.3203 | top1:  92.0668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|█████████████████████████████████████████████████▋                             | 800/1272 [09:19<05:15,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800/1272) Data: 0.013s | Batch: 0.700s | Total: 0:09:19 | ETA: 0:05:17 | Loss: 0.3203 | top1:  92.0684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████████████████████████████████████████████████████▉                       | 900/1272 [10:26<04:08,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900/1272) Data: 0.012s | Batch: 0.697s | Total: 0:10:26 | ETA: 0:04:09 | Loss: 0.3204 | top1:  92.0629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|█████████████████████████████████████████████████████████████▎                | 1000/1272 [11:33<03:01,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000/1272) Data: 0.011s | Batch: 0.694s | Total: 0:11:33 | ETA: 0:03:03 | Loss: 0.3204 | top1:  92.0621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|███████████████████████████████████████████████████████████████████▍          | 1100/1272 [12:40<01:54,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1100/1272) Data: 0.010s | Batch: 0.691s | Total: 0:12:40 | ETA: 0:01:56 | Loss: 0.3204 | top1:  92.0573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████████████████████████████████████████████████████████████████████▌    | 1200/1272 [13:46<00:47,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200/1272) Data: 0.009s | Batch: 0.689s | Total: 0:13:46 | ETA: 0:00:49 | Loss: 0.3204 | top1:  92.0610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1272/1272 [14:35<00:00,  1.45it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 156/156 [00:39<00:00,  3.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156/156) Data: 0.045s | Batch: 0.250s | Total: 0:00:39 | ETA: 0:00:01 | Loss: 0.3323 | top1:  91.5234\n",
      "=> saving checkpoint 'checkpoints\\checkpoint.pth.tar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/1272 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [9 | 80] LR: 0.0100000000000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████▏                                                                        | 100/1272 [01:15<12:59,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100/1272) Data: 0.094s | Batch: 0.755s | Total: 0:01:15 | ETA: 0:13:01 | Loss: 0.3170 | top1:  92.3061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████████▍                                                                  | 200/1272 [02:22<11:53,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200/1272) Data: 0.048s | Batch: 0.711s | Total: 0:02:22 | ETA: 0:11:55 | Loss: 0.3174 | top1:  92.2687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██████████████████▋                                                            | 300/1272 [03:28<10:47,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300/1272) Data: 0.032s | Batch: 0.696s | Total: 0:03:28 | ETA: 0:10:49 | Loss: 0.3177 | top1:  92.2486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|████████████████████████▊                                                      | 400/1272 [04:35<09:41,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400/1272) Data: 0.025s | Batch: 0.689s | Total: 0:04:35 | ETA: 0:09:42 | Loss: 0.3181 | top1:  92.2157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███████████████████████████████                                                | 500/1272 [05:42<08:34,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500/1272) Data: 0.020s | Batch: 0.684s | Total: 0:05:42 | ETA: 0:08:36 | Loss: 0.3184 | top1:  92.1960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|█████████████████████████████████████▎                                         | 600/1272 [06:48<07:28,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600/1272) Data: 0.017s | Batch: 0.681s | Total: 0:06:48 | ETA: 0:07:29 | Loss: 0.3185 | top1:  92.1913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|███████████████████████████████████████████▍                                   | 700/1272 [07:55<06:21,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700/1272) Data: 0.015s | Batch: 0.679s | Total: 0:07:55 | ETA: 0:06:22 | Loss: 0.3186 | top1:  92.1795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|█████████████████████████████████████████████████▋                             | 800/1272 [09:02<05:14,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800/1272) Data: 0.013s | Batch: 0.678s | Total: 0:09:02 | ETA: 0:05:15 | Loss: 0.3188 | top1:  92.1672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████████████████████████████████████████████████████▉                       | 900/1272 [10:08<04:07,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900/1272) Data: 0.012s | Batch: 0.676s | Total: 0:10:08 | ETA: 0:04:09 | Loss: 0.3189 | top1:  92.1668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|█████████████████████████████████████████████████████████████▎                | 1000/1272 [11:15<03:01,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000/1272) Data: 0.011s | Batch: 0.675s | Total: 0:11:15 | ETA: 0:03:02 | Loss: 0.3189 | top1:  92.1634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|███████████████████████████████████████████████████████████████████▍          | 1100/1272 [12:21<01:54,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1100/1272) Data: 0.010s | Batch: 0.675s | Total: 0:12:21 | ETA: 0:01:56 | Loss: 0.3190 | top1:  92.1518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████████████████████████████████████████████████████████████████████▌    | 1200/1272 [13:28<00:47,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200/1272) Data: 0.009s | Batch: 0.674s | Total: 0:13:28 | ETA: 0:00:49 | Loss: 0.3190 | top1:  92.1522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1272/1272 [14:17<00:00,  1.48it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 156/156 [00:39<00:00,  3.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156/156) Data: 0.044s | Batch: 0.249s | Total: 0:00:38 | ETA: 0:00:01 | Loss: 0.3260 | top1:  91.7197\n",
      "=> saving checkpoint 'checkpoints\\checkpoint.pth.tar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/1272 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [10 | 80] LR: 0.0100000000000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████▏                                                                        | 100/1272 [01:15<13:02,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100/1272) Data: 0.095s | Batch: 0.757s | Total: 0:01:15 | ETA: 0:13:03 | Loss: 0.3159 | top1:  92.3447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████████▍                                                                  | 200/1272 [02:22<11:55,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200/1272) Data: 0.048s | Batch: 0.712s | Total: 0:02:22 | ETA: 0:11:57 | Loss: 0.3165 | top1:  92.2950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██████████████████▋                                                            | 300/1272 [03:29<10:47,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300/1272) Data: 0.032s | Batch: 0.697s | Total: 0:03:29 | ETA: 0:10:49 | Loss: 0.3169 | top1:  92.2735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|████████████████████████▊                                                      | 400/1272 [04:35<09:42,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400/1272) Data: 0.025s | Batch: 0.689s | Total: 0:04:35 | ETA: 0:09:43 | Loss: 0.3171 | top1:  92.2683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███████████████████████████████                                                | 500/1272 [05:43<08:58,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500/1272) Data: 0.020s | Batch: 0.686s | Total: 0:05:43 | ETA: 0:08:58 | Loss: 0.3171 | top1:  92.2725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|█████████████████████████████████████▎                                         | 600/1272 [06:51<07:36,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600/1272) Data: 0.017s | Batch: 0.686s | Total: 0:06:51 | ETA: 0:07:33 | Loss: 0.3173 | top1:  92.2611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|███████████████████████████████████████████▍                                   | 700/1272 [08:01<06:46,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700/1272) Data: 0.015s | Batch: 0.687s | Total: 0:08:01 | ETA: 0:06:51 | Loss: 0.3174 | top1:  92.2562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|█████████████████████████████████████████████████▋                             | 800/1272 [09:08<05:19,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800/1272) Data: 0.013s | Batch: 0.686s | Total: 0:09:08 | ETA: 0:05:22 | Loss: 0.3174 | top1:  92.2460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████████████████████████████████████████████████████▉                       | 900/1272 [10:17<04:14,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900/1272) Data: 0.012s | Batch: 0.686s | Total: 0:10:17 | ETA: 0:04:13 | Loss: 0.3175 | top1:  92.2415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|█████████████████████████████████████████████████████████████▎                | 1000/1272 [11:26<03:03,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000/1272) Data: 0.011s | Batch: 0.687s | Total: 0:11:26 | ETA: 0:03:05 | Loss: 0.3175 | top1:  92.2396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|███████████████████████████████████████████████████████████████████▍          | 1100/1272 [12:36<02:02,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1100/1272) Data: 0.010s | Batch: 0.687s | Total: 0:12:36 | ETA: 0:02:03 | Loss: 0.3176 | top1:  92.2371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████████████████████████████████████████████████████████████████████▌    | 1200/1272 [13:45<00:48,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200/1272) Data: 0.009s | Batch: 0.688s | Total: 0:13:45 | ETA: 0:00:51 | Loss: 0.3177 | top1:  92.2340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1272/1272 [14:36<00:00,  1.45it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 156/156 [00:40<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156/156) Data: 0.046s | Batch: 0.259s | Total: 0:00:40 | ETA: 0:00:01 | Loss: 0.3265 | top1:  91.6168\n",
      "=> saving checkpoint 'checkpoints\\checkpoint.pth.tar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/1272 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [11 | 80] LR: 0.0100000000000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████▏                                                                        | 100/1272 [01:19<13:02,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100/1272) Data: 0.098s | Batch: 0.797s | Total: 0:01:19 | ETA: 0:13:04 | Loss: 0.3158 | top1:  92.3668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████████▍                                                                  | 200/1272 [02:27<12:09,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200/1272) Data: 0.050s | Batch: 0.738s | Total: 0:02:27 | ETA: 0:12:31 | Loss: 0.3157 | top1:  92.3650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██████████████████▋                                                            | 300/1272 [03:34<10:48,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300/1272) Data: 0.034s | Batch: 0.715s | Total: 0:03:34 | ETA: 0:10:50 | Loss: 0.3161 | top1:  92.3441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|████████████████████████▊                                                      | 400/1272 [04:41<09:40,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400/1272) Data: 0.026s | Batch: 0.703s | Total: 0:04:41 | ETA: 0:09:42 | Loss: 0.3164 | top1:  92.3160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███████████████████████████████                                                | 500/1272 [05:47<08:34,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500/1272) Data: 0.021s | Batch: 0.696s | Total: 0:05:47 | ETA: 0:08:36 | Loss: 0.3164 | top1:  92.3176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|█████████████████████████████████████▎                                         | 600/1272 [06:54<07:27,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600/1272) Data: 0.017s | Batch: 0.691s | Total: 0:06:54 | ETA: 0:07:30 | Loss: 0.3165 | top1:  92.3081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|███████████████████████████████████████████▍                                   | 700/1272 [08:01<06:21,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700/1272) Data: 0.015s | Batch: 0.687s | Total: 0:08:01 | ETA: 0:06:23 | Loss: 0.3165 | top1:  92.3093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|█████████████████████████████████████████████████▋                             | 800/1272 [09:09<05:25,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800/1272) Data: 0.013s | Batch: 0.687s | Total: 0:09:09 | ETA: 0:05:24 | Loss: 0.3165 | top1:  92.3124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████████████████████████████████████████████████████▉                       | 900/1272 [10:18<04:12,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900/1272) Data: 0.012s | Batch: 0.687s | Total: 0:10:18 | ETA: 0:04:12 | Loss: 0.3165 | top1:  92.3074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|█████████████████████████████████████████████████████████████▎                | 1000/1272 [11:28<03:16,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000/1272) Data: 0.011s | Batch: 0.688s | Total: 0:11:28 | ETA: 0:03:19 | Loss: 0.3166 | top1:  92.3042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|█████████████████████████████████████████████████████████████▉                | 1011/1272 [11:35<02:58,  1.46it/s]"
     ]
    }
   ],
   "source": [
    "# config.epoch = 1\n",
    "#model = create_model(device)\n",
    "dataloaders, attribute_names = load_dataloaders()\n",
    "criterion = get_criterion()\n",
    "#optimizer = get_optimizer(model)\n",
    "\n",
    "print(f\"=> Training model: {not config.evaluate}\")\n",
    "if config.evaluate:\n",
    "    best_prec1, model = load_inference_model(device, config.bestmodel_fname) # checkpoint_fname bestmodel_fname\n",
    "    test_loss, prec1, top1 = validate(dataloaders['test'], model, criterion)\n",
    "    print(f\"=> Best test accuracy: {prec1}, Model val acc: {best_prec1}\")\n",
    "    attr_acc = print_attribute_acc(top1, attribute_names)\n",
    "else:\n",
    "    best_prec1, model_timer, lr, start_epoch, logger, model, optimizer = resume_checkpoint(device, config.ckp_logger_fname, config.ckp_resume)\n",
    "    run_name, run_time = get_run_name_time(model, criterion, optimizer, comments)\n",
    "    mtimer = trainer(dataloaders, model, criterion, optimizer, logger, start_epoch, best_prec1, run_name, model_timer)\n",
    "    print(f\"=> Model trained time: {mtimer}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not config.evaluate:\n",
    "    config.evaluate = True\n",
    "    #model = create_model(device)\n",
    "    dataloaders, attribute_names = load_dataloaders()\n",
    "    criterion = get_criterion()\n",
    "    #optimizer = get_optimizer(model)\n",
    "    \n",
    "    best_prec1, model = load_inference_model(device, config.bestmodel_fname) # checkpoint_fname bestmodel_fname\n",
    "    #best_prec1, mtimer, _, _, logger, = resume_checkpoint(model, optimizer, config.ckp_logger_fname, config.checkpoint_fname)\n",
    "    test_loss, prec1, top1 = validate(dataloaders['test'], model, criterion)\n",
    "    print(f\"=> Best test accuracy: {prec1}, Model val acc: {best_prec1}\")\n",
    "    attr_acc = print_attribute_acc(top1, attribute_names)\n",
    "    if config.test_preds_fname:\n",
    "        json.dump(attr_acc, open(config.test_preds_fname,'w'))\n",
    "#     best_prec1, mtimer, _, _, _, = resume_checkpoint(model, optimizer, config.ckp_logger_fname, config.bestmodel_fname)# config.bestmodel_fname  config.checkpoint_fname\n",
    "#     #print(model)\n",
    "#     test_loss, prec1, top1 = validate(dataloaders['test'], model, criterion)\n",
    "#     print(f\"=> Best test accuracy: {prec1}, Model val acc: {best_prec1}\")\n",
    "#     print_attribute_acc(top1, attribute_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save & Backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ISJUPYTER:\n",
    "    # Wait for notebook to save\n",
    "    %autosave 1\n",
    "    time.sleep(150)\n",
    "    %autosave 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backup_everything(run_time, run_name, title, backup_nb=ISJUPYTER):\n",
    "    # backup checkpoints\n",
    "    print(f\"=> backing up checkpoints... \")\n",
    "    run_dir = os.path.join(config.BACKUP_DIR, run_name, run_time)\n",
    "    create_dir_ifne(run_dir)\n",
    "    fromDirectory = config.CHECKPOINT_DIR\n",
    "    toDirectory = run_dir\n",
    "    copy_tree(fromDirectory, toDirectory)\n",
    "    \n",
    "    if backup_nb:\n",
    "        print(f\"=> backing up notebook... \")\n",
    "        # backup notebook html\n",
    "        nb_name = title + '.ipynb'\n",
    "        html_name = title + '.html'\n",
    "        save_name = os.path.join(run_dir, html_name)\n",
    "        !jupyter nbconvert --to html $nb_name\n",
    "        shutil.move(html_name, save_name)\n",
    "    \n",
    "backup_everything(run_time, run_name, title, backup_nb=ISJUPYTER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.auto_hibernate and False:\n",
    "    os.system('shutdown -h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOYWQroywTLOsSvW/4lPmBg",
   "collapsed_sections": [],
   "name": "ai6126-project1-colab-v0.1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
