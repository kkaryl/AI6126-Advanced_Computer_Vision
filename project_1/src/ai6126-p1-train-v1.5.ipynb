{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UVAZt6s-Fu41"
   },
   "source": [
    "# AI6126 ACV Project 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1038,
     "status": "ok",
     "timestamp": 1601175331072,
     "user": {
      "displayName": "Jia Hui Ong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKvHQmYQfzydylrU8HXZxYxJP3L6kGAQ94P-sS=s64",
      "userId": "05957301376516334331"
     },
     "user_tz": -480
    },
    "id": "jzjCg15BeR43"
   },
   "outputs": [],
   "source": [
    "nb_ver = 1.5\n",
    "title = f'ai6126-p1-train-v{nb_ver}'\n",
    "print(title)\n",
    "comments = \"54\"\n",
    "print(comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Versioning & References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4c2s81g4d5PE"
   },
   "source": [
    "### Changelogs\n",
    "+ V0.1 - Setup codes to download and unzip celeba to gDrive\n",
    "+ V0.2 - Added training loop \n",
    "+ V0.3 - Added seeding + save/ load checkpoint\n",
    "+ V0.4 - Added time taken + save output\n",
    "+ V0.5 - Added RandomErasing to transforms\n",
    "+ V0.6 - Added get_criterion (FocalLoss) \n",
    "+ V0.7 - Added FaceAttrMobileNetV2 & FaceAttrResNeXt\n",
    "+ V0.8 - Added Albumentations\n",
    "+ V0.9 - Updated Optimizer (SGD, AdamW works well)\n",
    "+ V0.91 - Added ModelTimer() + Added more augmentations\n",
    "+ V1.0 - Added ReduceLROnPlateau Scheduler\n",
    "+ V1.1 - Updated Augmentations to more closely follow Tricks paper + Added OneCycleLR Scheduler + No bias decay\n",
    "+ V1.2 - Added Early Stopping\n",
    "+ V1.3 - Code Clean\n",
    "+ V1.4 - Added LabelSmoothing to CrossEntropyLoss and FocalLoss\n",
    "+ V1.5 - Added MixedUp + CosineWarmUpLR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ToDo:\n",
    "+ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "+ [Face Attribute Prediction on CelebA benchmark with PyTorch Implementation](https://github.com/d-li14/face-attribute-prediction)\n",
    "+ [PyTorch Transfer Learning](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html)\n",
    "+ [Albumentations](https://albumentations.ai/)\n",
    "+ [Focal Loss](https://github.com/kornia/kornia/blob/master/kornia/losses/focal.py)\n",
    "+ [Bag of Tricks](https://arxiv.org/abs/1812.01187)\n",
    "+ [Torch ToolBox](https://github.com/PistonY/torch-toolbox)\n",
    "+ [Fastai Course](https://www.youtube.com/watch?v=vnOpEwmtFJ8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install pytorch torchvision cudatoolkit=10.2 -c pytorch\n",
    "# conda install matplotlib\n",
    "# conda install pandas\n",
    "# conda install tqdm\n",
    "# conda install -c conda-forge jupyterlab\n",
    "# conda install -c conda-forge tensorboard\n",
    "# conda install -c conda-forge protobuf # for tensorboard\n",
    "# conda install nb_conda_kernels # auto add kernels\n",
    "\n",
    "# conda install -c conda-forge imgaug\n",
    "# conda install albumentations -c conda-forge\n",
    "# conda install seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UmjjrIheF0u5"
   },
   "source": [
    "## Setup/ Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "executionInfo": {
     "elapsed": 4455,
     "status": "error",
     "timestamp": 1601175336681,
     "user": {
      "displayName": "Jia Hui Ong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKvHQmYQfzydylrU8HXZxYxJP3L6kGAQ94P-sS=s64",
      "userId": "05957301376516334331"
     },
     "user_tz": -480
    },
    "id": "7mTWwwivDNy3",
    "outputId": "9f87be63-e615-42bf-b306-8a2ec7e2458d"
   },
   "outputs": [],
   "source": [
    "# you can choose to mount your Google Drive (optional)\n",
    "import sys, os\n",
    "if 'google.colab' in sys.modules:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    file_name = f'ai6126-project1-colab-v{nb_ver}.ipynb'\n",
    "    print(file_name)\n",
    "    import subprocess\n",
    "    path_to_file = subprocess.check_output('find . -type f -name ' + str(file_name), shell=True).decode(\"utf-8\")\n",
    "    print(path_to_file)\n",
    "    path_to_file = path_to_file.replace(file_name,\"\").replace('\\n',\"\")\n",
    "    os.chdir(path_to_file)\n",
    "    !pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Dataset (JUPYTER ONLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download celeba dataset: False\n"
     ]
    }
   ],
   "source": [
    "import os, glob\n",
    "local_download_path = '../data/celeba/img_align_celeba'\n",
    "download_dataset = True\n",
    "if os.path.exists(local_download_path):\n",
    "    images = glob.glob(local_download_path + '/*.jpg')\n",
    "    if len(images) == 202599:\n",
    "        download_dataset = False\n",
    "print(f\"download celeba dataset: {download_dataset}\")\n",
    "\n",
    "if download_dataset:\n",
    "    # create dataset root and enter it\n",
    "    !mkdir -p data/celeba\n",
    "    %cd data/celeba\n",
    "\n",
    "    # we have prepared a backup of `img_align_celeba.zip` of Celeb-A dataset in the Dropbox\n",
    "    # download it directly, or manually download the original file from Google Drive above\n",
    "    !wget https://www.dropbox.com/s/8kzo40fqx7nodat/img_align_celeba.zip\n",
    "\n",
    "    # unzip the downloaded file\n",
    "    !unzip -qq img_align_celeba.zip\n",
    "    !rm -f img_align_celeba.zip\n",
    "\n",
    "    # change the directory back to the root\n",
    "    %cd ../..\n",
    "    !ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "tEkTpN_qDN5u"
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import shutil\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import copy\n",
    "from datetime import datetime\n",
    "from distutils.dir_util import copy_tree #for recursive filecopying\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import config\n",
    "from celeba_dataset import CelebaDataset\n",
    "import models\n",
    "import losses\n",
    "import schedulers\n",
    "from utils import Logger, AverageMeter, Bar, ModelTimer, savefig, adjust_learning_rate, accuracy, print_attribute_acc, create_dir_ifne, add_weight_decay, mixup_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "DCjPfxzUDN3Y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.0 True\n",
      "cuda:0\n",
      "disable_tqdm: False\n"
     ]
    }
   ],
   "source": [
    "# check PyTorch version and cuda status\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "\n",
    "# define device\n",
    "device = torch.device(\"cuda:\"+config.gpu_id if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "ISJUPYTER = False\n",
    "if 'ipykernel' in sys.modules:\n",
    "    ISJUPYTER = True\n",
    "    # set the backend of matplotlib to the 'inline' backend\n",
    "    %matplotlib inline\n",
    "    config.disable_tqdm = False\n",
    "    \n",
    "print(f\"disable_tqdm: {config.disable_tqdm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "executionInfo": {
     "elapsed": 4483,
     "status": "ok",
     "timestamp": 1601174828368,
     "user": {
      "displayName": "Jia Hui Ong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKvHQmYQfzydylrU8HXZxYxJP3L6kGAQ94P-sS=s64",
      "userId": "05957301376516334331"
     },
     "user_tz": -480
    },
    "id": "9Te1EuMyDN7-",
    "outputId": "e1a9321b-0c11-476e-dea5-57b3fa33f732"
   },
   "outputs": [],
   "source": [
    "# set random seed for reproducibility\n",
    "def seed_everything(seed=None):\n",
    "    if seed is None:\n",
    "        seed = random.randint(1, 10000) # create random seed\n",
    "        print(f'random seed used: {seed}')\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    if 'torch' in sys.modules:\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "seed_everything(seed=config.manual_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 7867,
     "status": "ok",
     "timestamp": 1601174831763,
     "user": {
      "displayName": "Jia Hui Ong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKvHQmYQfzydylrU8HXZxYxJP3L6kGAQ94P-sS=s64",
      "userId": "05957301376516334331"
     },
     "user_tz": -480
    },
    "id": "UeTJbZQ5b_ea",
    "outputId": "de5f0be8-65fe-4648-e719-ff92f2642235",
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "### Data Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation and testing\n",
    "def load_dataloaders(print_info=True, albu_transforms = True):\n",
    "    if config.evaluate:\n",
    "        phases = ['test']\n",
    "    else:\n",
    "        phases = ['train', 'val']\n",
    "\n",
    "    attribute_names = ['5_o_Clock_Shadow', 'Arched_Eyebrows', 'Attractive', 'Bags_Under_Eyes', 'Bald', \n",
    "                       'Bangs', 'Big_Lips', 'Big_Nose', 'Black_Hair', 'Blond_Hair', 'Blurry', 'Brown_Hair', \n",
    "                       'Bushy_Eyebrows', 'Chubby', 'Double_Chin', 'Eyeglasses', 'Goatee', 'Gray_Hair',\n",
    "                       'Heavy_Makeup', 'High_Cheekbones', 'Male', 'Mouth_Slightly_Open', 'Mustache', \n",
    "                       'Narrow_Eyes', 'No_Beard', 'Oval_Face', 'Pale_Skin', 'Pointy_Nose', 'Receding_Hairline',\n",
    "                       'Rosy_Cheeks', 'Sideburns', 'Smiling', 'Straight_Hair', 'Wavy_Hair', 'Wearing_Earrings', \n",
    "                       'Wearing_Hat', 'Wearing_Lipstick', 'Wearing_Necklace', 'Wearing_Necktie', 'Young']\n",
    "    \n",
    "    attributes_list = {\n",
    "        'train': config.TRAIN_ATTRIBUTE_LIST,\n",
    "        'val': config.VAL_ATTRIBUTE_LIST,\n",
    "        'test': config.TEST_ATTRIBUTE_LIST\n",
    "    }\n",
    "\n",
    "    batch_sizes = {\n",
    "        'train': config.train_batch,\n",
    "        'val': config.test_batch,\n",
    "        'test': config.test_batch\n",
    "    }\n",
    "\n",
    "    if not albu_transforms:\n",
    "        normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                                         std=[0.229, 0.224, 0.225])\n",
    "        data_transforms = {\n",
    "            'train': transforms.Compose([\n",
    "                transforms.CenterCrop((198, 158)), #new\n",
    "                transforms.RandomHorizontalFlip(p=0.5),\n",
    "                #transforms.RandomRotation(degrees=10), #new\n",
    "                transforms.ToTensor(),\n",
    "                normalize,\n",
    "            ]),\n",
    "            'val': transforms.Compose([\n",
    "                transforms.CenterCrop((198, 158)), #new\n",
    "                transforms.ToTensor(),\n",
    "                normalize\n",
    "            ]),\n",
    "            'test': transforms.Compose([\n",
    "                transforms.CenterCrop((198, 158)), #new\n",
    "                transforms.ToTensor(),\n",
    "                normalize\n",
    "            ])\n",
    "        }\n",
    "    else:\n",
    "        normalize_A = A.Normalize(mean=(0.485, 0.456, 0.406), \n",
    "                                  std=(0.229, 0.224, 0.225))\n",
    "        data_transforms = {\n",
    "            'train': A.Compose([\n",
    "                #A.RandomResizedCrop(148, 148), # cuts out too much attributes, use centercrop instead\n",
    "                A.CenterCrop(height=198, width=158),\n",
    "                A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, \n",
    "                                 rotate_limit=15, p=0.5), # AFFACT https://arxiv.org/pdf/1611.06158.pdf\n",
    "                A.HorizontalFlip(p=0.5),\n",
    "                #A.HueSaturationValue(hue_shift_limit=14, sat_shift_limit=14, val_shift_limit=14, p=0.5),\n",
    "                #A.FancyPCA(alpha=0.1, p=0.5), #http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf\n",
    "                #A.RandomBrightnessContrast(p=0.5),\n",
    "                #A.GaussNoise(var_limit=10.0, p=0.5), \n",
    "                #A.GaussianBlur(p=0.1), # AFFACT https://arxiv.org/pdf/1611.06158.pdf\n",
    "                #A.CoarseDropout(max_holes=1, max_height=74, max_width=74, \n",
    "                #               min_height=49, min_width=49, fill_value=0, p=0.2), #https://arxiv.org/pdf/1708.04896.pdf\n",
    "                normalize_A,\n",
    "                ToTensorV2(),\n",
    "                \n",
    "            ]),\n",
    "            'val': A.Compose([\n",
    "                #Rescale an image so that minimum side is equal to max_size 178 (shortest edge of Celeba)\n",
    "                #A.SmallestMaxSize(max_size=178), \n",
    "                A.CenterCrop(height=198, width=158),\n",
    "                normalize_A,\n",
    "                ToTensorV2(),\n",
    "            ]),\n",
    "            'test': A.Compose([\n",
    "                #A.SmallestMaxSize(max_size=178),\n",
    "                A.CenterCrop(height=198, width=158),\n",
    "                normalize_A,\n",
    "                ToTensorV2(),\n",
    "            ])\n",
    "        }\n",
    "\n",
    "    image_datasets = {x: CelebaDataset(config.IMG_DIR, attributes_list[x], \n",
    "                                       data_transforms[x], albu=albu_transforms) \n",
    "                      for x in phases}\n",
    "    dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], \n",
    "                                                  batch_size=batch_sizes[x],\n",
    "                                                  pin_memory=True, shuffle=(x == 'train'), \n",
    "                                                  num_workers=config.dl_workers) \n",
    "                   for x in phases}\n",
    "    if print_info:\n",
    "        dataset_sizes = {x: len(image_datasets[x]) for x in phases}\n",
    "        print(f\"Dataset sizes: {dataset_sizes}\")\n",
    "        \n",
    "    if config.evaluate:\n",
    "        class_names = image_datasets['test'].targets\n",
    "    else:\n",
    "        class_names = image_datasets['train'].targets\n",
    "    print(f\"Class Labels: {len(class_names[0])}\")\n",
    "    assert len(attribute_names) == len(class_names[0])\n",
    "    return dataloaders, attribute_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qtfDq7Z2F6Nh",
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "### Model Architecture Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Models: ['FaceAttrMobileNetV2', 'FaceAttrResNeXt', 'FaceAttrResNet']\n"
     ]
    }
   ],
   "source": [
    "model_names = sorted(name for name in models.__dict__\n",
    "                     if callable(models.__dict__[name])) # and name.islower() and not name.startswith(\"__\"))\n",
    "print(f\"Available Models: {model_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> creating model 'FaceAttrMobileNetV2'\n"
     ]
    }
   ],
   "source": [
    "def create_model(arch, layers, device):\n",
    "    print(\"=> creating model '{}'\".format(config.arch))\n",
    "    if arch.startswith('FaceAttrResNet'):\n",
    "        model = models.__dict__[arch](resnet_layers = layers)\n",
    "    elif arch.startswith('FaceAttrResNeXt'):\n",
    "        model = models.__dict__[arch](resnet_layers = layers)\n",
    "    elif arch.startswith('FaceAttrMobileNetV2'):\n",
    "        model = models.__dict__[arch]()\n",
    "    model = model.to(device)\n",
    "    return model\n",
    "\n",
    "model = create_model(config.arch, config.pt_layers, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criterion & Optimizer & Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def get_criterion():\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    if config.criterion == 'CE' and config.label_smoothing:\n",
    "        criterion = losses.LabelSmoothingCrossEntropy(ls=config.label_smoothing).to(device) \n",
    "    elif config.criterion == 'FocalLoss':\n",
    "        criterion = losses.FocalLossLS(alpha=0.25, gamma=3, reduction='mean', ls=config.label_smoothing).to(device) \n",
    "        \n",
    "    if config.mixed_up > 0:\n",
    "        criterion = losses.MixedUp(criterion).to(device) \n",
    "        \n",
    "    return criterion\n",
    "\n",
    "criterion = get_criterion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(model, opt_name=config.optimizer, no_bias_bn_decay=config.no_bias_bn_decay):\n",
    "    weight_decay = config.weight_decay\n",
    "    if no_bias_bn_decay: #bag of tricks paper\n",
    "        parameters = add_weight_decay(model, weight_decay)\n",
    "        weight_decay = 0.\n",
    "    else:\n",
    "        parameters = model.parameters()\n",
    "    \n",
    "    optimizer = None\n",
    "    if opt_name == 'SGD':\n",
    "        optimizer = torch.optim.SGD(parameters, config.lr,\n",
    "                                momentum=config.momentum,\n",
    "                                weight_decay=weight_decay)\n",
    "    elif opt_name == 'Adam':\n",
    "        optimizer = torch.optim.Adam(parameters, config.lr,\n",
    "                            weight_decay=weight_decay)\n",
    "    elif opt_name == 'AdamW':\n",
    "        optimizer = torch.optim.AdamW(parameters, config.lr,\n",
    "                            weight_decay=weight_decay)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scheduler(optimizer, steps_per_epoch, epochs):\n",
    "    scheduler = None # Manual\n",
    "    if config.scheduler == 'ReduceLROnPlateau':\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min',\n",
    "                                                               factor=0.1,\n",
    "                                                               patience=config.patience)\n",
    "    elif config.scheduler == 'OneCycleLR': \n",
    "        scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.1, epochs=epochs,\n",
    "                                                        steps_per_epoch=int(steps_per_epoch), \n",
    "                                                        anneal_strategy='cos') #https://arxiv.org/pdf/1708.07120.pdf\n",
    "    elif config.scheduler == 'CosineWarmupLR':\n",
    "        scheduler = schedulers.CosineWarmupLR(optimizer, batches=int(steps_per_epoch),\n",
    "                                              epochs=epochs, base_lr=0.001, target_lr=0, warmup_epochs=5,\n",
    "                                              warmup_lr = 0.01)\n",
    "    \n",
    "    return scheduler    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resume Checkpoint if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_checkpoint(modelname, opt_name, bias_decay=False, ckp_resume=None):\n",
    "    best_prec1 = 0\n",
    "\n",
    "    if ckp_resume and os.path.isfile(ckp_resume): \n",
    "        print(f\"=> formatting model: {ckp_resume}\")\n",
    "        checkpoint = torch.load(ckp_resume)\n",
    "        print(checkpoint['arch'])\n",
    "        try:\n",
    "            total_time = checkpoint['total_time']\n",
    "        except:\n",
    "            total_time = 0\n",
    "        \n",
    "        state = {\n",
    "            'epoch': checkpoint['epoch'],\n",
    "            'arch': modelname,\n",
    "            'state_dict': checkpoint['state_dict'],\n",
    "            'best_prec1': checkpoint['best_prec1'],\n",
    "            'opt_name': opt_name,\n",
    "            'optimizer' : checkpoint['optimizer'],\n",
    "            'lr': checkpoint['lr'],\n",
    "            'total_time': total_time,\n",
    "            'bias_decay': bias_decay\n",
    "        }\n",
    "        torch.save(state, ckp_resume)\n",
    "        \n",
    "    else:\n",
    "        raise\n",
    "        \n",
    "#format_checkpoint('FaceAttrResNeXt_50', 'SGD', True, ckp_resume=config.bestmodel_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resume_checkpoint(device, ckp_logger_fname, ckp_resume=None):\n",
    "    if not ckp_logger_fname:\n",
    "        print(\"[W] Logger path not found.\")\n",
    "        raise\n",
    "\n",
    "    start_epoch = 0\n",
    "    best_prec1 = 0\n",
    "    lr = config.lr\n",
    "    \n",
    "    if ckp_resume == '':\n",
    "        ckp_resume = None\n",
    "    \n",
    "    if ckp_resume and os.path.isfile(ckp_resume): \n",
    "        print(f\"=> resuming checkpoint: {ckp_resume}\")\n",
    "        checkpoint = torch.load(ckp_resume)\n",
    "        \n",
    "        try:\n",
    "            total_time = checkpoint['total_time']\n",
    "            model_timer = ModelTimer(total_time)\n",
    "            print(f\"=> model trained time: {model_timer}\")\n",
    "        except:\n",
    "            print(f\"=> old model\")\n",
    "            model_timer = ModelTimer()\n",
    "        best_prec1 = checkpoint['best_prec1']\n",
    "        print(f\"=> model best val: {best_prec1}\")\n",
    "        \n",
    "        start_epoch = checkpoint['epoch']\n",
    "        print(f\"=> model epoch: {start_epoch}\")\n",
    "        lr = checkpoint['lr']\n",
    "\n",
    "        print(f\"=> resuming model: {checkpoint['arch']}\")\n",
    "        model = create_model(checkpoint['arch'].split('_')[0], \n",
    "                             int(checkpoint['arch'].split('_')[1]), \n",
    "                             device)\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        \n",
    "        print(f\"=> resuming optimizer: {checkpoint['opt_name']}\")\n",
    "        bias_decay = True\n",
    "        if checkpoint['bias_decay']:\n",
    "            bias_decay = checkpoint['bias_decay']\n",
    "            \n",
    "        optimizer = get_optimizer(model, checkpoint['opt_name'], bias_decay)\n",
    "        if optimizer:\n",
    "            optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        logger = Logger(ckp_logger_fname, title=model.name, resume=True)\n",
    "        \n",
    "    else:\n",
    "        print(f\"=> restarting training: {ckp_resume}\")\n",
    "        model_timer = ModelTimer()\n",
    "        model = create_model(config.arch, config.pt_layers, device)\n",
    "        optimizer = get_optimizer(model)\n",
    "        logger = Logger(ckp_logger_fname, title=model.name)\n",
    "        logger.set_names(['Learning Rate', 'Train Loss', 'Valid Loss', 'Train Acc.', 'Valid Acc.'])\n",
    "              \n",
    "    return best_prec1, model_timer, lr, start_epoch, logger, model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_inference_model(device, ckp_resume):\n",
    "    if not (ckp_resume and os.path.isfile(ckp_resume)):\n",
    "        print(\"[W] Checkpoint not found for inference.\")\n",
    "        raise \n",
    "    \n",
    "    print(f\"=> loading checkpoint: {ckp_resume}\")\n",
    "    checkpoint = torch.load(ckp_resume)\n",
    "    try:\n",
    "        total_time = checkpoint['total_time']\n",
    "        model_timer = ModelTimer(total_time)\n",
    "        print(f\"=> model trained time: {model_timer}\")\n",
    "    except:\n",
    "        print(f\"=> old model\")\n",
    "    best_prec1 = checkpoint['best_prec1']\n",
    "    print(f\"=> model best val: {best_prec1}\")\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    print(f\"=> model epoch: {start_epoch}\")\n",
    "\n",
    "    print(f\"=> resuming model: {checkpoint['arch']}\")\n",
    "    model = create_model(checkpoint['arch'].split('_')[0], \n",
    "                         int(checkpoint['arch'].split('_')[1]), \n",
    "                         device)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "              \n",
    "    return best_prec1, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Validate Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer):\n",
    "    bar = Bar('Processing', max=len(train_loader))\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = [AverageMeter() for _ in range(40)]\n",
    "    top1 = [AverageMeter() for _ in range(40)]\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (X, y) in enumerate(tqdm(train_loader, disable=config.disable_tqdm)):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        # Overlapping transfer if pinned memory\n",
    "        X = X.to(device, non_blocking=True)\n",
    "        y = y.to(device, non_blocking=True)\n",
    "        if config.mixed_up > 0:\n",
    "            X, y, lam = mixup_data(X, y, alpha=config.mixed_up)\n",
    "            criterion.set_lambda(lam)\n",
    "    \n",
    "        # compute output\n",
    "        output = model(X)\n",
    "        # measure accuracy and record loss\n",
    "        loss = []\n",
    "        prec1 = []\n",
    "        for j in range(len(output)): \n",
    "            if config.mixed_up > 0:\n",
    "                labels = y[:, :, j]\n",
    "                actual_labels = y[0, :, j] * lam + y[1, :, j] * (1-lam)\n",
    "            else:\n",
    "                labels = y[:, j]\n",
    "                actual_labels = y[:, j]\n",
    "            crit = criterion(output[j], labels)\n",
    "            loss.append(crit)\n",
    "            prec1.append(accuracy(output[j], actual_labels, topk=(1,), mixedup=config.mixed_up))\n",
    "            losses[j].update(loss[j].detach().item(), X.size(0))\n",
    "            top1[j].update(prec1[j][0].item(), X.size(0))\n",
    "            \n",
    "        losses_avg = [losses[k].avg for k in range(len(losses))]\n",
    "        top1_avg = [top1[k].avg for k in range(len(top1))]\n",
    "        loss_avg = sum(losses_avg) / len(losses_avg)\n",
    "        prec1_avg = sum(top1_avg) / len(top1_avg)\n",
    "\n",
    "        # compute gradient and do optimizer step\n",
    "        optimizer.zero_grad()\n",
    "        loss_sum = sum(loss)\n",
    "        loss_sum.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # plot progress\n",
    "        print_line = '({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | Loss: {loss:.4f} | top1: {top1: .4f}'.format(\n",
    "                        batch=i + 1,\n",
    "                        size=len(train_loader),\n",
    "                        data=data_time.avg,\n",
    "                        bt=batch_time.avg,\n",
    "                        total=bar.elapsed_td,\n",
    "                        eta=bar.eta_td,\n",
    "                        loss=loss_avg,\n",
    "                        top1=prec1_avg,\n",
    "                        )\n",
    "        if not config.disable_tqdm and (i+1)% 100 == 0:\n",
    "            print(print_line)\n",
    "        bar.suffix  = print_line\n",
    "        bar.next()\n",
    "    bar.finish()\n",
    "    return (loss_avg, prec1_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion):\n",
    "    bar = Bar('Processing', max=len(val_loader))\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = [AverageMeter() for _ in range(40)]\n",
    "    top1 = [AverageMeter() for _ in range(40)]\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (X, y) in enumerate(tqdm(val_loader, disable=config.disable_tqdm)):\n",
    "            # measure data loading time\n",
    "            data_time.update(time.time() - end)\n",
    "\n",
    "            # Overlapping transfer if pinned memory\n",
    "            X = X.to(device, non_blocking=True)\n",
    "            y = y.to(device, non_blocking=True)\n",
    "            \n",
    "            # compute output\n",
    "            output = model(X)\n",
    "            # measure accuracy and record loss\n",
    "            loss = []\n",
    "            prec1 = []\n",
    "            for j in range(len(output)):\n",
    "                if config.mixed_up > 0:\n",
    "                    loss.append(criterion(output[j], y[:, j], mixed=False))\n",
    "                else:\n",
    "                    loss.append(criterion(output[j], y[:, j]))\n",
    "                prec1.append(accuracy(output[j], y[:, j], topk=(1,)))\n",
    "                \n",
    "                losses[j].update(loss[j].detach().item(), X.size(0))\n",
    "                top1[j].update(prec1[j][0].item(), X.size(0))\n",
    "            losses_avg = [losses[k].avg for k in range(len(losses))]\n",
    "            top1_avg = [top1[k].avg for k in range(len(top1))]\n",
    "            loss_avg = sum(losses_avg) / len(losses_avg)\n",
    "            prec1_avg = sum(top1_avg) / len(top1_avg)\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "            \n",
    "            # plot progress\n",
    "            print_line = '({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | Loss: {loss:.4f} | top1: {top1: .4f}'.format(\n",
    "                            batch=i + 1,\n",
    "                            size=len(val_loader),\n",
    "                            data=data_time.avg,\n",
    "                            bt=batch_time.avg,\n",
    "                            total=bar.elapsed_td,\n",
    "                            eta=bar.eta_td,\n",
    "                            loss=loss_avg,\n",
    "                            top1=prec1_avg,\n",
    "                            )\n",
    "\n",
    "            bar.suffix  = print_line\n",
    "            bar.next()  \n",
    "\n",
    "    if not config.disable_tqdm:\n",
    "        print(print_line)        \n",
    "    bar.finish()\n",
    "    return (loss_avg, prec1_avg, top1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(dataloaders, model, criterion, optimizer, logger, start_epoch, best_prec1, run_name, model_timer):\n",
    "    # visualization\n",
    "    writer = SummaryWriter(os.path.join(config.tensorboard_dir, run_name))\n",
    "    \n",
    "    scheduler = get_scheduler(optimizer, len(dataloaders['train']), config.epochs-start_epoch)\n",
    "    \n",
    "    stagnant_val_loss_ctr = 0\n",
    "    min_val_loss = 1.\n",
    "    \n",
    "    for epoch in range(start_epoch, config.epochs):\n",
    "        model_timer.start_epoch_timer()\n",
    "        if not scheduler:\n",
    "            lr = adjust_learning_rate(optimizer, config.lr_decay, epoch, gamma=config.gamma, step=config.step,\n",
    "                                     total_epochs=config.epochs, turning_point=config.turning_point,\n",
    "                                     schedule=config.schedule)\n",
    "        else:\n",
    "            lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "        print('\\nEpoch: [%d | %d] LR: %.16f' % (epoch + 1, config.epochs, lr))\n",
    "\n",
    "        # train for one epoch\n",
    "        train_loss, train_acc = train(dataloaders['train'], model, criterion, optimizer)\n",
    "\n",
    "        # evaluate on validation set\n",
    "        val_loss, prec1, _ = validate(dataloaders['val'], model, criterion)\n",
    "        \n",
    "        if scheduler:\n",
    "            scheduler.step(None if config.scheduler != 'ReduceLROnPlateau' else val_loss)\n",
    "            \n",
    "        # append logger file\n",
    "        logger.append([lr, train_loss, val_loss, train_acc, prec1])\n",
    "\n",
    "        # tensorboardX\n",
    "        writer.add_scalar('learning rate', lr, epoch + 1)\n",
    "        writer.add_scalars('loss', {'train loss': train_loss, 'validation loss': val_loss}, epoch + 1)\n",
    "        writer.add_scalars('accuracy', {'train accuracy': train_acc, 'validation accuracy': prec1}, epoch + 1)\n",
    "\n",
    "        is_best = prec1 > best_prec1\n",
    "        best_prec1 = max(prec1, best_prec1)\n",
    "        model_timer.stop_epoch_timer()\n",
    "        model.save_ckp({\n",
    "            'epoch': epoch + 1,\n",
    "            'arch': model.name,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'best_prec1': best_prec1,\n",
    "            'opt_name': config.optimizer,\n",
    "            'optimizer' : optimizer.state_dict(),\n",
    "            'lr': lr,\n",
    "            'total_time': model_timer.total_time,\n",
    "            'bias_decay': config.no_bias_bn_decay,\n",
    "        }, is_best, config.checkpoint_fname,config.bestmodel_fname)\n",
    "        \n",
    "        if config.early_stopping:\n",
    "            if is_best:\n",
    "                stagnant_val_loss_ctr = 0\n",
    "                min_val_loss = val_loss\n",
    "            elif val_loss >= min_val_loss:\n",
    "                stagnant_val_loss_ctr += 1\n",
    "                if (epoch+1) > config.es_min and stagnant_val_loss_ctr >= config.es_patience: \n",
    "                    break\n",
    "            else:\n",
    "                stagnant_val_loss_ctr = 0\n",
    "                min_val_loss = val_loss\n",
    "\n",
    "    print(\"training completed\")\n",
    "    logger.close()\n",
    "    writer.close()\n",
    "    try:\n",
    "        print(\"normal plot\")\n",
    "        logger.plot()\n",
    "        save_path = None\n",
    "        if config.train_saveplot:\n",
    "            save_path = os.path.join(config.CHECKPOINT_DIR, \"losses.jpg\")\n",
    "        print(\"special plot\")\n",
    "        logger.plot_special(save_path)\n",
    "        savefig(config.train_plotfig)\n",
    "    except:\n",
    "        print(\"error plotting\")\n",
    "    \n",
    "    print('Best accuracy:')\n",
    "    print(best_prec1)\n",
    "    return model_timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_run_name_time(model, criterion, optimizer, comments, start_epoch=0):\n",
    "    try:\n",
    "        if criterion.name:\n",
    "            p_criterion = criterion.name\n",
    "    except:\n",
    "        p_criterion = 'CE'\n",
    "\n",
    "    p_optimizer = f'{str(optimizer).split(\"(\")[0].strip()}'\n",
    "    p_scheduler = f'lr{config.lr}_wd{config.weight_decay}'\n",
    "    if config.scheduler == 'Manual':\n",
    "        p_scheduler += f'_{config.lr_decay}'\n",
    "        if config.lr_decay == 'step':\n",
    "            p_scheduler += f'_g{config.gamma}_sp{config.step}'\n",
    "        elif config.lr_decay == 'linear2exp':\n",
    "            p_scheduler += f'_g{config.gamma}_tp{config.turning_point}'\n",
    "        elif config.lr_decay == 'schedule':\n",
    "            p_scheduler += f'_g{config.gamma}_sch{config.schedule}'\n",
    "    else: \n",
    "        p_scheduler += f'_{config.scheduler}'\n",
    "    \n",
    "    run_name = f'{model.name}_{config.manual_seed}_s{start_epoch}e{config.epochs}_' \\\n",
    "                + f'tb{config.train_batch}_vb{config.test_batch}_' \\\n",
    "                + f'{p_criterion}_{p_optimizer}_' \\\n",
    "                + f'{comments}_' \\\n",
    "                + f'{p_scheduler}'\n",
    "    \n",
    "    run_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    print(run_name, run_time)\n",
    "    return run_name, run_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PWCHnDeVD4WT",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset sizes: {'train': 162770, 'val': 19867}\n",
      "Class Labels: 40\n",
      "=> Training model: True\n",
      "=> restarting training: None\n",
      "=> creating model 'FaceAttrMobileNetV2'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/1628 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FaceAttrMobileNetV2_50_42_s0e80_tb100_vb100_MU_FLLS_SGD_54_lr0.01_wd0.0001_ReduceLROnPlateau 20201020_095753\n",
      "\n",
      "Epoch: [1 | 80] LR: 0.0100000000000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████▊                                                                          | 100/1628 [01:10<14:20,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100/1628) Data: 0.077s | Batch: 0.704s | Total: 0:01:10 | ETA: 0:15:19 | Loss: 0.0137 | top1:  83.2445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████████▋                                                                     | 200/1628 [02:05<13:17,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200/1628) Data: 0.039s | Batch: 0.625s | Total: 0:02:05 | ETA: 0:12:55 | Loss: 0.0124 | top1:  85.0322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|██████████████▌                                                                | 300/1628 [02:59<12:20,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300/1628) Data: 0.026s | Batch: 0.598s | Total: 0:02:59 | ETA: 0:12:22 | Loss: 0.0116 | top1:  86.0123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████████████▍                                                           | 400/1628 [03:52<10:46,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400/1628) Data: 0.020s | Batch: 0.581s | Total: 0:03:52 | ETA: 0:10:50 | Loss: 0.0112 | top1:  86.5718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|████████████████████████▎                                                      | 500/1628 [04:45<10:31,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500/1628) Data: 0.016s | Batch: 0.571s | Total: 0:04:45 | ETA: 0:11:00 | Loss: 0.0109 | top1:  86.9996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|█████████████████████████████                                                  | 600/1628 [05:38<08:49,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600/1628) Data: 0.014s | Batch: 0.564s | Total: 0:05:38 | ETA: 0:08:55 | Loss: 0.0107 | top1:  87.2969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|█████████████████████████████████▉                                             | 700/1628 [06:31<08:34,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700/1628) Data: 0.012s | Batch: 0.559s | Total: 0:06:31 | ETA: 0:08:42 | Loss: 0.0105 | top1:  87.5284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|██████████████████████████████████████▊                                        | 800/1628 [07:25<07:31,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800/1628) Data: 0.010s | Batch: 0.557s | Total: 0:07:25 | ETA: 0:07:25 | Loss: 0.0104 | top1:  87.7040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|███████████████████████████████████████████▋                                   | 900/1628 [08:20<05:49,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900/1628) Data: 0.009s | Batch: 0.556s | Total: 0:08:20 | ETA: 0:05:58 | Loss: 0.0103 | top1:  87.8756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|███████████████████████████████████████████████▉                              | 1000/1628 [09:11<05:06,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000/1628) Data: 0.008s | Batch: 0.551s | Total: 0:09:11 | ETA: 0:05:05 | Loss: 0.0102 | top1:  88.0073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|████████████████████████████████████████████████████▋                         | 1100/1628 [10:02<04:31,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1100/1628) Data: 0.008s | Batch: 0.548s | Total: 0:10:02 | ETA: 0:04:38 | Loss: 0.0101 | top1:  88.1405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|█████████████████████████████████████████████████████████▍                    | 1200/1628 [10:52<03:34,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200/1628) Data: 0.007s | Batch: 0.544s | Total: 0:10:52 | ETA: 0:03:38 | Loss: 0.0100 | top1:  88.2466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████████████████████████████████▎               | 1300/1628 [11:42<02:36,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1300/1628) Data: 0.007s | Batch: 0.540s | Total: 0:11:42 | ETA: 0:02:40 | Loss: 0.0100 | top1:  88.3363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|███████████████████████████████████████████████████████████████████           | 1400/1628 [12:33<01:51,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400/1628) Data: 0.006s | Batch: 0.538s | Total: 0:12:33 | ETA: 0:01:55 | Loss: 0.0099 | top1:  88.4512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|███████████████████████████████████████████████████████████████████████▊      | 1500/1628 [13:23<01:06,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500/1628) Data: 0.006s | Batch: 0.536s | Total: 0:13:23 | ETA: 0:01:06 | Loss: 0.0098 | top1:  88.5077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|████████████████████████████████████████████████████████████████████████████▋ | 1600/1628 [14:14<00:13,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600/1628) Data: 0.006s | Batch: 0.534s | Total: 0:14:14 | ETA: 0:00:15 | Loss: 0.0098 | top1:  88.5638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1628/1628 [14:31<00:00,  1.87it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 199/199 [00:24<00:00,  8.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(199/199) Data: 0.032s | Batch: 0.121s | Total: 0:00:24 | ETA: 0:00:01 | Loss: 0.0072 | top1:  90.9492\n",
      "=> saving checkpoint 'checkpoints\\checkpoint.pth.tar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/1628 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving best model 'checkpoints\\model_best.pth.tar'\n",
      "\n",
      "Epoch: [2 | 80] LR: 0.0100000000000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████▊                                                                          | 100/1628 [00:52<11:34,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100/1628) Data: 0.079s | Batch: 0.529s | Total: 0:00:52 | ETA: 0:12:04 | Loss: 0.0090 | top1:  89.7177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████████▋                                                                     | 200/1628 [01:39<10:36,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200/1628) Data: 0.040s | Batch: 0.496s | Total: 0:01:39 | ETA: 0:10:39 | Loss: 0.0089 | top1:  89.8334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|██████████████▌                                                                | 300/1628 [02:25<10:17,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300/1628) Data: 0.027s | Batch: 0.484s | Total: 0:02:25 | ETA: 0:10:39 | Loss: 0.0088 | top1:  89.8822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████████████▍                                                           | 400/1628 [03:12<09:32,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400/1628) Data: 0.021s | Batch: 0.480s | Total: 0:03:12 | ETA: 0:09:33 | Loss: 0.0089 | top1:  89.8750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|████████████████████████▎                                                      | 500/1628 [03:59<08:37,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500/1628) Data: 0.017s | Batch: 0.478s | Total: 0:03:59 | ETA: 0:08:41 | Loss: 0.0089 | top1:  89.8419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|█████████████████████████████                                                  | 600/1628 [04:45<07:45,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600/1628) Data: 0.014s | Batch: 0.476s | Total: 0:04:45 | ETA: 0:07:59 | Loss: 0.0090 | top1:  89.8087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|█████████████████████████████████▉                                             | 700/1628 [05:33<07:44,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700/1628) Data: 0.012s | Batch: 0.477s | Total: 0:05:33 | ETA: 0:07:20 | Loss: 0.0089 | top1:  89.8003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|██████████████████████████████████████▊                                        | 800/1628 [06:22<07:08,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800/1628) Data: 0.011s | Batch: 0.478s | Total: 0:06:22 | ETA: 0:06:55 | Loss: 0.0089 | top1:  89.8273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|███████████████████████████████████████████▋                                   | 900/1628 [07:11<05:31,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900/1628) Data: 0.010s | Batch: 0.480s | Total: 0:07:11 | ETA: 0:05:49 | Loss: 0.0089 | top1:  89.8700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|███████████████████████████████████████████████▉                              | 1000/1628 [07:59<05:19,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000/1628) Data: 0.009s | Batch: 0.479s | Total: 0:07:59 | ETA: 0:05:11 | Loss: 0.0088 | top1:  89.9000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|████████████████████████████████████████████████████▋                         | 1100/1628 [08:45<04:00,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1100/1628) Data: 0.008s | Batch: 0.478s | Total: 0:08:45 | ETA: 0:04:04 | Loss: 0.0089 | top1:  89.8913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|█████████████████████████████████████████████████████████▍                    | 1200/1628 [09:33<03:15,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200/1628) Data: 0.007s | Batch: 0.478s | Total: 0:09:33 | ETA: 0:03:17 | Loss: 0.0088 | top1:  89.9031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████████████████████████████████▎               | 1300/1628 [10:20<02:37,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1300/1628) Data: 0.007s | Batch: 0.477s | Total: 0:10:20 | ETA: 0:02:36 | Loss: 0.0088 | top1:  89.9212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|███████████████████████████████████████████████████████████████████           | 1400/1628 [11:06<01:41,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400/1628) Data: 0.006s | Batch: 0.476s | Total: 0:11:06 | ETA: 0:01:40 | Loss: 0.0088 | top1:  89.9125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|███████████████████████████████████████████████████████████████████████▊      | 1500/1628 [11:55<01:01,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500/1628) Data: 0.006s | Batch: 0.477s | Total: 0:11:55 | ETA: 0:01:06 | Loss: 0.0088 | top1:  89.9270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|████████████████████████████████████████████████████████████████████████████▋ | 1600/1628 [12:42<00:12,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600/1628) Data: 0.006s | Batch: 0.477s | Total: 0:12:42 | ETA: 0:00:13 | Loss: 0.0088 | top1:  89.9386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1628/1628 [12:56<00:00,  2.10it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 199/199 [00:34<00:00,  5.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(199/199) Data: 0.029s | Batch: 0.170s | Total: 0:00:33 | ETA: 0:00:01 | Loss: 0.0069 | top1:  91.3121\n",
      "=> saving checkpoint 'checkpoints\\checkpoint.pth.tar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/1628 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving best model 'checkpoints\\model_best.pth.tar'\n",
      "\n",
      "Epoch: [3 | 80] LR: 0.0100000000000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████▊                                                                          | 100/1628 [00:54<11:30,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100/1628) Data: 0.076s | Batch: 0.541s | Total: 0:00:54 | ETA: 0:11:58 | Loss: 0.0086 | top1:  90.1358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████████▋                                                                     | 200/1628 [01:43<11:03,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200/1628) Data: 0.038s | Batch: 0.519s | Total: 0:01:43 | ETA: 0:10:49 | Loss: 0.0085 | top1:  90.1689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████████▉                                                                  | 266/1628 [02:14<10:40,  2.13it/s]"
     ]
    }
   ],
   "source": [
    "# config.epoch = 1\n",
    "#model = create_model(device)\n",
    "dataloaders, attribute_names = load_dataloaders()\n",
    "criterion = get_criterion()\n",
    "#optimizer = get_optimizer(model)\n",
    "\n",
    "print(f\"=> Training model: {not config.evaluate}\")\n",
    "if config.evaluate:\n",
    "    best_prec1, model = load_inference_model(device, config.bestmodel_fname) # checkpoint_fname bestmodel_fname\n",
    "    test_loss, prec1, top1 = validate(dataloaders['test'], model, criterion)\n",
    "    print(f\"=> Best test accuracy: {prec1}, Model val acc: {best_prec1}\")\n",
    "    attr_acc = print_attribute_acc(top1, attribute_names)\n",
    "    if config.test_preds_fname:\n",
    "        json.dump(attr_acc, open(config.test_preds_fname,'w'))\n",
    "else:\n",
    "    best_prec1, model_timer, lr, start_epoch, logger, model, optimizer = resume_checkpoint(device, config.ckp_logger_fname, config.ckp_resume)\n",
    "    run_name, run_time = get_run_name_time(model, criterion, optimizer, comments, start_epoch)\n",
    "    mtimer = trainer(dataloaders, model, criterion, optimizer, logger, start_epoch, best_prec1, run_name, model_timer)\n",
    "    print(f\"=> Model trained time: {mtimer}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not config.evaluate:\n",
    "    config.evaluate = True\n",
    "    #model = create_model(device)\n",
    "    dataloaders, attribute_names = load_dataloaders()\n",
    "    criterion = get_criterion()\n",
    "    #optimizer = get_optimizer(model)\n",
    "    \n",
    "    best_prec1, model = load_inference_model(device, config.bestmodel_fname) # checkpoint_fname bestmodel_fname\n",
    "    #best_prec1, mtimer, _, _, logger, = resume_checkpoint(model, optimizer, config.ckp_logger_fname, config.checkpoint_fname)\n",
    "    test_loss, prec1, top1 = validate(dataloaders['test'], model, criterion)\n",
    "    print(f\"=> Best test accuracy: {prec1}, Model val acc: {best_prec1}\")\n",
    "    attr_acc = print_attribute_acc(top1, attribute_names)\n",
    "    if config.test_preds_fname:\n",
    "        json.dump(attr_acc, open(config.test_preds_fname,'w'))\n",
    "#     best_prec1, mtimer, _, _, _, = resume_checkpoint(model, optimizer, config.ckp_logger_fname, config.bestmodel_fname)# config.bestmodel_fname  config.checkpoint_fname\n",
    "#     #print(model)\n",
    "#     test_loss, prec1, top1 = validate(dataloaders['test'], model, criterion)\n",
    "#     print(f\"=> Best test accuracy: {prec1}, Model val acc: {best_prec1}\")\n",
    "#     print_attribute_acc(top1, attribute_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save & Backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ISJUPYTER:\n",
    "    # Wait for notebook to save\n",
    "    %autosave 1\n",
    "    time.sleep(121)\n",
    "    %autosave 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backup_everything(run_time, run_name, title, backup_nb=ISJUPYTER):\n",
    "    # backup checkpoints\n",
    "    print(f\"=> backing up checkpoints... \")\n",
    "    run_dir = os.path.join(config.BACKUP_DIR, run_name, run_time)\n",
    "    create_dir_ifne(run_dir)\n",
    "    fromDirectory = config.CHECKPOINT_DIR\n",
    "    toDirectory = run_dir\n",
    "    copy_tree(fromDirectory, toDirectory)\n",
    "    \n",
    "    if backup_nb:\n",
    "        print(f\"=> backing up notebook... \")\n",
    "        # backup notebook html\n",
    "        nb_name = title + '.ipynb'\n",
    "        html_name = title + '.html'\n",
    "        save_name = os.path.join(run_dir, html_name)\n",
    "        !jupyter nbconvert --to html $nb_name\n",
    "        shutil.move(html_name, save_name)\n",
    "    \n",
    "backup_everything(run_time, run_name, title, backup_nb=ISJUPYTER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.auto_hibernate and False:\n",
    "    os.system('shutdown -h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOYWQroywTLOsSvW/4lPmBg",
   "collapsed_sections": [],
   "name": "ai6126-project1-colab-v0.1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
