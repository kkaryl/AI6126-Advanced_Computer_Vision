{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UVAZt6s-Fu41"
   },
   "source": [
    "# AI6126 ACV Project 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 1038,
     "status": "ok",
     "timestamp": 1601175331072,
     "user": {
      "displayName": "Jia Hui Ong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKvHQmYQfzydylrU8HXZxYxJP3L6kGAQ94P-sS=s64",
      "userId": "05957301376516334331"
     },
     "user_tz": -480
    },
    "id": "jzjCg15BeR43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ai6126-p1-train-v1.5\n",
      "53\n"
     ]
    }
   ],
   "source": [
    "nb_ver = 1.5\n",
    "title = f'ai6126-p1-train-v{nb_ver}'\n",
    "print(title)\n",
    "comments = \"53\"\n",
    "print(comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Versioning & References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4c2s81g4d5PE"
   },
   "source": [
    "### Changelogs\n",
    "+ V0.1 - Setup codes to download and unzip celeba to gDrive\n",
    "+ V0.2 - Added training loop \n",
    "+ V0.3 - Added seeding + save/ load checkpoint\n",
    "+ V0.4 - Added time taken + save output\n",
    "+ V0.5 - Added RandomErasing to transforms\n",
    "+ V0.6 - Added get_criterion (FocalLoss) \n",
    "+ V0.7 - Added FaceAttrMobileNetV2 & FaceAttrResNeXt\n",
    "+ V0.8 - Added Albumentations\n",
    "+ V0.9 - Updated Optimizer (SGD, AdamW works well)\n",
    "+ V0.91 - Added ModelTimer() + Added more augmentations\n",
    "+ V1.0 - Added ReduceLROnPlateau Scheduler\n",
    "+ V1.1 - Updated Augmentations to more closely follow Tricks paper + Added OneCycleLR Scheduler + No bias decay\n",
    "+ V1.2 - Added Early Stopping\n",
    "+ V1.3 - Code Clean\n",
    "+ V1.4 - Added LabelSmoothing to CrossEntropyLoss and FocalLoss\n",
    "+ V1.5 - Added MixedUp + CosineWarmUpLR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ToDo:\n",
    "+ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "+ [Face Attribute Prediction on CelebA benchmark with PyTorch Implementation](https://github.com/d-li14/face-attribute-prediction)\n",
    "+ [PyTorch Transfer Learning](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html)\n",
    "+ [Albumentations](https://albumentations.ai/)\n",
    "+ [Focal Loss](https://github.com/kornia/kornia/blob/master/kornia/losses/focal.py)\n",
    "+ [Bag of Tricks](https://arxiv.org/abs/1812.01187)\n",
    "+ [Torch ToolBox](https://github.com/PistonY/torch-toolbox)\n",
    "+ [Fastai Course](https://www.youtube.com/watch?v=vnOpEwmtFJ8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install pytorch torchvision cudatoolkit=10.2 -c pytorch\n",
    "# conda install matplotlib\n",
    "# conda install pandas\n",
    "# conda install tqdm\n",
    "# conda install -c conda-forge jupyterlab\n",
    "# conda install -c conda-forge tensorboard\n",
    "# conda install -c conda-forge protobuf # for tensorboard\n",
    "# conda install nb_conda_kernels # auto add kernels\n",
    "\n",
    "# conda install -c conda-forge imgaug\n",
    "# conda install albumentations -c conda-forge\n",
    "# conda install seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UmjjrIheF0u5"
   },
   "source": [
    "## Setup/ Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "executionInfo": {
     "elapsed": 4455,
     "status": "error",
     "timestamp": 1601175336681,
     "user": {
      "displayName": "Jia Hui Ong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKvHQmYQfzydylrU8HXZxYxJP3L6kGAQ94P-sS=s64",
      "userId": "05957301376516334331"
     },
     "user_tz": -480
    },
    "id": "7mTWwwivDNy3",
    "outputId": "9f87be63-e615-42bf-b306-8a2ec7e2458d"
   },
   "outputs": [],
   "source": [
    "# you can choose to mount your Google Drive (optional)\n",
    "import sys, os\n",
    "if 'google.colab' in sys.modules:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    file_name = f'ai6126-project1-colab-v{nb_ver}.ipynb'\n",
    "    print(file_name)\n",
    "    import subprocess\n",
    "    path_to_file = subprocess.check_output('find . -type f -name ' + str(file_name), shell=True).decode(\"utf-8\")\n",
    "    print(path_to_file)\n",
    "    path_to_file = path_to_file.replace(file_name,\"\").replace('\\n',\"\")\n",
    "    os.chdir(path_to_file)\n",
    "    !pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Dataset (JUPYTER ONLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download celeba dataset: False\n"
     ]
    }
   ],
   "source": [
    "import os, glob\n",
    "local_download_path = '../data/celeba/img_align_celeba'\n",
    "download_dataset = True\n",
    "if os.path.exists(local_download_path):\n",
    "    images = glob.glob(local_download_path + '/*.jpg')\n",
    "    if len(images) == 202599:\n",
    "        download_dataset = False\n",
    "print(f\"download celeba dataset: {download_dataset}\")\n",
    "\n",
    "if download_dataset:\n",
    "    # create dataset root and enter it\n",
    "    !mkdir -p data/celeba\n",
    "    %cd data/celeba\n",
    "\n",
    "    # we have prepared a backup of `img_align_celeba.zip` of Celeb-A dataset in the Dropbox\n",
    "    # download it directly, or manually download the original file from Google Drive above\n",
    "    !wget https://www.dropbox.com/s/8kzo40fqx7nodat/img_align_celeba.zip\n",
    "\n",
    "    # unzip the downloaded file\n",
    "    !unzip -qq img_align_celeba.zip\n",
    "    !rm -f img_align_celeba.zip\n",
    "\n",
    "    # change the directory back to the root\n",
    "    %cd ../..\n",
    "    !ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "tEkTpN_qDN5u"
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import shutil\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import copy\n",
    "from datetime import datetime\n",
    "from distutils.dir_util import copy_tree #for recursive filecopying\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import config\n",
    "from celeba_dataset import CelebaDataset\n",
    "import models\n",
    "import losses\n",
    "import schedulers\n",
    "from utils import Logger, AverageMeter, Bar, ModelTimer, savefig, adjust_learning_rate, accuracy, print_attribute_acc, create_dir_ifne, add_weight_decay, mixup_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "DCjPfxzUDN3Y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.0 True\n",
      "cuda:0\n",
      "disable_tqdm: False\n"
     ]
    }
   ],
   "source": [
    "# check PyTorch version and cuda status\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "\n",
    "# define device\n",
    "device = torch.device(\"cuda:\"+config.gpu_id if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "ISJUPYTER = False\n",
    "if 'ipykernel' in sys.modules:\n",
    "    ISJUPYTER = True\n",
    "    # set the backend of matplotlib to the 'inline' backend\n",
    "    %matplotlib inline\n",
    "    config.disable_tqdm = False\n",
    "    \n",
    "print(f\"disable_tqdm: {config.disable_tqdm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "executionInfo": {
     "elapsed": 4483,
     "status": "ok",
     "timestamp": 1601174828368,
     "user": {
      "displayName": "Jia Hui Ong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKvHQmYQfzydylrU8HXZxYxJP3L6kGAQ94P-sS=s64",
      "userId": "05957301376516334331"
     },
     "user_tz": -480
    },
    "id": "9Te1EuMyDN7-",
    "outputId": "e1a9321b-0c11-476e-dea5-57b3fa33f732"
   },
   "outputs": [],
   "source": [
    "# set random seed for reproducibility\n",
    "def seed_everything(seed=None):\n",
    "    if seed is None:\n",
    "        seed = random.randint(1, 10000) # create random seed\n",
    "        print(f'random seed used: {seed}')\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    if 'torch' in sys.modules:\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "seed_everything(seed=config.manual_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 7867,
     "status": "ok",
     "timestamp": 1601174831763,
     "user": {
      "displayName": "Jia Hui Ong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKvHQmYQfzydylrU8HXZxYxJP3L6kGAQ94P-sS=s64",
      "userId": "05957301376516334331"
     },
     "user_tz": -480
    },
    "id": "UeTJbZQ5b_ea",
    "outputId": "de5f0be8-65fe-4648-e719-ff92f2642235",
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "### Data Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation and testing\n",
    "def load_dataloaders(print_info=True, albu_transforms = True):\n",
    "    if config.evaluate:\n",
    "        phases = ['test']\n",
    "    else:\n",
    "        phases = ['train', 'val']\n",
    "\n",
    "    attribute_names = ['5_o_Clock_Shadow', 'Arched_Eyebrows', 'Attractive', 'Bags_Under_Eyes', 'Bald', \n",
    "                       'Bangs', 'Big_Lips', 'Big_Nose', 'Black_Hair', 'Blond_Hair', 'Blurry', 'Brown_Hair', \n",
    "                       'Bushy_Eyebrows', 'Chubby', 'Double_Chin', 'Eyeglasses', 'Goatee', 'Gray_Hair',\n",
    "                       'Heavy_Makeup', 'High_Cheekbones', 'Male', 'Mouth_Slightly_Open', 'Mustache', \n",
    "                       'Narrow_Eyes', 'No_Beard', 'Oval_Face', 'Pale_Skin', 'Pointy_Nose', 'Receding_Hairline',\n",
    "                       'Rosy_Cheeks', 'Sideburns', 'Smiling', 'Straight_Hair', 'Wavy_Hair', 'Wearing_Earrings', \n",
    "                       'Wearing_Hat', 'Wearing_Lipstick', 'Wearing_Necklace', 'Wearing_Necktie', 'Young']\n",
    "    \n",
    "    attributes_list = {\n",
    "        'train': config.TRAIN_ATTRIBUTE_LIST,\n",
    "        'val': config.VAL_ATTRIBUTE_LIST,\n",
    "        'test': config.TEST_ATTRIBUTE_LIST\n",
    "    }\n",
    "\n",
    "    batch_sizes = {\n",
    "        'train': config.train_batch,\n",
    "        'val': config.test_batch,\n",
    "        'test': config.test_batch\n",
    "    }\n",
    "\n",
    "    if not albu_transforms:\n",
    "        normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                                         std=[0.229, 0.224, 0.225])\n",
    "        data_transforms = {\n",
    "            'train': transforms.Compose([\n",
    "                transforms.CenterCrop((198, 158)), #new\n",
    "                transforms.RandomHorizontalFlip(p=0.5),\n",
    "                #transforms.RandomRotation(degrees=10), #new\n",
    "                transforms.ToTensor(),\n",
    "                normalize,\n",
    "            ]),\n",
    "            'val': transforms.Compose([\n",
    "                transforms.CenterCrop((198, 158)), #new\n",
    "                transforms.ToTensor(),\n",
    "                normalize\n",
    "            ]),\n",
    "            'test': transforms.Compose([\n",
    "                transforms.CenterCrop((198, 158)), #new\n",
    "                transforms.ToTensor(),\n",
    "                normalize\n",
    "            ])\n",
    "        }\n",
    "    else:\n",
    "        normalize_A = A.Normalize(mean=(0.485, 0.456, 0.406), \n",
    "                                  std=(0.229, 0.224, 0.225))\n",
    "        data_transforms = {\n",
    "            'train': A.Compose([\n",
    "                #A.RandomResizedCrop(148, 148), # cuts out too much attributes, use centercrop instead\n",
    "                A.CenterCrop(height=198, width=158),\n",
    "                A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, \n",
    "                                 rotate_limit=15, p=0.5), # AFFACT https://arxiv.org/pdf/1611.06158.pdf\n",
    "                A.HorizontalFlip(p=0.5),\n",
    "                #A.HueSaturationValue(hue_shift_limit=14, sat_shift_limit=14, val_shift_limit=14, p=0.5),\n",
    "                #A.FancyPCA(alpha=0.1, p=0.5), #http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf\n",
    "                #A.RandomBrightnessContrast(p=0.5),\n",
    "                #A.GaussNoise(var_limit=10.0, p=0.5), \n",
    "                #A.GaussianBlur(p=0.1), # AFFACT https://arxiv.org/pdf/1611.06158.pdf\n",
    "                #A.CoarseDropout(max_holes=1, max_height=74, max_width=74, \n",
    "                #               min_height=49, min_width=49, fill_value=0, p=0.2), #https://arxiv.org/pdf/1708.04896.pdf\n",
    "                normalize_A,\n",
    "                ToTensorV2(),\n",
    "                \n",
    "            ]),\n",
    "            'val': A.Compose([\n",
    "                #Rescale an image so that minimum side is equal to max_size 178 (shortest edge of Celeba)\n",
    "                #A.SmallestMaxSize(max_size=178), \n",
    "                A.CenterCrop(height=198, width=158),\n",
    "                normalize_A,\n",
    "                ToTensorV2(),\n",
    "            ]),\n",
    "            'test': A.Compose([\n",
    "                #A.SmallestMaxSize(max_size=178),\n",
    "                A.CenterCrop(height=198, width=158),\n",
    "                normalize_A,\n",
    "                ToTensorV2(),\n",
    "            ])\n",
    "        }\n",
    "\n",
    "    image_datasets = {x: CelebaDataset(config.IMG_DIR, attributes_list[x], \n",
    "                                       data_transforms[x], albu=albu_transforms) \n",
    "                      for x in phases}\n",
    "    dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], \n",
    "                                                  batch_size=batch_sizes[x],\n",
    "                                                  pin_memory=True, shuffle=(x == 'train'), \n",
    "                                                  num_workers=config.dl_workers) \n",
    "                   for x in phases}\n",
    "    if print_info:\n",
    "        dataset_sizes = {x: len(image_datasets[x]) for x in phases}\n",
    "        print(f\"Dataset sizes: {dataset_sizes}\")\n",
    "        \n",
    "    if config.evaluate:\n",
    "        class_names = image_datasets['test'].targets\n",
    "    else:\n",
    "        class_names = image_datasets['train'].targets\n",
    "    print(f\"Class Labels: {len(class_names[0])}\")\n",
    "    assert len(attribute_names) == len(class_names[0])\n",
    "    return dataloaders, attribute_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qtfDq7Z2F6Nh",
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "### Model Architecture Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Models: ['FaceAttrMobileNetV2', 'FaceAttrResNeXt', 'FaceAttrResNet']\n"
     ]
    }
   ],
   "source": [
    "model_names = sorted(name for name in models.__dict__\n",
    "                     if callable(models.__dict__[name])) # and name.islower() and not name.startswith(\"__\"))\n",
    "print(f\"Available Models: {model_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> creating model 'FaceAttrMobileNetV2'\n"
     ]
    }
   ],
   "source": [
    "def create_model(arch, layers, device):\n",
    "    print(\"=> creating model '{}'\".format(config.arch))\n",
    "    if arch.startswith('FaceAttrResNet'):\n",
    "        model = models.__dict__[arch](resnet_layers = layers)\n",
    "    elif arch.startswith('FaceAttrResNeXt'):\n",
    "        model = models.__dict__[arch](resnet_layers = layers)\n",
    "    elif arch.startswith('FaceAttrMobileNetV2'):\n",
    "        model = models.__dict__[arch]()\n",
    "    model = model.to(device)\n",
    "    return model\n",
    "\n",
    "model = create_model(config.arch, config.pt_layers, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criterion & Optimizer & Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def get_criterion():\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    if config.criterion == 'CE' and config.label_smoothing:\n",
    "        criterion = losses.LabelSmoothingCrossEntropy(ls=config.label_smoothing).to(device) \n",
    "    elif config.criterion == 'FocalLoss':\n",
    "        criterion = losses.FocalLossLS(alpha=0.25, gamma=3, reduction='mean', ls=config.label_smoothing).to(device) \n",
    "        \n",
    "    if config.mixed_up > 0:\n",
    "        criterion = losses.MixedUp(criterion).to(device) \n",
    "        \n",
    "    return criterion\n",
    "\n",
    "criterion = get_criterion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(model, opt_name=config.optimizer, no_bias_bn_decay=config.no_bias_bn_decay):\n",
    "    weight_decay = config.weight_decay\n",
    "    if no_bias_bn_decay: #bag of tricks paper\n",
    "        parameters = add_weight_decay(model, weight_decay)\n",
    "        weight_decay = 0.\n",
    "    else:\n",
    "        parameters = model.parameters()\n",
    "    \n",
    "    optimizer = None\n",
    "    if opt_name == 'SGD':\n",
    "        optimizer = torch.optim.SGD(parameters, config.lr,\n",
    "                                momentum=config.momentum,\n",
    "                                weight_decay=weight_decay)\n",
    "    elif opt_name == 'Adam':\n",
    "        optimizer = torch.optim.Adam(parameters, config.lr,\n",
    "                            weight_decay=weight_decay)\n",
    "    elif opt_name == 'AdamW':\n",
    "        optimizer = torch.optim.AdamW(parameters, config.lr,\n",
    "                            weight_decay=weight_decay)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scheduler(optimizer, steps_per_epoch, epochs):\n",
    "    scheduler = None # Manual\n",
    "    if config.scheduler == 'ReduceLROnPlateau':\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min',\n",
    "                                                               factor=0.1,\n",
    "                                                               patience=config.patience)\n",
    "    elif config.scheduler == 'OneCycleLR': \n",
    "        scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.1, epochs=epochs,\n",
    "                                                        steps_per_epoch=int(steps_per_epoch), \n",
    "                                                        anneal_strategy='cos') #https://arxiv.org/pdf/1708.07120.pdf\n",
    "    elif config.scheduler == 'CosineWarmupLR':\n",
    "        scheduler = schedulers.CosineWarmupLR(optimizer, batches=int(steps_per_epoch),\n",
    "                                              epochs=epochs, base_lr=0.001, target_lr=0, warmup_epochs=5,\n",
    "                                              warmup_lr = 0.01)\n",
    "    \n",
    "    return scheduler    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resume Checkpoint if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_checkpoint(modelname, opt_name, bias_decay=False, ckp_resume=None):\n",
    "    best_prec1 = 0\n",
    "\n",
    "    if ckp_resume and os.path.isfile(ckp_resume): \n",
    "        print(f\"=> formatting model: {ckp_resume}\")\n",
    "        checkpoint = torch.load(ckp_resume)\n",
    "        print(checkpoint['arch'])\n",
    "        try:\n",
    "            total_time = checkpoint['total_time']\n",
    "        except:\n",
    "            total_time = 0\n",
    "        \n",
    "        state = {\n",
    "            'epoch': checkpoint['epoch'],\n",
    "            'arch': modelname,\n",
    "            'state_dict': checkpoint['state_dict'],\n",
    "            'best_prec1': checkpoint['best_prec1'],\n",
    "            'opt_name': opt_name,\n",
    "            'optimizer' : checkpoint['optimizer'],\n",
    "            'lr': checkpoint['lr'],\n",
    "            'total_time': total_time,\n",
    "            'bias_decay': bias_decay\n",
    "        }\n",
    "        torch.save(state, ckp_resume)\n",
    "        \n",
    "    else:\n",
    "        raise\n",
    "        \n",
    "#format_checkpoint('FaceAttrResNeXt_50', 'SGD', True, ckp_resume=config.bestmodel_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resume_checkpoint(device, ckp_logger_fname, ckp_resume=None):\n",
    "    if not ckp_logger_fname:\n",
    "        print(\"[W] Logger path not found.\")\n",
    "        raise\n",
    "\n",
    "    start_epoch = 0\n",
    "    best_prec1 = 0\n",
    "    lr = config.lr\n",
    "    \n",
    "    if ckp_resume == '':\n",
    "        ckp_resume = None\n",
    "    \n",
    "    if ckp_resume and os.path.isfile(ckp_resume): \n",
    "        print(f\"=> resuming checkpoint: {ckp_resume}\")\n",
    "        checkpoint = torch.load(ckp_resume)\n",
    "        \n",
    "        try:\n",
    "            total_time = checkpoint['total_time']\n",
    "            model_timer = ModelTimer(total_time)\n",
    "            print(f\"=> model trained time: {model_timer}\")\n",
    "        except:\n",
    "            print(f\"=> old model\")\n",
    "            model_timer = ModelTimer()\n",
    "        best_prec1 = checkpoint['best_prec1']\n",
    "        print(f\"=> model best val: {best_prec1}\")\n",
    "        \n",
    "        start_epoch = checkpoint['epoch']\n",
    "        print(f\"=> model epoch: {start_epoch}\")\n",
    "        lr = checkpoint['lr']\n",
    "\n",
    "        print(f\"=> resuming model: {checkpoint['arch']}\")\n",
    "        model = create_model(checkpoint['arch'].split('_')[0], \n",
    "                             int(checkpoint['arch'].split('_')[1]), \n",
    "                             device)\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        \n",
    "        print(f\"=> resuming optimizer: {checkpoint['opt_name']}\")\n",
    "        bias_decay = True\n",
    "        if checkpoint['bias_decay']:\n",
    "            bias_decay = checkpoint['bias_decay']\n",
    "            \n",
    "        optimizer = get_optimizer(model, checkpoint['opt_name'], bias_decay)\n",
    "        if optimizer:\n",
    "            optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        logger = Logger(ckp_logger_fname, title=model.name, resume=True)\n",
    "        \n",
    "    else:\n",
    "        print(f\"=> restarting training: {ckp_resume}\")\n",
    "        model_timer = ModelTimer()\n",
    "        model = create_model(config.arch, config.pt_layers, device)\n",
    "        optimizer = get_optimizer(model)\n",
    "        logger = Logger(ckp_logger_fname, title=model.name)\n",
    "        logger.set_names(['Learning Rate', 'Train Loss', 'Valid Loss', 'Train Acc.', 'Valid Acc.'])\n",
    "              \n",
    "    return best_prec1, model_timer, lr, start_epoch, logger, model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_inference_model(device, ckp_resume):\n",
    "    if not (ckp_resume and os.path.isfile(ckp_resume)):\n",
    "        print(\"[W] Checkpoint not found for inference.\")\n",
    "        raise \n",
    "    \n",
    "    print(f\"=> loading checkpoint: {ckp_resume}\")\n",
    "    checkpoint = torch.load(ckp_resume)\n",
    "    try:\n",
    "        total_time = checkpoint['total_time']\n",
    "        model_timer = ModelTimer(total_time)\n",
    "        print(f\"=> model trained time: {model_timer}\")\n",
    "    except:\n",
    "        print(f\"=> old model\")\n",
    "    best_prec1 = checkpoint['best_prec1']\n",
    "    print(f\"=> model best val: {best_prec1}\")\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    print(f\"=> model epoch: {start_epoch}\")\n",
    "\n",
    "    print(f\"=> resuming model: {checkpoint['arch']}\")\n",
    "    model = create_model(checkpoint['arch'].split('_')[0], \n",
    "                         int(checkpoint['arch'].split('_')[1]), \n",
    "                         device)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "              \n",
    "    return best_prec1, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Validate Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer):\n",
    "    bar = Bar('Processing', max=len(train_loader))\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = [AverageMeter() for _ in range(40)]\n",
    "    top1 = [AverageMeter() for _ in range(40)]\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (X, y) in enumerate(tqdm(train_loader, disable=config.disable_tqdm)):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        # Overlapping transfer if pinned memory\n",
    "        X = X.to(device, non_blocking=True)\n",
    "        y = y.to(device, non_blocking=True)\n",
    "        if config.mixed_up > 0:\n",
    "            X, y, lam = mixup_data(X, y, alpha=config.mixed_up)\n",
    "            criterion.set_lambda(lam)\n",
    "    \n",
    "        # compute output\n",
    "        output = model(X)\n",
    "        # measure accuracy and record loss\n",
    "        loss = []\n",
    "        prec1 = []\n",
    "        for j in range(len(output)): \n",
    "            if config.mixed_up > 0:\n",
    "                labels = y[:, :, j]\n",
    "                actual_labels = y[0, :, j] * lam + y[1, :, j] * (1-lam)\n",
    "            else:\n",
    "                labels = y[:, j]\n",
    "                actual_labels = y[:, j]\n",
    "            crit = criterion(output[j], labels)\n",
    "            loss.append(crit)\n",
    "            prec1.append(accuracy(output[j], actual_labels, topk=(1,), mixedup=config.mixed_up))\n",
    "            losses[j].update(loss[j].detach().item(), X.size(0))\n",
    "            top1[j].update(prec1[j][0].item(), X.size(0))\n",
    "            \n",
    "        losses_avg = [losses[k].avg for k in range(len(losses))]\n",
    "        top1_avg = [top1[k].avg for k in range(len(top1))]\n",
    "        loss_avg = sum(losses_avg) / len(losses_avg)\n",
    "        prec1_avg = sum(top1_avg) / len(top1_avg)\n",
    "\n",
    "        # compute gradient and do optimizer step\n",
    "        optimizer.zero_grad()\n",
    "        loss_sum = sum(loss)\n",
    "        loss_sum.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # plot progress\n",
    "        print_line = '({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | Loss: {loss:.4f} | top1: {top1: .4f}'.format(\n",
    "                        batch=i + 1,\n",
    "                        size=len(train_loader),\n",
    "                        data=data_time.avg,\n",
    "                        bt=batch_time.avg,\n",
    "                        total=bar.elapsed_td,\n",
    "                        eta=bar.eta_td,\n",
    "                        loss=loss_avg,\n",
    "                        top1=prec1_avg,\n",
    "                        )\n",
    "        if not config.disable_tqdm and (i+1)% 100 == 0:\n",
    "            print(print_line)\n",
    "        bar.suffix  = print_line\n",
    "        bar.next()\n",
    "    bar.finish()\n",
    "    return (loss_avg, prec1_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion):\n",
    "    bar = Bar('Processing', max=len(val_loader))\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = [AverageMeter() for _ in range(40)]\n",
    "    top1 = [AverageMeter() for _ in range(40)]\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (X, y) in enumerate(tqdm(val_loader, disable=config.disable_tqdm)):\n",
    "            # measure data loading time\n",
    "            data_time.update(time.time() - end)\n",
    "\n",
    "            # Overlapping transfer if pinned memory\n",
    "            X = X.to(device, non_blocking=True)\n",
    "            y = y.to(device, non_blocking=True)\n",
    "            \n",
    "            # compute output\n",
    "            output = model(X)\n",
    "            # measure accuracy and record loss\n",
    "            loss = []\n",
    "            prec1 = []\n",
    "            for j in range(len(output)):\n",
    "                if config.mixed_up > 0:\n",
    "                    loss.append(criterion(output[j], y[:, j], mixed=False))\n",
    "                else:\n",
    "                    loss.append(criterion(output[j], y[:, j]))\n",
    "                prec1.append(accuracy(output[j], y[:, j], topk=(1,)))\n",
    "                \n",
    "                losses[j].update(loss[j].detach().item(), X.size(0))\n",
    "                top1[j].update(prec1[j][0].item(), X.size(0))\n",
    "            losses_avg = [losses[k].avg for k in range(len(losses))]\n",
    "            top1_avg = [top1[k].avg for k in range(len(top1))]\n",
    "            loss_avg = sum(losses_avg) / len(losses_avg)\n",
    "            prec1_avg = sum(top1_avg) / len(top1_avg)\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "            \n",
    "            # plot progress\n",
    "            print_line = '({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | Loss: {loss:.4f} | top1: {top1: .4f}'.format(\n",
    "                            batch=i + 1,\n",
    "                            size=len(val_loader),\n",
    "                            data=data_time.avg,\n",
    "                            bt=batch_time.avg,\n",
    "                            total=bar.elapsed_td,\n",
    "                            eta=bar.eta_td,\n",
    "                            loss=loss_avg,\n",
    "                            top1=prec1_avg,\n",
    "                            )\n",
    "\n",
    "            bar.suffix  = print_line\n",
    "            bar.next()  \n",
    "\n",
    "    if not config.disable_tqdm:\n",
    "        print(print_line)        \n",
    "    bar.finish()\n",
    "    return (loss_avg, prec1_avg, top1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(dataloaders, model, criterion, optimizer, logger, start_epoch, best_prec1, run_name, model_timer):\n",
    "    # visualization\n",
    "    writer = SummaryWriter(os.path.join(config.tensorboard_dir, run_name))\n",
    "    \n",
    "    scheduler = get_scheduler(optimizer, len(dataloaders['train']), config.epochs-start_epoch)\n",
    "    \n",
    "    stagnant_val_loss_ctr = 0\n",
    "    min_val_loss = 1.\n",
    "    \n",
    "    for epoch in range(start_epoch, config.epochs):\n",
    "        model_timer.start_epoch_timer()\n",
    "        if not scheduler:\n",
    "            lr = adjust_learning_rate(optimizer, config.lr_decay, epoch, gamma=config.gamma, step=config.step,\n",
    "                                     total_epochs=config.epochs, turning_point=config.turning_point,\n",
    "                                     schedule=config.schedule)\n",
    "        else:\n",
    "            lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "        print('\\nEpoch: [%d | %d] LR: %.16f' % (epoch + 1, config.epochs, lr))\n",
    "\n",
    "        # train for one epoch\n",
    "        train_loss, train_acc = train(dataloaders['train'], model, criterion, optimizer)\n",
    "\n",
    "        # evaluate on validation set\n",
    "        val_loss, prec1, _ = validate(dataloaders['val'], model, criterion)\n",
    "        \n",
    "        if scheduler:\n",
    "            scheduler.step(None if config.scheduler != 'ReduceLROnPlateau' else val_loss)\n",
    "            \n",
    "        # append logger file\n",
    "        logger.append([lr, train_loss, val_loss, train_acc, prec1])\n",
    "\n",
    "        # tensorboardX\n",
    "        writer.add_scalar('learning rate', lr, epoch + 1)\n",
    "        writer.add_scalars('loss', {'train loss': train_loss, 'validation loss': val_loss}, epoch + 1)\n",
    "        writer.add_scalars('accuracy', {'train accuracy': train_acc, 'validation accuracy': prec1}, epoch + 1)\n",
    "\n",
    "        is_best = prec1 > best_prec1\n",
    "        best_prec1 = max(prec1, best_prec1)\n",
    "        model_timer.stop_epoch_timer()\n",
    "        model.save_ckp({\n",
    "            'epoch': epoch + 1,\n",
    "            'arch': model.name,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'best_prec1': best_prec1,\n",
    "            'opt_name': config.optimizer,\n",
    "            'optimizer' : optimizer.state_dict(),\n",
    "            'lr': lr,\n",
    "            'total_time': model_timer.total_time,\n",
    "            'bias_decay': config.no_bias_bn_decay,\n",
    "        }, is_best, config.checkpoint_fname,config.bestmodel_fname)\n",
    "        \n",
    "        if config.early_stopping:\n",
    "            if is_best:\n",
    "                stagnant_val_loss_ctr = 0\n",
    "                min_val_loss = val_loss\n",
    "            elif val_loss >= min_val_loss:\n",
    "                stagnant_val_loss_ctr += 1\n",
    "                if (epoch+1) > config.es_min and stagnant_val_loss_ctr >= config.es_patience: \n",
    "                    break\n",
    "            else:\n",
    "                stagnant_val_loss_ctr = 0\n",
    "                min_val_loss = val_loss\n",
    "\n",
    "    logger.close()\n",
    "    logger.plot()\n",
    "    save_path = None\n",
    "    if config.train_saveplot:\n",
    "        save_path = os.path.join(config.CHECKPOINT_DIR, \"losses.jpg\")\n",
    "    logger.plot_special(save_path)\n",
    "    savefig(config.train_plotfig)\n",
    "    writer.close()\n",
    "\n",
    "    print('Best accuracy:')\n",
    "    print(best_prec1)\n",
    "    return model_timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_run_name_time(model, criterion, optimizer, comments, start_epoch=0):\n",
    "    try:\n",
    "        if criterion.name:\n",
    "            p_criterion = criterion.name\n",
    "    except:\n",
    "        p_criterion = 'CE'\n",
    "\n",
    "    p_optimizer = f'{str(optimizer).split(\"(\")[0].strip()}'\n",
    "    p_scheduler = f'lr{config.lr}_wd{config.weight_decay}'\n",
    "    if config.scheduler == 'Manual':\n",
    "        p_scheduler += f'_{config.lr_decay}'\n",
    "        if config.lr_decay == 'step':\n",
    "            p_scheduler += f'_g{config.gamma}_sp{config.step}'\n",
    "        elif config.lr_decay == 'linear2exp':\n",
    "            p_scheduler += f'_g{config.gamma}_tp{config.turning_point}'\n",
    "        elif config.lr_decay == 'schedule':\n",
    "            p_scheduler += f'_g{config.gamma}_sch{config.schedule}'\n",
    "    else: \n",
    "        p_scheduler += f'_{config.scheduler}'\n",
    "    \n",
    "    run_name = f'{model.name}_{config.manual_seed}_s{start_epoch}e{config.epochs}_' \\\n",
    "                + f'tb{config.train_batch}_vb{config.test_batch}_' \\\n",
    "                + f'{p_criterion}_{p_optimizer}_' \\\n",
    "                + f'{comments}_' \\\n",
    "                + f'{p_scheduler}'\n",
    "    \n",
    "    run_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    print(run_name, run_time)\n",
    "    return run_name, run_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PWCHnDeVD4WT",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset sizes: {'train': 162770, 'val': 19867}\n",
      "Class Labels: 40\n",
      "=> Training model: True\n",
      "=> restarting training: None\n",
      "=> creating model 'FaceAttrMobileNetV2'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/1628 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FaceAttrMobileNetV2_50_42_s0e80_tb100_vb100_MU_FL_SGD_53_lr0.01_wd0.0001_ReduceLROnPlateau 20201020_011817\n",
      "\n",
      "Epoch: [1 | 80] LR: 0.0100000000000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████▊                                                                          | 100/1628 [00:40<07:10,  3.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100/1628) Data: 0.076s | Batch: 0.401s | Total: 0:00:40 | ETA: 0:07:08 | Loss: 0.0142 | top1:  83.0855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████████▋                                                                     | 200/1628 [01:08<06:47,  3.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200/1628) Data: 0.038s | Batch: 0.343s | Total: 0:01:08 | ETA: 0:06:47 | Loss: 0.0127 | top1:  84.8810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|██████████████▌                                                                | 300/1628 [01:38<07:19,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300/1628) Data: 0.026s | Batch: 0.327s | Total: 0:01:38 | ETA: 0:07:01 | Loss: 0.0119 | top1:  85.8817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████████████▍                                                           | 400/1628 [02:09<06:22,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400/1628) Data: 0.020s | Batch: 0.323s | Total: 0:02:09 | ETA: 0:06:20 | Loss: 0.0114 | top1:  86.4597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|████████████████████████▎                                                      | 500/1628 [02:40<05:57,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500/1628) Data: 0.016s | Batch: 0.320s | Total: 0:02:40 | ETA: 0:05:47 | Loss: 0.0110 | top1:  86.9117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|█████████████████████████████                                                  | 600/1628 [03:11<05:19,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600/1628) Data: 0.013s | Batch: 0.319s | Total: 0:03:11 | ETA: 0:05:17 | Loss: 0.0108 | top1:  87.2194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|█████████████████████████████████▉                                             | 700/1628 [03:42<04:51,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700/1628) Data: 0.012s | Batch: 0.318s | Total: 0:03:42 | ETA: 0:04:59 | Loss: 0.0106 | top1:  87.4506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|██████████████████████████████████████▊                                        | 800/1628 [04:15<04:14,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800/1628) Data: 0.010s | Batch: 0.319s | Total: 0:04:15 | ETA: 0:04:13 | Loss: 0.0105 | top1:  87.6340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|███████████████████████████████████████████▋                                   | 900/1628 [04:48<03:57,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900/1628) Data: 0.009s | Batch: 0.321s | Total: 0:04:48 | ETA: 0:03:51 | Loss: 0.0104 | top1:  87.8120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|███████████████████████████████████████████████▉                              | 1000/1628 [05:21<03:14,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000/1628) Data: 0.008s | Batch: 0.321s | Total: 0:05:21 | ETA: 0:03:20 | Loss: 0.0103 | top1:  87.9463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|████████████████████████████████████████████████████▋                         | 1100/1628 [05:52<02:49,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1100/1628) Data: 0.008s | Batch: 0.321s | Total: 0:05:52 | ETA: 0:02:45 | Loss: 0.0102 | top1:  88.0823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|█████████████████████████████████████████████████████████▍                    | 1200/1628 [06:24<02:13,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200/1628) Data: 0.007s | Batch: 0.321s | Total: 0:06:24 | ETA: 0:02:21 | Loss: 0.0101 | top1:  88.1881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████████████████████████████████▎               | 1300/1628 [06:56<01:41,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1300/1628) Data: 0.007s | Batch: 0.321s | Total: 0:06:56 | ETA: 0:01:42 | Loss: 0.0100 | top1:  88.2789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|███████████████████████████████████████████████████████████████████           | 1400/1628 [07:28<01:17,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400/1628) Data: 0.006s | Batch: 0.320s | Total: 0:07:28 | ETA: 0:01:16 | Loss: 0.0099 | top1:  88.3950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|███████████████████████████████████████████████████████████████████████▊      | 1500/1628 [08:00<00:40,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500/1628) Data: 0.006s | Batch: 0.321s | Total: 0:08:00 | ETA: 0:00:43 | Loss: 0.0099 | top1:  88.4504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|████████████████████████████████████████████████████████████████████████████▋ | 1600/1628 [08:32<00:09,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600/1628) Data: 0.006s | Batch: 0.321s | Total: 0:08:32 | ETA: 0:00:10 | Loss: 0.0099 | top1:  88.5061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1628/1628 [08:44<00:00,  3.11it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 199/199 [00:26<00:00,  7.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(199/199) Data: 0.033s | Batch: 0.128s | Total: 0:00:25 | ETA: 0:00:01 | Loss: 0.0073 | top1:  90.8914\n",
      "=> saving checkpoint 'checkpoints\\checkpoint.pth.tar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/1628 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving best model 'checkpoints\\model_best.pth.tar'\n",
      "\n",
      "Epoch: [2 | 80] LR: 0.0100000000000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████▊                                                                          | 100/1628 [00:38<07:55,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100/1628) Data: 0.080s | Batch: 0.383s | Total: 0:00:38 | ETA: 0:08:04 | Loss: 0.0090 | top1:  89.6638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████████▋                                                                     | 200/1628 [01:09<07:39,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200/1628) Data: 0.041s | Batch: 0.348s | Total: 0:01:09 | ETA: 0:07:30 | Loss: 0.0089 | top1:  89.7703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|██████████████▌                                                                | 300/1628 [01:41<06:44,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300/1628) Data: 0.027s | Batch: 0.338s | Total: 0:01:41 | ETA: 0:07:12 | Loss: 0.0089 | top1:  89.8291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████████████▍                                                           | 400/1628 [02:13<06:25,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400/1628) Data: 0.021s | Batch: 0.333s | Total: 0:02:13 | ETA: 0:06:40 | Loss: 0.0089 | top1:  89.8339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|████████████████████████▎                                                      | 500/1628 [02:44<05:52,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500/1628) Data: 0.017s | Batch: 0.330s | Total: 0:02:44 | ETA: 0:05:47 | Loss: 0.0090 | top1:  89.7999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|█████████████████████████████                                                  | 600/1628 [03:16<05:25,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600/1628) Data: 0.014s | Batch: 0.327s | Total: 0:03:16 | ETA: 0:05:22 | Loss: 0.0090 | top1:  89.7657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|█████████████████████████████████▉                                             | 700/1628 [03:47<05:00,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700/1628) Data: 0.012s | Batch: 0.326s | Total: 0:03:47 | ETA: 0:04:55 | Loss: 0.0090 | top1:  89.7544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|██████████████████████████████████████▊                                        | 800/1628 [04:20<04:15,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800/1628) Data: 0.011s | Batch: 0.325s | Total: 0:04:20 | ETA: 0:04:18 | Loss: 0.0089 | top1:  89.7776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|███████████████████████████████████████████▋                                   | 900/1628 [04:51<03:53,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900/1628) Data: 0.010s | Batch: 0.324s | Total: 0:04:51 | ETA: 0:03:50 | Loss: 0.0089 | top1:  89.8232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|███████████████████████████████████████████████▉                              | 1000/1628 [05:22<03:13,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000/1628) Data: 0.009s | Batch: 0.323s | Total: 0:05:22 | ETA: 0:03:21 | Loss: 0.0089 | top1:  89.8530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|████████████████████████████████████████████████████▋                         | 1100/1628 [05:54<02:51,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1100/1628) Data: 0.008s | Batch: 0.323s | Total: 0:05:54 | ETA: 0:02:46 | Loss: 0.0089 | top1:  89.8414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|█████████████████████████████████████████████████████████▍                    | 1200/1628 [06:26<02:10,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200/1628) Data: 0.007s | Batch: 0.322s | Total: 0:06:26 | ETA: 0:02:20 | Loss: 0.0089 | top1:  89.8504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████████████████████████████████▎               | 1300/1628 [06:57<01:42,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1300/1628) Data: 0.007s | Batch: 0.321s | Total: 0:06:57 | ETA: 0:01:44 | Loss: 0.0088 | top1:  89.8685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|███████████████████████████████████████████████████████████████████           | 1400/1628 [07:29<01:10,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400/1628) Data: 0.006s | Batch: 0.321s | Total: 0:07:29 | ETA: 0:01:12 | Loss: 0.0088 | top1:  89.8610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|███████████████████████████████████████████████████████████████████████▊      | 1500/1628 [08:00<00:41,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500/1628) Data: 0.006s | Batch: 0.320s | Total: 0:08:00 | ETA: 0:00:42 | Loss: 0.0088 | top1:  89.8745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|████████████████████████████████████████████████████████████████████████████▋ | 1600/1628 [08:31<00:08,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600/1628) Data: 0.006s | Batch: 0.320s | Total: 0:08:31 | ETA: 0:00:09 | Loss: 0.0088 | top1:  89.8883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1628/1628 [08:41<00:00,  3.12it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 199/199 [00:25<00:00,  7.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(199/199) Data: 0.033s | Batch: 0.124s | Total: 0:00:24 | ETA: 0:00:01 | Loss: 0.0069 | top1:  91.3025\n",
      "=> saving checkpoint 'checkpoints\\checkpoint.pth.tar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/1628 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving best model 'checkpoints\\model_best.pth.tar'\n",
      "\n",
      "Epoch: [3 | 80] LR: 0.0100000000000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████▊                                                                          | 100/1628 [00:38<07:53,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100/1628) Data: 0.081s | Batch: 0.383s | Total: 0:00:38 | ETA: 0:07:54 | Loss: 0.0086 | top1:  90.0750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████████▋                                                                     | 200/1628 [01:09<07:19,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200/1628) Data: 0.041s | Batch: 0.348s | Total: 0:01:09 | ETA: 0:07:32 | Loss: 0.0085 | top1:  90.1217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|██████████████▌                                                                | 300/1628 [01:42<07:35,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300/1628) Data: 0.027s | Batch: 0.341s | Total: 0:01:42 | ETA: 0:07:12 | Loss: 0.0085 | top1:  90.1230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████████████▍                                                           | 400/1628 [02:17<07:21,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400/1628) Data: 0.021s | Batch: 0.344s | Total: 0:02:17 | ETA: 0:07:22 | Loss: 0.0086 | top1:  90.1278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|████████████████████████▎                                                      | 500/1628 [02:50<05:49,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500/1628) Data: 0.017s | Batch: 0.341s | Total: 0:02:50 | ETA: 0:05:50 | Loss: 0.0085 | top1:  90.1729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|█████████████████████████████                                                  | 600/1628 [03:22<05:31,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600/1628) Data: 0.014s | Batch: 0.338s | Total: 0:03:22 | ETA: 0:05:31 | Loss: 0.0085 | top1:  90.1775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|█████████████████████████████████▉                                             | 700/1628 [03:54<04:40,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700/1628) Data: 0.012s | Batch: 0.335s | Total: 0:03:54 | ETA: 0:04:53 | Loss: 0.0085 | top1:  90.1511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|██████████████████████████████████████▊                                        | 800/1628 [04:27<04:43,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800/1628) Data: 0.011s | Batch: 0.334s | Total: 0:04:27 | ETA: 0:04:40 | Loss: 0.0085 | top1:  90.1898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|███████████████████████████████████████████▋                                   | 900/1628 [05:00<03:54,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900/1628) Data: 0.010s | Batch: 0.333s | Total: 0:05:00 | ETA: 0:04:03 | Loss: 0.0085 | top1:  90.1619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|███████████████████████████████████████████████▉                              | 1000/1628 [05:32<03:22,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000/1628) Data: 0.009s | Batch: 0.333s | Total: 0:05:32 | ETA: 0:03:32 | Loss: 0.0085 | top1:  90.1702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|████████████████████████████████████████████████████▋                         | 1100/1628 [06:04<02:52,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1100/1628) Data: 0.008s | Batch: 0.332s | Total: 0:06:04 | ETA: 0:02:55 | Loss: 0.0085 | top1:  90.1571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|█████████████████████████████████████████████████████████▍                    | 1200/1628 [06:36<02:26,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200/1628) Data: 0.007s | Batch: 0.331s | Total: 0:06:36 | ETA: 0:02:26 | Loss: 0.0085 | top1:  90.1469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████████████████████████████████▎               | 1300/1628 [07:09<01:49,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1300/1628) Data: 0.007s | Batch: 0.331s | Total: 0:07:09 | ETA: 0:01:50 | Loss: 0.0085 | top1:  90.1591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|███████████████████████████████████████████████████████████████████           | 1400/1628 [07:42<01:10,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400/1628) Data: 0.007s | Batch: 0.331s | Total: 0:07:42 | ETA: 0:01:12 | Loss: 0.0085 | top1:  90.1574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|███████████████████████████████████████████████████████████████████████▊      | 1500/1628 [08:15<00:40,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500/1628) Data: 0.006s | Batch: 0.330s | Total: 0:08:15 | ETA: 0:00:42 | Loss: 0.0085 | top1:  90.1652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|████████████████████████████████████████████████████████████████████████████▋ | 1600/1628 [08:48<00:09,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600/1628) Data: 0.006s | Batch: 0.330s | Total: 0:08:48 | ETA: 0:00:11 | Loss: 0.0085 | top1:  90.1588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1628/1628 [08:58<00:00,  3.02it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 199/199 [00:25<00:00,  7.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(199/199) Data: 0.034s | Batch: 0.125s | Total: 0:00:24 | ETA: 0:00:01 | Loss: 0.0071 | top1:  91.3288\n",
      "=> saving checkpoint 'checkpoints\\checkpoint.pth.tar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/1628 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving best model 'checkpoints\\model_best.pth.tar'\n",
      "\n",
      "Epoch: [4 | 80] LR: 0.0100000000000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████▊                                                                          | 100/1628 [00:38<07:44,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100/1628) Data: 0.082s | Batch: 0.384s | Total: 0:00:38 | ETA: 0:07:51 | Loss: 0.0085 | top1:  90.0385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████████▋                                                                     | 200/1628 [01:09<07:22,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200/1628) Data: 0.041s | Batch: 0.350s | Total: 0:01:09 | ETA: 0:07:24 | Loss: 0.0086 | top1:  90.0800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|██████████████▌                                                                | 300/1628 [01:41<06:55,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300/1628) Data: 0.028s | Batch: 0.337s | Total: 0:01:41 | ETA: 0:07:01 | Loss: 0.0085 | top1:  90.2158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████████████▍                                                           | 400/1628 [02:12<06:24,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400/1628) Data: 0.021s | Batch: 0.331s | Total: 0:02:12 | ETA: 0:06:20 | Loss: 0.0085 | top1:  90.2688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|████████████████████████▎                                                      | 500/1628 [02:45<06:04,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500/1628) Data: 0.017s | Batch: 0.331s | Total: 0:02:45 | ETA: 0:06:41 | Loss: 0.0085 | top1:  90.2982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|█████████████████████████████                                                  | 600/1628 [03:19<05:58,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600/1628) Data: 0.014s | Batch: 0.333s | Total: 0:03:19 | ETA: 0:06:39 | Loss: 0.0084 | top1:  90.3447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|█████████████████████████████████▉                                             | 700/1628 [03:53<05:08,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700/1628) Data: 0.012s | Batch: 0.333s | Total: 0:03:53 | ETA: 0:04:58 | Loss: 0.0084 | top1:  90.3090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|██████████████████████████████████████▊                                        | 800/1628 [04:26<04:25,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800/1628) Data: 0.011s | Batch: 0.333s | Total: 0:04:26 | ETA: 0:04:31 | Loss: 0.0084 | top1:  90.3114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|███████████████████████████████████████████▋                                   | 900/1628 [04:58<03:54,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900/1628) Data: 0.010s | Batch: 0.332s | Total: 0:04:58 | ETA: 0:04:01 | Loss: 0.0084 | top1:  90.3348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|███████████████████████████████████████████████▉                              | 1000/1628 [05:31<03:28,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000/1628) Data: 0.009s | Batch: 0.332s | Total: 0:05:31 | ETA: 0:03:21 | Loss: 0.0084 | top1:  90.3417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|████████████████████████████████████████████████████▋                         | 1100/1628 [06:04<02:49,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1100/1628) Data: 0.008s | Batch: 0.331s | Total: 0:06:04 | ETA: 0:02:57 | Loss: 0.0084 | top1:  90.3486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|█████████████████████████████████████████████████████████▍                    | 1200/1628 [06:36<02:15,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200/1628) Data: 0.008s | Batch: 0.330s | Total: 0:06:36 | ETA: 0:02:18 | Loss: 0.0084 | top1:  90.3194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████████████████████████████████▎               | 1300/1628 [07:08<01:42,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1300/1628) Data: 0.007s | Batch: 0.329s | Total: 0:07:08 | ETA: 0:01:41 | Loss: 0.0084 | top1:  90.3212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|███████████████████████████████████████████████████████████████████           | 1400/1628 [07:40<01:11,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400/1628) Data: 0.007s | Batch: 0.329s | Total: 0:07:40 | ETA: 0:01:13 | Loss: 0.0084 | top1:  90.3451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|███████████████████████████████████████████████████████████████████████▊      | 1500/1628 [08:12<00:38,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500/1628) Data: 0.006s | Batch: 0.328s | Total: 0:08:12 | ETA: 0:00:41 | Loss: 0.0084 | top1:  90.3625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|████████████████████████████████████████████████████████████████████████████▋ | 1600/1628 [08:44<00:08,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600/1628) Data: 0.006s | Batch: 0.328s | Total: 0:08:44 | ETA: 0:00:10 | Loss: 0.0084 | top1:  90.3732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1628/1628 [08:54<00:00,  3.05it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 199/199 [00:25<00:00,  7.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(199/199) Data: 0.035s | Batch: 0.125s | Total: 0:00:24 | ETA: 0:00:01 | Loss: 0.0067 | top1:  91.6560\n",
      "=> saving checkpoint 'checkpoints\\checkpoint.pth.tar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/1628 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving best model 'checkpoints\\model_best.pth.tar'\n",
      "\n",
      "Epoch: [5 | 80] LR: 0.0100000000000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████▊                                                                          | 100/1628 [00:38<07:54,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100/1628) Data: 0.081s | Batch: 0.387s | Total: 0:00:38 | ETA: 0:07:48 | Loss: 0.0085 | top1:  90.1810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████████▋                                                                     | 200/1628 [01:10<07:16,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200/1628) Data: 0.041s | Batch: 0.351s | Total: 0:01:10 | ETA: 0:07:23 | Loss: 0.0083 | top1:  90.3839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|██████████████▌                                                                | 300/1628 [01:41<06:46,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300/1628) Data: 0.028s | Batch: 0.337s | Total: 0:01:41 | ETA: 0:06:45 | Loss: 0.0083 | top1:  90.3286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████████████▍                                                           | 400/1628 [02:12<06:40,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400/1628) Data: 0.021s | Batch: 0.331s | Total: 0:02:12 | ETA: 0:06:27 | Loss: 0.0084 | top1:  90.2791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|████████████████████████▎                                                      | 500/1628 [02:44<06:07,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500/1628) Data: 0.017s | Batch: 0.328s | Total: 0:02:44 | ETA: 0:06:24 | Loss: 0.0084 | top1:  90.2813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|█████████████████████████████                                                  | 600/1628 [03:14<05:13,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600/1628) Data: 0.014s | Batch: 0.325s | Total: 0:03:14 | ETA: 0:05:18 | Loss: 0.0084 | top1:  90.2936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|█████████████████████████████████▉                                             | 700/1628 [03:45<05:24,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700/1628) Data: 0.012s | Batch: 0.323s | Total: 0:03:45 | ETA: 0:04:58 | Loss: 0.0084 | top1:  90.3306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|██████████████████████████████████████▊                                        | 800/1628 [04:16<04:15,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800/1628) Data: 0.011s | Batch: 0.321s | Total: 0:04:16 | ETA: 0:04:24 | Loss: 0.0084 | top1:  90.3315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|███████████████████████████████████████████▋                                   | 900/1628 [04:48<03:43,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900/1628) Data: 0.010s | Batch: 0.320s | Total: 0:04:48 | ETA: 0:03:46 | Loss: 0.0084 | top1:  90.3611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|███████████████████████████████████████████████▉                              | 1000/1628 [05:19<03:18,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000/1628) Data: 0.009s | Batch: 0.319s | Total: 0:05:19 | ETA: 0:03:14 | Loss: 0.0084 | top1:  90.3349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|████████████████████████████████████████████████████▋                         | 1100/1628 [05:50<02:47,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1100/1628) Data: 0.008s | Batch: 0.319s | Total: 0:05:50 | ETA: 0:02:46 | Loss: 0.0083 | top1:  90.3640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|█████████████████████████████████████████████████████████▍                    | 1200/1628 [06:21<02:10,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200/1628) Data: 0.008s | Batch: 0.318s | Total: 0:06:21 | ETA: 0:02:14 | Loss: 0.0083 | top1:  90.3834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████████████████████████████████▎               | 1300/1628 [06:53<01:43,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1300/1628) Data: 0.007s | Batch: 0.318s | Total: 0:06:53 | ETA: 0:01:44 | Loss: 0.0083 | top1:  90.3956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|███████████████████████████████████████████████████████████████████           | 1400/1628 [07:25<01:10,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400/1628) Data: 0.007s | Batch: 0.318s | Total: 0:07:25 | ETA: 0:01:17 | Loss: 0.0083 | top1:  90.4088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|███████████████████████████████████████████████████████████████████████▊      | 1500/1628 [07:56<00:42,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500/1628) Data: 0.006s | Batch: 0.318s | Total: 0:07:56 | ETA: 0:00:41 | Loss: 0.0083 | top1:  90.4143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|████████████████████████████████████████████████████████████████████████████▋ | 1600/1628 [08:27<00:08,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600/1628) Data: 0.006s | Batch: 0.317s | Total: 0:08:27 | ETA: 0:00:09 | Loss: 0.0084 | top1:  90.4041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1628/1628 [08:37<00:00,  3.14it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 199/199 [00:24<00:00,  8.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(199/199) Data: 0.032s | Batch: 0.121s | Total: 0:00:24 | ETA: 0:00:01 | Loss: 0.0066 | top1:  91.7698\n",
      "=> saving checkpoint 'checkpoints\\checkpoint.pth.tar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/1628 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving best model 'checkpoints\\model_best.pth.tar'\n",
      "\n",
      "Epoch: [6 | 80] LR: 0.0100000000000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████▊                                                                          | 100/1628 [00:37<07:35,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100/1628) Data: 0.082s | Batch: 0.378s | Total: 0:00:37 | ETA: 0:07:34 | Loss: 0.0086 | top1:  90.2985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████████▋                                                                     | 200/1628 [01:08<07:20,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200/1628) Data: 0.042s | Batch: 0.341s | Total: 0:01:08 | ETA: 0:07:14 | Loss: 0.0084 | top1:  90.3974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|██████████████▌                                                                | 300/1628 [01:38<06:43,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300/1628) Data: 0.028s | Batch: 0.330s | Total: 0:01:38 | ETA: 0:06:51 | Loss: 0.0084 | top1:  90.3513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████████████▍                                                           | 400/1628 [02:09<06:16,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400/1628) Data: 0.021s | Batch: 0.324s | Total: 0:02:09 | ETA: 0:06:20 | Loss: 0.0084 | top1:  90.4092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|████████████████████████▎                                                      | 500/1628 [02:40<05:51,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500/1628) Data: 0.017s | Batch: 0.320s | Total: 0:02:40 | ETA: 0:05:54 | Loss: 0.0084 | top1:  90.4282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|█████████████████████████████                                                  | 600/1628 [03:10<05:05,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600/1628) Data: 0.014s | Batch: 0.318s | Total: 0:03:10 | ETA: 0:05:16 | Loss: 0.0084 | top1:  90.4278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|█████████████████████████████████▉                                             | 700/1628 [03:43<05:39,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700/1628) Data: 0.012s | Batch: 0.320s | Total: 0:03:43 | ETA: 0:05:22 | Loss: 0.0084 | top1:  90.3862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|██████████████████████████████████████▊                                        | 800/1628 [04:15<04:18,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800/1628) Data: 0.011s | Batch: 0.319s | Total: 0:04:15 | ETA: 0:04:20 | Loss: 0.0084 | top1:  90.3700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|███████████████████████████████████████████▋                                   | 900/1628 [04:48<04:09,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900/1628) Data: 0.010s | Batch: 0.320s | Total: 0:04:48 | ETA: 0:03:58 | Loss: 0.0084 | top1:  90.3963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|███████████████████████████████████████████████▉                              | 1000/1628 [05:20<03:21,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000/1628) Data: 0.009s | Batch: 0.320s | Total: 0:05:20 | ETA: 0:03:31 | Loss: 0.0084 | top1:  90.4082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|████████████████████████████████████████████████████▋                         | 1100/1628 [05:53<02:53,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1100/1628) Data: 0.008s | Batch: 0.321s | Total: 0:05:53 | ETA: 0:02:54 | Loss: 0.0084 | top1:  90.3934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|█████████████████████████████████████████████████████████▍                    | 1200/1628 [06:27<02:31,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200/1628) Data: 0.008s | Batch: 0.323s | Total: 0:06:27 | ETA: 0:02:35 | Loss: 0.0084 | top1:  90.4122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████████████████████████████████▎               | 1300/1628 [07:00<01:46,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1300/1628) Data: 0.007s | Batch: 0.323s | Total: 0:07:00 | ETA: 0:01:46 | Loss: 0.0084 | top1:  90.4096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|███████████████████████████████████████████████████████████████████           | 1400/1628 [07:33<01:19,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400/1628) Data: 0.007s | Batch: 0.324s | Total: 0:07:33 | ETA: 0:01:17 | Loss: 0.0083 | top1:  90.4255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|███████████████████████████████████████████████████████████████████████▊      | 1500/1628 [08:07<00:42,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500/1628) Data: 0.006s | Batch: 0.325s | Total: 0:08:07 | ETA: 0:00:43 | Loss: 0.0083 | top1:  90.4350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|████████████████████████████████████████████████████████████████████████████▋ | 1600/1628 [08:40<00:09,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600/1628) Data: 0.006s | Batch: 0.325s | Total: 0:08:40 | ETA: 0:00:11 | Loss: 0.0083 | top1:  90.4430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1628/1628 [08:50<00:00,  3.07it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 199/199 [00:25<00:00,  7.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(199/199) Data: 0.034s | Batch: 0.127s | Total: 0:00:25 | ETA: 0:00:01 | Loss: 0.0065 | top1:  91.8232\n",
      "=> saving checkpoint 'checkpoints\\checkpoint.pth.tar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/1628 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving best model 'checkpoints\\model_best.pth.tar'\n",
      "\n",
      "Epoch: [7 | 80] LR: 0.0100000000000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████▊                                                                          | 100/1628 [00:42<07:51,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100/1628) Data: 0.083s | Batch: 0.424s | Total: 0:00:42 | ETA: 0:07:50 | Loss: 0.0082 | top1:  90.6955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████████▋                                                                     | 200/1628 [01:14<07:32,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200/1628) Data: 0.042s | Batch: 0.373s | Total: 0:01:14 | ETA: 0:07:34 | Loss: 0.0082 | top1:  90.6440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|██████████████▌                                                                | 300/1628 [01:47<08:00,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300/1628) Data: 0.028s | Batch: 0.358s | Total: 0:01:47 | ETA: 0:08:06 | Loss: 0.0082 | top1:  90.6107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████████████▍                                                           | 400/1628 [02:21<06:41,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400/1628) Data: 0.021s | Batch: 0.354s | Total: 0:02:21 | ETA: 0:06:57 | Loss: 0.0082 | top1:  90.5838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|████████████████████████▎                                                      | 500/1628 [02:55<06:15,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500/1628) Data: 0.017s | Batch: 0.350s | Total: 0:02:55 | ETA: 0:05:47 | Loss: 0.0082 | top1:  90.5888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|█████████████████████████████                                                  | 600/1628 [03:28<05:44,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600/1628) Data: 0.015s | Batch: 0.347s | Total: 0:03:28 | ETA: 0:05:40 | Loss: 0.0082 | top1:  90.6316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|█████████████████████████████████▉                                             | 700/1628 [04:00<04:50,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700/1628) Data: 0.013s | Batch: 0.343s | Total: 0:04:00 | ETA: 0:04:50 | Loss: 0.0082 | top1:  90.6080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|██████████████████████████████████████▊                                        | 800/1628 [04:31<04:15,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800/1628) Data: 0.011s | Batch: 0.340s | Total: 0:04:31 | ETA: 0:04:13 | Loss: 0.0082 | top1:  90.5960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|███████████████████████████████████████████▋                                   | 900/1628 [05:04<04:24,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900/1628) Data: 0.010s | Batch: 0.338s | Total: 0:05:04 | ETA: 0:04:10 | Loss: 0.0082 | top1:  90.5779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|███████████████████████████████████████████████▉                              | 1000/1628 [05:37<03:18,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000/1628) Data: 0.009s | Batch: 0.337s | Total: 0:05:37 | ETA: 0:03:27 | Loss: 0.0082 | top1:  90.5674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|████████████████████████████████████████████████████▋                         | 1100/1628 [06:09<02:37,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1100/1628) Data: 0.008s | Batch: 0.336s | Total: 0:06:09 | ETA: 0:02:43 | Loss: 0.0082 | top1:  90.5375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|█████████████████████████████████████████████████████████▍                    | 1200/1628 [06:43<02:23,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200/1628) Data: 0.008s | Batch: 0.336s | Total: 0:06:43 | ETA: 0:02:27 | Loss: 0.0082 | top1:  90.5504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████████████████████████████████▎               | 1300/1628 [07:17<01:45,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1300/1628) Data: 0.007s | Batch: 0.336s | Total: 0:07:17 | ETA: 0:01:44 | Loss: 0.0082 | top1:  90.5544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|███████████████████████████████████████████████████████████████████           | 1400/1628 [07:50<01:10,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400/1628) Data: 0.007s | Batch: 0.336s | Total: 0:07:50 | ETA: 0:01:14 | Loss: 0.0082 | top1:  90.5595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|███████████████████████████████████████████████████████████████████████▊      | 1500/1628 [08:23<00:41,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500/1628) Data: 0.006s | Batch: 0.336s | Total: 0:08:23 | ETA: 0:00:44 | Loss: 0.0082 | top1:  90.5896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|████████████████████████████████████████████████████████████████████████████▋ | 1600/1628 [08:57<00:08,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600/1628) Data: 0.006s | Batch: 0.336s | Total: 0:08:57 | ETA: 0:00:09 | Loss: 0.0082 | top1:  90.5855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1628/1628 [09:07<00:00,  2.98it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 199/199 [00:27<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(199/199) Data: 0.037s | Batch: 0.137s | Total: 0:00:27 | ETA: 0:00:01 | Loss: 0.0066 | top1:  91.8353\n",
      "=> saving checkpoint 'checkpoints\\checkpoint.pth.tar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/1628 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving best model 'checkpoints\\model_best.pth.tar'\n",
      "\n",
      "Epoch: [8 | 80] LR: 0.0100000000000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████▊                                                                          | 100/1628 [00:42<08:32,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100/1628) Data: 0.094s | Batch: 0.421s | Total: 0:00:42 | ETA: 0:08:26 | Loss: 0.0081 | top1:  90.5612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████████▋                                                                     | 200/1628 [01:14<07:57,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200/1628) Data: 0.047s | Batch: 0.371s | Total: 0:01:14 | ETA: 0:07:32 | Loss: 0.0082 | top1:  90.5495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|██████████████▌                                                                | 300/1628 [01:45<07:12,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300/1628) Data: 0.032s | Batch: 0.353s | Total: 0:01:45 | ETA: 0:07:02 | Loss: 0.0080 | top1:  90.6873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████████████▍                                                           | 400/1628 [02:18<06:13,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400/1628) Data: 0.024s | Batch: 0.347s | Total: 0:02:18 | ETA: 0:06:17 | Loss: 0.0081 | top1:  90.6212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|████████████████████████▎                                                      | 500/1628 [02:50<06:02,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500/1628) Data: 0.020s | Batch: 0.341s | Total: 0:02:50 | ETA: 0:05:53 | Loss: 0.0081 | top1:  90.6394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|█████████████████████████████                                                  | 600/1628 [03:22<05:41,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600/1628) Data: 0.016s | Batch: 0.338s | Total: 0:03:22 | ETA: 0:05:43 | Loss: 0.0081 | top1:  90.6442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|█████████████████████████████████▉                                             | 700/1628 [03:55<04:48,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700/1628) Data: 0.014s | Batch: 0.336s | Total: 0:03:55 | ETA: 0:04:42 | Loss: 0.0082 | top1:  90.6217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|██████████████████████████████████████▊                                        | 800/1628 [04:28<04:52,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800/1628) Data: 0.013s | Batch: 0.335s | Total: 0:04:28 | ETA: 0:04:34 | Loss: 0.0082 | top1:  90.5899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|███████████████████████████████████████████▋                                   | 900/1628 [05:00<03:56,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900/1628) Data: 0.011s | Batch: 0.334s | Total: 0:05:00 | ETA: 0:04:00 | Loss: 0.0082 | top1:  90.6101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|███████████████████████████████████████████████▉                              | 1000/1628 [05:32<03:27,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000/1628) Data: 0.010s | Batch: 0.333s | Total: 0:05:32 | ETA: 0:03:24 | Loss: 0.0082 | top1:  90.5813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|████████████████████████████████████████████████████▋                         | 1100/1628 [06:06<02:46,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1100/1628) Data: 0.009s | Batch: 0.333s | Total: 0:06:06 | ETA: 0:02:57 | Loss: 0.0082 | top1:  90.5965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|█████████████████████████████████████████████████████████▍                    | 1200/1628 [06:38<02:15,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200/1628) Data: 0.009s | Batch: 0.332s | Total: 0:06:38 | ETA: 0:02:16 | Loss: 0.0082 | top1:  90.6090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████████████████████████████████▎               | 1300/1628 [07:10<01:45,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1300/1628) Data: 0.008s | Batch: 0.331s | Total: 0:07:10 | ETA: 0:01:43 | Loss: 0.0082 | top1:  90.6095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|███████████████████████████████████████████████████████████████████           | 1400/1628 [07:42<01:14,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400/1628) Data: 0.008s | Batch: 0.330s | Total: 0:07:42 | ETA: 0:01:13 | Loss: 0.0082 | top1:  90.5942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|███████████████████████████████████████████████████████████████████████▊      | 1500/1628 [08:14<00:40,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500/1628) Data: 0.007s | Batch: 0.329s | Total: 0:08:14 | ETA: 0:00:40 | Loss: 0.0082 | top1:  90.6018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|████████████████████████████████████████████████████████████████████████████▋ | 1600/1628 [08:46<00:09,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600/1628) Data: 0.007s | Batch: 0.329s | Total: 0:08:46 | ETA: 0:00:10 | Loss: 0.0082 | top1:  90.6152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1628/1628 [08:56<00:00,  3.03it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 199/199 [00:25<00:00,  7.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(199/199) Data: 0.034s | Batch: 0.124s | Total: 0:00:24 | ETA: 0:00:01 | Loss: 0.0066 | top1:  91.8527\n",
      "=> saving checkpoint 'checkpoints\\checkpoint.pth.tar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/1628 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving best model 'checkpoints\\model_best.pth.tar'\n",
      "\n",
      "Epoch: [9 | 80] LR: 0.0100000000000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████▊                                                                          | 100/1628 [00:38<07:54,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100/1628) Data: 0.083s | Batch: 0.388s | Total: 0:00:38 | ETA: 0:07:56 | Loss: 0.0080 | top1:  90.6260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████████▋                                                                     | 200/1628 [01:10<07:27,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200/1628) Data: 0.042s | Batch: 0.350s | Total: 0:01:10 | ETA: 0:07:20 | Loss: 0.0082 | top1:  90.5416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|██████████████▌                                                                | 300/1628 [01:42<07:09,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300/1628) Data: 0.028s | Batch: 0.340s | Total: 0:01:42 | ETA: 0:07:23 | Loss: 0.0081 | top1:  90.6519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████████████▍                                                           | 400/1628 [02:13<06:13,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400/1628) Data: 0.021s | Batch: 0.334s | Total: 0:02:13 | ETA: 0:06:25 | Loss: 0.0080 | top1:  90.7367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|████████████████████████▎                                                      | 500/1628 [02:46<05:50,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500/1628) Data: 0.017s | Batch: 0.332s | Total: 0:02:46 | ETA: 0:06:01 | Loss: 0.0081 | top1:  90.6884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|█████████████████████████████                                                  | 600/1628 [03:18<05:45,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600/1628) Data: 0.015s | Batch: 0.330s | Total: 0:03:18 | ETA: 0:05:31 | Loss: 0.0081 | top1:  90.7063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|█████████████████████████████████▉                                             | 700/1628 [03:50<05:04,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700/1628) Data: 0.013s | Batch: 0.330s | Total: 0:03:50 | ETA: 0:05:13 | Loss: 0.0081 | top1:  90.7047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|██████████████████████████████████████▊                                        | 800/1628 [04:23<04:27,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800/1628) Data: 0.011s | Batch: 0.329s | Total: 0:04:23 | ETA: 0:04:23 | Loss: 0.0081 | top1:  90.7019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|███████████████████████████████████████████▋                                   | 900/1628 [04:55<03:55,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900/1628) Data: 0.010s | Batch: 0.328s | Total: 0:04:55 | ETA: 0:03:55 | Loss: 0.0081 | top1:  90.7248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|███████████████████████████████████████████████▉                              | 1000/1628 [05:28<03:24,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000/1628) Data: 0.009s | Batch: 0.328s | Total: 0:05:28 | ETA: 0:03:25 | Loss: 0.0081 | top1:  90.7244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|████████████████████████████████████████████████████▋                         | 1100/1628 [06:01<02:56,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1100/1628) Data: 0.008s | Batch: 0.328s | Total: 0:06:01 | ETA: 0:03:00 | Loss: 0.0081 | top1:  90.6948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|█████████████████████████████████████████████████████████▍                    | 1200/1628 [06:35<02:22,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200/1628) Data: 0.008s | Batch: 0.329s | Total: 0:06:35 | ETA: 0:02:33 | Loss: 0.0081 | top1:  90.6834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████████████████████████████████▎               | 1300/1628 [07:08<01:46,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1300/1628) Data: 0.007s | Batch: 0.330s | Total: 0:07:08 | ETA: 0:01:45 | Loss: 0.0081 | top1:  90.7160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|███████████████████████████████████████████████████████████████████           | 1400/1628 [07:40<01:15,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400/1628) Data: 0.007s | Batch: 0.329s | Total: 0:07:40 | ETA: 0:01:12 | Loss: 0.0081 | top1:  90.7066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|███████████████████████████████████████████████████████████████████████▊      | 1500/1628 [08:13<00:41,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500/1628) Data: 0.006s | Batch: 0.329s | Total: 0:08:13 | ETA: 0:00:43 | Loss: 0.0081 | top1:  90.7123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|████████████████████████████████████████████████████████████████████████████▋ | 1600/1628 [08:46<00:09,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600/1628) Data: 0.006s | Batch: 0.329s | Total: 0:08:46 | ETA: 0:00:10 | Loss: 0.0081 | top1:  90.7245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1628/1628 [08:56<00:00,  3.03it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 199/199 [00:25<00:00,  7.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(199/199) Data: 0.033s | Batch: 0.127s | Total: 0:00:25 | ETA: 0:00:01 | Loss: 0.0065 | top1:  91.9201\n",
      "=> saving checkpoint 'checkpoints\\checkpoint.pth.tar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/1628 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving best model 'checkpoints\\model_best.pth.tar'\n",
      "\n",
      "Epoch: [10 | 80] LR: 0.0100000000000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████▊                                                                          | 100/1628 [00:39<07:47,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100/1628) Data: 0.086s | Batch: 0.390s | Total: 0:00:39 | ETA: 0:07:55 | Loss: 0.0083 | top1:  90.6183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████████▋                                                                     | 200/1628 [01:09<07:07,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200/1628) Data: 0.044s | Batch: 0.350s | Total: 0:01:09 | ETA: 0:07:33 | Loss: 0.0080 | top1:  90.7143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|██████████████▌                                                                | 300/1628 [01:43<06:47,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300/1628) Data: 0.029s | Batch: 0.344s | Total: 0:01:43 | ETA: 0:07:03 | Loss: 0.0080 | top1:  90.6937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████████████▍                                                           | 400/1628 [02:15<06:40,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400/1628) Data: 0.022s | Batch: 0.338s | Total: 0:02:15 | ETA: 0:06:24 | Loss: 0.0080 | top1:  90.7586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|████████████████████████▎                                                      | 500/1628 [02:47<05:47,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500/1628) Data: 0.018s | Batch: 0.335s | Total: 0:02:47 | ETA: 0:05:55 | Loss: 0.0079 | top1:  90.8140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|█████████████████████████████                                                  | 600/1628 [03:18<05:14,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600/1628) Data: 0.015s | Batch: 0.331s | Total: 0:03:18 | ETA: 0:05:17 | Loss: 0.0079 | top1:  90.8463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|█████████████████████████████████▉                                             | 700/1628 [03:50<05:11,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700/1628) Data: 0.013s | Batch: 0.330s | Total: 0:03:50 | ETA: 0:05:00 | Loss: 0.0079 | top1:  90.8349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|██████████████████████████████████████▊                                        | 800/1628 [04:22<04:35,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800/1628) Data: 0.012s | Batch: 0.328s | Total: 0:04:22 | ETA: 0:04:41 | Loss: 0.0079 | top1:  90.8181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|███████████████████████████████████████████▋                                   | 900/1628 [04:55<03:57,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900/1628) Data: 0.010s | Batch: 0.328s | Total: 0:04:55 | ETA: 0:04:14 | Loss: 0.0079 | top1:  90.8118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|███████████████████████████████████████████████▉                              | 1000/1628 [05:29<03:52,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000/1628) Data: 0.009s | Batch: 0.329s | Total: 0:05:29 | ETA: 0:03:49 | Loss: 0.0080 | top1:  90.7821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|████████████████████████████████████████████████████▋                         | 1100/1628 [06:02<02:52,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1100/1628) Data: 0.009s | Batch: 0.330s | Total: 0:06:02 | ETA: 0:03:00 | Loss: 0.0080 | top1:  90.7472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|█████████████████████████████████████████████████████████▍                    | 1200/1628 [06:36<02:09,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200/1628) Data: 0.008s | Batch: 0.330s | Total: 0:06:36 | ETA: 0:02:12 | Loss: 0.0080 | top1:  90.7572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████████████████████████████████▎               | 1300/1628 [07:11<02:10,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1300/1628) Data: 0.007s | Batch: 0.332s | Total: 0:07:11 | ETA: 0:02:13 | Loss: 0.0080 | top1:  90.7668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|███████████████████████████████████████████████████████████████████           | 1400/1628 [07:45<01:14,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400/1628) Data: 0.007s | Batch: 0.333s | Total: 0:07:45 | ETA: 0:01:15 | Loss: 0.0080 | top1:  90.7665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|███████████████████████████████████████████████████████████████████████▊      | 1500/1628 [08:18<00:43,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500/1628) Data: 0.007s | Batch: 0.332s | Total: 0:08:18 | ETA: 0:00:45 | Loss: 0.0080 | top1:  90.7627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|████████████████████████████████████████████████████████████████████████████▋ | 1600/1628 [08:53<00:10,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600/1628) Data: 0.006s | Batch: 0.334s | Total: 0:08:53 | ETA: 0:00:11 | Loss: 0.0080 | top1:  90.7528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1628/1628 [09:03<00:00,  2.99it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 199/199 [00:26<00:00,  7.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(199/199) Data: 0.035s | Batch: 0.133s | Total: 0:00:26 | ETA: 0:00:01 | Loss: 0.0063 | top1:  91.9137\n",
      "=> saving checkpoint 'checkpoints\\checkpoint.pth.tar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/1628 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [11 | 80] LR: 0.0100000000000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████▊                                                                          | 100/1628 [00:39<08:12,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100/1628) Data: 0.085s | Batch: 0.399s | Total: 0:00:39 | ETA: 0:07:55 | Loss: 0.0083 | top1:  90.4437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████████▋                                                                     | 200/1628 [01:14<07:57,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200/1628) Data: 0.043s | Batch: 0.371s | Total: 0:01:14 | ETA: 0:08:32 | Loss: 0.0083 | top1:  90.4119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|██████████████▌                                                                | 300/1628 [01:48<07:47,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300/1628) Data: 0.029s | Batch: 0.361s | Total: 0:01:48 | ETA: 0:07:22 | Loss: 0.0082 | top1:  90.5919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████████████▍                                                           | 400/1628 [02:21<07:07,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400/1628) Data: 0.022s | Batch: 0.355s | Total: 0:02:21 | ETA: 0:06:59 | Loss: 0.0082 | top1:  90.5981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|████████████████████████▎                                                      | 500/1628 [02:54<06:07,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500/1628) Data: 0.018s | Batch: 0.348s | Total: 0:02:54 | ETA: 0:05:58 | Loss: 0.0082 | top1:  90.6118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|█████████████████████████████                                                  | 600/1628 [03:27<06:08,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600/1628) Data: 0.015s | Batch: 0.346s | Total: 0:03:27 | ETA: 0:05:36 | Loss: 0.0081 | top1:  90.6425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|█████████████████████████████████▉                                             | 700/1628 [04:00<04:53,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700/1628) Data: 0.013s | Batch: 0.344s | Total: 0:04:00 | ETA: 0:04:59 | Loss: 0.0081 | top1:  90.6532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|██████████████████████████████████████▍                                        | 791/1628 [04:30<04:23,  3.17it/s]"
     ]
    }
   ],
   "source": [
    "# config.epoch = 1\n",
    "#model = create_model(device)\n",
    "dataloaders, attribute_names = load_dataloaders()\n",
    "criterion = get_criterion()\n",
    "#optimizer = get_optimizer(model)\n",
    "\n",
    "print(f\"=> Training model: {not config.evaluate}\")\n",
    "if config.evaluate:\n",
    "    best_prec1, model = load_inference_model(device, config.bestmodel_fname) # checkpoint_fname bestmodel_fname\n",
    "    test_loss, prec1, top1 = validate(dataloaders['test'], model, criterion)\n",
    "    print(f\"=> Best test accuracy: {prec1}, Model val acc: {best_prec1}\")\n",
    "    attr_acc = print_attribute_acc(top1, attribute_names)\n",
    "    if config.test_preds_fname:\n",
    "        json.dump(attr_acc, open(config.test_preds_fname,'w'))\n",
    "else:\n",
    "    best_prec1, model_timer, lr, start_epoch, logger, model, optimizer = resume_checkpoint(device, config.ckp_logger_fname, config.ckp_resume)\n",
    "    run_name, run_time = get_run_name_time(model, criterion, optimizer, comments, start_epoch)\n",
    "    mtimer = trainer(dataloaders, model, criterion, optimizer, logger, start_epoch, best_prec1, run_name, model_timer)\n",
    "    print(f\"=> Model trained time: {mtimer}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not config.evaluate:\n",
    "    config.evaluate = True\n",
    "    #model = create_model(device)\n",
    "    dataloaders, attribute_names = load_dataloaders()\n",
    "    criterion = get_criterion()\n",
    "    #optimizer = get_optimizer(model)\n",
    "    \n",
    "    best_prec1, model = load_inference_model(device, config.bestmodel_fname) # checkpoint_fname bestmodel_fname\n",
    "    #best_prec1, mtimer, _, _, logger, = resume_checkpoint(model, optimizer, config.ckp_logger_fname, config.checkpoint_fname)\n",
    "    test_loss, prec1, top1 = validate(dataloaders['test'], model, criterion)\n",
    "    print(f\"=> Best test accuracy: {prec1}, Model val acc: {best_prec1}\")\n",
    "    attr_acc = print_attribute_acc(top1, attribute_names)\n",
    "    if config.test_preds_fname:\n",
    "        json.dump(attr_acc, open(config.test_preds_fname,'w'))\n",
    "#     best_prec1, mtimer, _, _, _, = resume_checkpoint(model, optimizer, config.ckp_logger_fname, config.bestmodel_fname)# config.bestmodel_fname  config.checkpoint_fname\n",
    "#     #print(model)\n",
    "#     test_loss, prec1, top1 = validate(dataloaders['test'], model, criterion)\n",
    "#     print(f\"=> Best test accuracy: {prec1}, Model val acc: {best_prec1}\")\n",
    "#     print_attribute_acc(top1, attribute_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save & Backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ISJUPYTER:\n",
    "    # Wait for notebook to save\n",
    "    %autosave 1\n",
    "    time.sleep(150)\n",
    "    %autosave 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backup_everything(run_time, run_name, title, backup_nb=ISJUPYTER):\n",
    "    # backup checkpoints\n",
    "    print(f\"=> backing up checkpoints... \")\n",
    "    run_dir = os.path.join(config.BACKUP_DIR, run_name, run_time)\n",
    "    create_dir_ifne(run_dir)\n",
    "    fromDirectory = config.CHECKPOINT_DIR\n",
    "    toDirectory = run_dir\n",
    "    copy_tree(fromDirectory, toDirectory)\n",
    "    \n",
    "    if backup_nb:\n",
    "        print(f\"=> backing up notebook... \")\n",
    "        # backup notebook html\n",
    "        nb_name = title + '.ipynb'\n",
    "        html_name = title + '.html'\n",
    "        save_name = os.path.join(run_dir, html_name)\n",
    "        !jupyter nbconvert --to html $nb_name\n",
    "        shutil.move(html_name, save_name)\n",
    "    \n",
    "backup_everything(run_time, run_name, title, backup_nb=ISJUPYTER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.auto_hibernate and False:\n",
    "    os.system('shutdown -h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOYWQroywTLOsSvW/4lPmBg",
   "collapsed_sections": [],
   "name": "ai6126-project1-colab-v0.1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
