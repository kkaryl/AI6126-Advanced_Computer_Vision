{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UVAZt6s-Fu41"
   },
   "source": [
    "# AI6126 ACV Project 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 1038,
     "status": "ok",
     "timestamp": 1601175331072,
     "user": {
      "displayName": "Jia Hui Ong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKvHQmYQfzydylrU8HXZxYxJP3L6kGAQ94P-sS=s64",
      "userId": "05957301376516334331"
     },
     "user_tz": -480
    },
    "id": "jzjCg15BeR43"
   },
   "outputs": [],
   "source": [
    "nb_ver = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true"
   },
   "source": [
    "## Versioning & References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true",
    "id": "4c2s81g4d5PE"
   },
   "source": [
    "### Changelogs\n",
    "+ V0.1 - Setup codes to download and unzip celeba to gDrive\n",
    "+ V0.2 - Added training loop \n",
    "+ V0.3 - Added seeding + save/ load checkpoint (doing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true"
   },
   "source": [
    "### References\n",
    "+ [PyTorch Transfer Learning](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html)\n",
    "+ [TWD fast.ai](https://towardsdatascience.com/real-time-multi-facial-attribute-detection-using-transfer-learning-and-haar-cascades-with-fastai-47ff59e36df0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true",
    "id": "UmjjrIheF0u5"
   },
   "source": [
    "## Setup/ Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true"
   },
   "source": [
    "### Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "executionInfo": {
     "elapsed": 4455,
     "status": "error",
     "timestamp": 1601175336681,
     "user": {
      "displayName": "Jia Hui Ong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKvHQmYQfzydylrU8HXZxYxJP3L6kGAQ94P-sS=s64",
      "userId": "05957301376516334331"
     },
     "user_tz": -480
    },
    "id": "7mTWwwivDNy3",
    "outputId": "9f87be63-e615-42bf-b306-8a2ec7e2458d"
   },
   "outputs": [],
   "source": [
    "# you can choose to mount your Google Drive (optional)\n",
    "import sys, os\n",
    "if 'google.colab' in sys.modules:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    file_name = f'ai6126-project1-colab-v{nb_ver}.ipynb'\n",
    "    print(file_name)\n",
    "    import subprocess\n",
    "    path_to_file = subprocess.check_output('find . -type f -name ' + str(file_name), shell=True).decode(\"utf-8\")\n",
    "    print(path_to_file)\n",
    "    path_to_file = path_to_file.replace(file_name,\"\").replace('\\n',\"\")\n",
    "    os.chdir(path_to_file)\n",
    "    !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "executionInfo": {
     "elapsed": 4089,
     "status": "ok",
     "timestamp": 1601174827944,
     "user": {
      "displayName": "Jia Hui Ong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKvHQmYQfzydylrU8HXZxYxJP3L6kGAQ94P-sS=s64",
      "userId": "05957301376516334331"
     },
     "user_tz": -480
    },
    "id": "x6grHtmwDexI",
    "outputId": "60e6ef2d-3b03-486f-e7cc-a87eaa29da82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2019 NVIDIA Corporation\n",
      "Built on Wed_Oct_23_19:32:27_Pacific_Daylight_Time_2019\n",
      "Cuda compilation tools, release 10.2, V10.2.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'gcc' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# check nvcc version\n",
    "!nvcc -V\n",
    "# check GCC version\n",
    "!gcc --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true"
   },
   "source": [
    "### Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download celeba dataset: False\n"
     ]
    }
   ],
   "source": [
    "import os, glob\n",
    "local_download_path = '../data/celeba/img_align_celeba'\n",
    "download_dataset = True\n",
    "if os.path.exists(local_download_path):\n",
    "    images = glob.glob(local_download_path + '/*.jpg')\n",
    "    if len(images) == 202599:\n",
    "        download_dataset = False\n",
    "print(f\"download celeba dataset: {download_dataset}\")\n",
    "\n",
    "if download_dataset:\n",
    "    # create dataset root and enter it\n",
    "    !mkdir -p data/celeba\n",
    "    %cd data/celeba\n",
    "\n",
    "    # we have prepared a backup of `img_align_celeba.zip` of Celeb-A dataset in the Dropbox\n",
    "    # download it directly, or manually download the original file from Google Drive above\n",
    "    !wget https://www.dropbox.com/s/8kzo40fqx7nodat/img_align_celeba.zip\n",
    "\n",
    "    # unzip the downloaded file\n",
    "    !unzip -qq img_align_celeba.zip\n",
    "    !rm -f img_align_celeba.zip\n",
    "\n",
    "    # change the directory back to the root\n",
    "    %cd ../..\n",
    "    !ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "tEkTpN_qDN5u"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "# from torchsummary import summary \n",
    "\n",
    "import config\n",
    "from celeba_dataset import CelebaDataset\n",
    "import models\n",
    "from utils import Logger, AverageMeter, Bar, savefig, adjust_learning_rate, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "DCjPfxzUDN3Y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.0 True\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# set the backend of matplotlib to the 'inline' backend\n",
    "%matplotlib inline\n",
    "\n",
    "# check PyTorch version and cuda status\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "\n",
    "# define device\n",
    "device = torch.device(\"cuda:\"+config.gpu_id if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "executionInfo": {
     "elapsed": 4483,
     "status": "ok",
     "timestamp": 1601174828368,
     "user": {
      "displayName": "Jia Hui Ong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKvHQmYQfzydylrU8HXZxYxJP3L6kGAQ94P-sS=s64",
      "userId": "05957301376516334331"
     },
     "user_tz": -480
    },
    "id": "9Te1EuMyDN7-",
    "outputId": "e1a9321b-0c11-476e-dea5-57b3fa33f732"
   },
   "outputs": [],
   "source": [
    "# set random seed for reproducibility\n",
    "def seed_everything(seed=None):\n",
    "    if seed is None:\n",
    "        seed = random.randint(1, 10000) # create random seed\n",
    "        print(f'random seed used: {seed}')\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    if 'torch' in sys.modules:\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "seed_everything(seed=config.manual_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 7867,
     "status": "ok",
     "timestamp": 1601174831763,
     "user": {
      "displayName": "Jia Hui Ong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKvHQmYQfzydylrU8HXZxYxJP3L6kGAQ94P-sS=s64",
      "userId": "05957301376516334331"
     },
     "user_tz": -480
    },
    "id": "UeTJbZQ5b_ea",
    "outputId": "de5f0be8-65fe-4648-e719-ff92f2642235",
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "### Data Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset sizes: {'train': 162770, 'val': 19867}\n",
      "Class Labels: 40\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation and testing\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "if config.evaluate:\n",
    "    phases = ['test']\n",
    "else:\n",
    "    phases = ['train', 'val']\n",
    "\n",
    "attributes_list = {\n",
    "    'train': config.TRAIN_ATTRIBUTE_LIST,\n",
    "    'val': config.VAL_ATTRIBUTE_LIST,\n",
    "    'test': config.TEST_ATTRIBUTE_LIST\n",
    "}\n",
    "\n",
    "batch_sizes = {\n",
    "    'train': config.train_batch,\n",
    "    'val': config.test_batch,\n",
    "    'test': config.test_batch\n",
    "}\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ])\n",
    "}\n",
    "\n",
    "image_datasets = {x: CelebaDataset(config.IMG_DIR, attributes_list[x], \n",
    "                                   data_transforms[x]) \n",
    "                  for x in phases}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], \n",
    "                                              batch_size=batch_sizes[x],\n",
    "                                              pin_memory=True, shuffle=(x == 'train'), \n",
    "                                              num_workers=config.dl_workers) \n",
    "               for x in phases}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in phases}\n",
    "print(f\"Dataset sizes: {dataset_sizes}\")\n",
    "class_names = image_datasets['train'].targets\n",
    "print(f\"Class Labels: {len(class_names[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true",
    "id": "qtfDq7Z2F6Nh",
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "### Model Architecture Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Models: ['FaceAttrResNet']\n"
     ]
    }
   ],
   "source": [
    "model_names = sorted(name for name in models.__dict__\n",
    "                     if callable(models.__dict__[name])) # and name.islower() and not name.startswith(\"__\"))\n",
    "print(f\"Available Models: {model_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> creating model 'FaceAttrResNet'\n"
     ]
    }
   ],
   "source": [
    "print(\"=> creating model '{}'\".format(config.arch))\n",
    "if config.arch.startswith('FaceAttrResNet'):\n",
    "    model = models.__dict__[config.arch](resnet_layers = config.pt_layers)\n",
    "model = model.to(device)\n",
    "#print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true"
   },
   "source": [
    "### Criterion & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), config.lr,\n",
    "                            momentum=config.momentum,\n",
    "                            weight_decay=config.weight_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true"
   },
   "source": [
    "### Resume Checkpoint if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resume_checkpoint(model, optimizer, ckp_resume):\n",
    "    if not os.path.isdir(config.CHECKPOINT_DIR):\n",
    "        try: \n",
    "            os.makedirs(config.CHECKPOINT_DIR)\n",
    "        except OSError:\n",
    "            raise\n",
    "\n",
    "    if config.ckp_resume and os.path.isfile(ckp_resume): \n",
    "        model.load_ckp(optimizer, config.ckp_resume)\n",
    "        # print(f\"=> loading checkpoint '{config.resume}'\")\n",
    "        # checkpoint = torch.load(config.resume)\n",
    "        # start_epoch = checkpoint['epoch']\n",
    "        # best_prec1 = checkpoint['best_prec1']\n",
    "        # model.load_state_dict(checkpoint['state_dict'])\n",
    "        # optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        # print(f\"=> loaded checkpoint '{config.resume}' (epoch {start_epoch})\")\n",
    "        config.checkpoint = os.path.dirname(ckp_resume)\n",
    "        logger = Logger(config.ckp_logger_fname, title=model.name, resume=True)\n",
    "    else:\n",
    "        logger = Logger(config.ckp_logger_fname, title=model.name)\n",
    "        logger.set_names(['Learning Rate', 'Train Loss', 'Valid Loss', 'Train Acc.', 'Valid Acc.'])\n",
    "        start_epoch = 0\n",
    "        best_prec1 = 0\n",
    "        \n",
    "    return logger, best_prec1, start_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Validate Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer):\n",
    "    bar = Bar('Processing', max=len(train_loader))\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = [AverageMeter() for _ in range(40)]\n",
    "    top1 = [AverageMeter() for _ in range(40)]\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (X, y) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        # Overlapping transfer if pinned memory\n",
    "        X = X.to(device, non_blocking=True)\n",
    "        y = y.to(device, non_blocking=True)\n",
    "    \n",
    "        # compute output\n",
    "        output = model(X)\n",
    "        # measure accuracy and record loss\n",
    "        loss = []\n",
    "        prec1 = []\n",
    "        for j in range(len(output)):\n",
    "            loss.append(criterion(output[j], y[:, j]))\n",
    "            prec1.append(accuracy(output[j], y[:, j], topk=(1,)))\n",
    "\n",
    "            losses[j].update(loss[j].item(), X.size(0))\n",
    "            top1[j].update(prec1[j][0].item(), X.size(0))\n",
    "            \n",
    "        losses_avg = [losses[k].avg for k in range(len(losses))]\n",
    "        top1_avg = [top1[k].avg for k in range(len(top1))]\n",
    "        loss_avg = sum(losses_avg) / len(losses_avg)\n",
    "        prec1_avg = sum(top1_avg) / len(top1_avg)\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss_sum = sum(loss)\n",
    "        loss_sum.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # plot progress\n",
    "        bar.suffix  = '({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | Loss: {loss:.4f} | top1: {top1: .4f}'.format(\n",
    "                    batch=i + 1,\n",
    "                    size=len(train_loader),\n",
    "                    data=data_time.avg,\n",
    "                    bt=batch_time.avg,\n",
    "                    total=bar.elapsed_td,\n",
    "                    eta=bar.eta_td,\n",
    "                    loss=loss_avg,\n",
    "                    top1=prec1_avg,\n",
    "                    )\n",
    "        bar.next()\n",
    "    bar.finish()\n",
    "    return (loss_avg, prec1_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion):\n",
    "    bar = Bar('Processing', max=len(val_loader))\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = [AverageMeter() for _ in range(40)]\n",
    "    top1 = [AverageMeter() for _ in range(40)]\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (X, y) in enumerate(val_loader):\n",
    "            # measure data loading time\n",
    "            data_time.update(time.time() - end)\n",
    "\n",
    "            # Overlapping transfer if pinned memory\n",
    "            X = X.to(device, non_blocking=True)\n",
    "            y = y.to(device, non_blocking=True)\n",
    "\n",
    "            # compute output\n",
    "            output = model(X)\n",
    "            # measure accuracy and record loss\n",
    "            loss = []\n",
    "            prec1 = []\n",
    "            for j in range(len(output)):\n",
    "                loss.append(criterion(output[j], y[:, j]))\n",
    "                prec1.append(accuracy(output[j], y[:, j], topk=(1,)))\n",
    "\n",
    "                losses[j].update(loss[j].item(), X.size(0))\n",
    "                top1[j].update(prec1[j][0].item(), X.size(0))\n",
    "            losses_avg = [losses[k].avg for k in range(len(losses))]\n",
    "            top1_avg = [top1[k].avg for k in range(len(top1))]\n",
    "            loss_avg = sum(losses_avg) / len(losses_avg)\n",
    "            prec1_avg = sum(top1_avg) / len(top1_avg)\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "        # plot progress\n",
    "        bar.suffix  = '({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | Loss: {loss:.4f} | top1: {top1: .4f}'.format(\n",
    "                    batch=i + 1,\n",
    "                    size=len(val_loader),\n",
    "                    data=data_time.avg,\n",
    "                    bt=batch_time.avg,\n",
    "                    total=bar.elapsed_td,\n",
    "                    eta=bar.eta_td,\n",
    "                    loss=loss_avg,\n",
    "                    top1=prec1_avg,\n",
    "                    )\n",
    "        bar.next()\n",
    "    bar.finish()\n",
    "    return (loss_avg, prec1_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(dataloaders, model, criterion, optimizer, start_epoch, best_prec1):\n",
    "    # visualization\n",
    "    writer = SummaryWriter(config.tensorboard_dir)\n",
    "\n",
    "    for epoch in range(start_epoch, config.epochs):\n",
    "        lr = adjust_learning_rate(optimizer, config.lr_decay, epoch, gamma=config.gamma, step=config.step,\n",
    "                                 total_epochs=config.epochs, turning_point=config.turning_point,\n",
    "                                 schedule=config.schedule)\n",
    "\n",
    "        print('\\nEpoch: [%d | %d] LR: %f' % (epoch + 1, config.epochs, lr))\n",
    "\n",
    "        # train for one epoch\n",
    "        train_loss, train_acc = train(dataloaders['train'], model, criterion, optimizer)\n",
    "\n",
    "        # evaluate on validation set\n",
    "        val_loss, prec1 = validate(dataloaders['val'], model, criterion)\n",
    "\n",
    "        # append logger file\n",
    "        logger.append([lr, train_loss, val_loss, train_acc, prec1])\n",
    "\n",
    "        # tensorboardX\n",
    "        writer.add_scalar('learning rate', lr, epoch + 1)\n",
    "        writer.add_scalars('loss', {'train loss': train_loss, 'validation loss': val_loss}, epoch + 1)\n",
    "        writer.add_scalars('accuracy', {'train accuracy': train_acc, 'validation accuracy': prec1}, epoch + 1)\n",
    "        #for name, param in model.named_parameters():\n",
    "        #    writer.add_histogram(name, param.clone().cpu().data.numpy(), epoch + 1)\n",
    "\n",
    "        is_best = prec1 > best_prec1\n",
    "        best_prec1 = max(prec1, best_prec1)\n",
    "        print(f'saving checkpoint: \"{config.checkpoint_fname}\"')\n",
    "        model.save_ckp({\n",
    "            'epoch': epoch + 1,\n",
    "            'arch': model.name,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'best_prec1': best_prec1,\n",
    "            'optimizer' : optimizer.state_dict()\n",
    "        }, is_best, config.checkpoint_fname,config.bestmodel_fname)\n",
    "\n",
    "    logger.close()\n",
    "    logger.plot()\n",
    "    savefig(config.train_plotfig)\n",
    "    writer.close()\n",
    "\n",
    "    print('Best accuracy:')\n",
    "    print(best_prec1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "PWCHnDeVD4WT",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [1 | 1] LR: 0.100000\n",
      "saving checkpoint: \"checkpoints\\checkpoint.pth.tar\"\n",
      "=> saving checkpoint 'checkpoints\\checkpoint.pth.tar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.backends.backend_ps:The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "WARNING:matplotlib.backends.backend_ps:The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy:\n",
      "83.11131524383472\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "config.epochs = 1\n",
    "logger, best_prec1, start_epoch = resume_checkpoint(model, optimizer, config.ckp_resume)\n",
    "if config.evaluate:\n",
    "    test_loss, prec1 = validate(dataloaders['test'], model, criterion)\n",
    "    print(f\"=> Best test accuracy: {prec1}, Model val acc: {best_prec1}\")\n",
    "else:\n",
    "    trainer(dataloaders, model, criterion, optimizer, start_epoch, best_prec1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOYWQroywTLOsSvW/4lPmBg",
   "collapsed_sections": [],
   "name": "ai6126-project1-colab-v0.1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
