{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UVAZt6s-Fu41"
   },
   "source": [
    "# AI6126 ACV Project 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 1038,
     "status": "ok",
     "timestamp": 1601175331072,
     "user": {
      "displayName": "Jia Hui Ong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKvHQmYQfzydylrU8HXZxYxJP3L6kGAQ94P-sS=s64",
      "userId": "05957301376516334331"
     },
     "user_tz": -480
    },
    "id": "jzjCg15BeR43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ai6126-project1-colab-v0.8\n",
      "adam\n"
     ]
    }
   ],
   "source": [
    "nb_ver = 0.8\n",
    "title = f'ai6126-project1-colab-v{nb_ver}'\n",
    "print(title)\n",
    "comments = \"adam\"\n",
    "print(comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Versioning & References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4c2s81g4d5PE"
   },
   "source": [
    "### Changelogs\n",
    "+ V0.1 - Setup codes to download and unzip celeba to gDrive\n",
    "+ V0.2 - Added training loop \n",
    "+ V0.3 - Added seeding + save/ load checkpoint\n",
    "+ V0.4 - Added time taken + save output\n",
    "+ V0.5 - Added RandomErasing to transforms\n",
    "+ V0.6 - Added get_criterion (BinaryFocalLoss) - NOT WORKING YET\n",
    "+ V0.7 - Added FaceAttrMobileNetV2 & FaceAttrResNeXt\n",
    "+ V0.8 - Added Albumentations\n",
    "+ V0.9 - Updated Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "+ [PyTorch Transfer Learning](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html)\n",
    "+ [TWD fast.ai](https://towardsdatascience.com/real-time-multi-facial-attribute-detection-using-transfer-learning-and-haar-cascades-with-fastai-47ff59e36df0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install pytorch torchvision cudatoolkit=10.2 -c pytorch\n",
    "# conda install matplotlib\n",
    "# conda install pandas\n",
    "# conda install tqdm\n",
    "# conda install -c conda-forge jupyterlab\n",
    "# conda install -c conda-forge tensorboard\n",
    "# conda install -c conda-forge protobuf # for tensorboard\n",
    "# conda install nb_conda_kernels # auto add kernels\n",
    "\n",
    "# conda install -c conda-forge imgaug\n",
    "# conda install albumentations -c conda-forge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UmjjrIheF0u5"
   },
   "source": [
    "## Setup/ Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "executionInfo": {
     "elapsed": 4455,
     "status": "error",
     "timestamp": 1601175336681,
     "user": {
      "displayName": "Jia Hui Ong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKvHQmYQfzydylrU8HXZxYxJP3L6kGAQ94P-sS=s64",
      "userId": "05957301376516334331"
     },
     "user_tz": -480
    },
    "id": "7mTWwwivDNy3",
    "outputId": "9f87be63-e615-42bf-b306-8a2ec7e2458d"
   },
   "outputs": [],
   "source": [
    "# you can choose to mount your Google Drive (optional)\n",
    "import sys, os\n",
    "if 'google.colab' in sys.modules:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    file_name = f'ai6126-project1-colab-v{nb_ver}.ipynb'\n",
    "    print(file_name)\n",
    "    import subprocess\n",
    "    path_to_file = subprocess.check_output('find . -type f -name ' + str(file_name), shell=True).decode(\"utf-8\")\n",
    "    print(path_to_file)\n",
    "    path_to_file = path_to_file.replace(file_name,\"\").replace('\\n',\"\")\n",
    "    os.chdir(path_to_file)\n",
    "    !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "executionInfo": {
     "elapsed": 4089,
     "status": "ok",
     "timestamp": 1601174827944,
     "user": {
      "displayName": "Jia Hui Ong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKvHQmYQfzydylrU8HXZxYxJP3L6kGAQ94P-sS=s64",
      "userId": "05957301376516334331"
     },
     "user_tz": -480
    },
    "id": "x6grHtmwDexI",
    "outputId": "60e6ef2d-3b03-486f-e7cc-a87eaa29da82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2019 NVIDIA Corporation\n",
      "Built on Sun_Jul_28_19:12:52_Pacific_Daylight_Time_2019\n",
      "Cuda compilation tools, release 10.1, V10.1.243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'gcc' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# check nvcc version\n",
    "!nvcc -V\n",
    "# check GCC version\n",
    "!gcc --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download celeba dataset: False\n"
     ]
    }
   ],
   "source": [
    "import os, glob\n",
    "local_download_path = '../data/celeba/img_align_celeba'\n",
    "download_dataset = True\n",
    "if os.path.exists(local_download_path):\n",
    "    images = glob.glob(local_download_path + '/*.jpg')\n",
    "    if len(images) == 202599:\n",
    "        download_dataset = False\n",
    "print(f\"download celeba dataset: {download_dataset}\")\n",
    "\n",
    "if download_dataset:\n",
    "    # create dataset root and enter it\n",
    "    !mkdir -p data/celeba\n",
    "    %cd data/celeba\n",
    "\n",
    "    # we have prepared a backup of `img_align_celeba.zip` of Celeb-A dataset in the Dropbox\n",
    "    # download it directly, or manually download the original file from Google Drive above\n",
    "    !wget https://www.dropbox.com/s/8kzo40fqx7nodat/img_align_celeba.zip\n",
    "\n",
    "    # unzip the downloaded file\n",
    "    !unzip -qq img_align_celeba.zip\n",
    "    !rm -f img_align_celeba.zip\n",
    "\n",
    "    # change the directory back to the root\n",
    "    %cd ../..\n",
    "    !ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "tEkTpN_qDN5u"
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import copy\n",
    "from datetime import datetime\n",
    "from distutils.dir_util import copy_tree #for recursive filecopying\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import config\n",
    "from celeba_dataset import CelebaDataset\n",
    "import models\n",
    "import losses\n",
    "from utils import Logger, AverageMeter, Bar, savefig, adjust_learning_rate, accuracy, reset_gpu_cache, print_attribute_acc, create_dir_ifne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "DCjPfxzUDN3Y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.0 True\n",
      "cuda:0\n",
      "disable_tqdm: False\n"
     ]
    }
   ],
   "source": [
    "# set the backend of matplotlib to the 'inline' backend\n",
    "%matplotlib inline\n",
    "\n",
    "# check PyTorch version and cuda status\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "\n",
    "# define device\n",
    "device = torch.device(\"cuda:\"+config.gpu_id if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "if 'ipykernel' in sys.modules:\n",
    "    config.disable_tqdm = False\n",
    "print(f\"disable_tqdm: {config.disable_tqdm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "executionInfo": {
     "elapsed": 4483,
     "status": "ok",
     "timestamp": 1601174828368,
     "user": {
      "displayName": "Jia Hui Ong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKvHQmYQfzydylrU8HXZxYxJP3L6kGAQ94P-sS=s64",
      "userId": "05957301376516334331"
     },
     "user_tz": -480
    },
    "id": "9Te1EuMyDN7-",
    "outputId": "e1a9321b-0c11-476e-dea5-57b3fa33f732"
   },
   "outputs": [],
   "source": [
    "# set random seed for reproducibility\n",
    "def seed_everything(seed=None):\n",
    "    if seed is None:\n",
    "        seed = random.randint(1, 10000) # create random seed\n",
    "        print(f'random seed used: {seed}')\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    if 'torch' in sys.modules:\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "seed_everything(seed=config.manual_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "collapsed": "true",
    "executionInfo": {
     "elapsed": 7867,
     "status": "ok",
     "timestamp": 1601174831763,
     "user": {
      "displayName": "Jia Hui Ong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKvHQmYQfzydylrU8HXZxYxJP3L6kGAQ94P-sS=s64",
      "userId": "05957301376516334331"
     },
     "user_tz": -480
    },
    "id": "UeTJbZQ5b_ea",
    "outputId": "de5f0be8-65fe-4648-e719-ff92f2642235",
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "### Data Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attribute_names = ['5_o_Clock_Shadow', 'Arched_Eyebrows', 'Attractive', 'Bags_Under_Eyes', 'Bald', \n",
    "#                    'Bangs', 'Big_Lips', 'Big_Nose', 'Black_Hair', 'Blond_Hair', 'Blurry', 'Brown_Hair', \n",
    "#                    'Bushy_Eyebrows', 'Chubby', 'Double_Chin', 'Eyeglasses', 'Goatee', 'Gray_Hair',\n",
    "#                    'Heavy_Makeup', 'High_Cheekbones', 'Male', 'Mouth_Slightly_Open', 'Mustache', \n",
    "#                    'Narrow_Eyes', 'No_Beard', 'Oval_Face', 'Pale_Skin', 'Pointy_Nose', 'Receding_Hairline',\n",
    "#                    'Rosy_Cheeks', 'Sideburns', 'Smiling', 'Straight_Hair', 'Wavy_Hair', 'Wearing_Earrings', \n",
    "#                    'Wearing_Hat', 'Wearing_Lipstick', 'Wearing_Necklace', 'Wearing_Necktie', 'Young']\n",
    "# print(attribute_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation and testing\n",
    "\n",
    "def load_dataloaders(print_info=True, albu_transforms = True):\n",
    "    if config.evaluate:\n",
    "        phases = ['test']\n",
    "    else:\n",
    "        phases = ['train', 'val']\n",
    "\n",
    "    attribute_names = ['5_o_Clock_Shadow', 'Arched_Eyebrows', 'Attractive', 'Bags_Under_Eyes', 'Bald', \n",
    "                       'Bangs', 'Big_Lips', 'Big_Nose', 'Black_Hair', 'Blond_Hair', 'Blurry', 'Brown_Hair', \n",
    "                       'Bushy_Eyebrows', 'Chubby', 'Double_Chin', 'Eyeglasses', 'Goatee', 'Gray_Hair',\n",
    "                       'Heavy_Makeup', 'High_Cheekbones', 'Male', 'Mouth_Slightly_Open', 'Mustache', \n",
    "                       'Narrow_Eyes', 'No_Beard', 'Oval_Face', 'Pale_Skin', 'Pointy_Nose', 'Receding_Hairline',\n",
    "                       'Rosy_Cheeks', 'Sideburns', 'Smiling', 'Straight_Hair', 'Wavy_Hair', 'Wearing_Earrings', \n",
    "                       'Wearing_Hat', 'Wearing_Lipstick', 'Wearing_Necklace', 'Wearing_Necktie', 'Young']\n",
    "    \n",
    "    attributes_list = {\n",
    "        'train': config.TRAIN_ATTRIBUTE_LIST,\n",
    "        'val': config.VAL_ATTRIBUTE_LIST,\n",
    "        'test': config.TEST_ATTRIBUTE_LIST\n",
    "    }\n",
    "\n",
    "    batch_sizes = {\n",
    "        'train': config.train_batch,\n",
    "        'val': config.test_batch,\n",
    "        'test': config.test_batch\n",
    "    }\n",
    "\n",
    "    if not albu_transforms:\n",
    "        normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                                         std=[0.229, 0.224, 0.225])\n",
    "        data_transforms = {\n",
    "            'train': transforms.Compose([\n",
    "                transforms.Resize(128), #new\n",
    "                transforms.CenterCrop(128), #new\n",
    "                transforms.RandomHorizontalFlip(p=0.5),\n",
    "                transforms.RandomRotation(degrees=10), #new\n",
    "                transforms.ToTensor(),\n",
    "                normalize,\n",
    "                transforms.RandomErasing()\n",
    "            ]),\n",
    "            'val': transforms.Compose([\n",
    "                transforms.Resize(128), #new\n",
    "                transforms.ToTensor(),\n",
    "                normalize\n",
    "            ]),\n",
    "            'test': transforms.Compose([\n",
    "                transforms.Resize(128), #new\n",
    "                transforms.ToTensor(),\n",
    "                normalize\n",
    "            ])\n",
    "        }\n",
    "    else:\n",
    "        normalize_A = A.Normalize(mean=(0.485, 0.456, 0.406), \n",
    "                                  std=(0.229, 0.224, 0.225))\n",
    "        data_transforms = {\n",
    "            'train': A.Compose(\n",
    "            [\n",
    "                A.SmallestMaxSize(max_size=160),\n",
    "                A.HorizontalFlip(p=0.5),\n",
    "                A.MotionBlur(p=0.1),\n",
    "                A.GaussNoise(p=0.5),\n",
    "                A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, \n",
    "                                   rotate_limit=15, p=0.5),\n",
    "                A.RandomBrightnessContrast(p=0.5),\n",
    "                #A.CoarseDropout(),\n",
    "                normalize_A,\n",
    "                ToTensorV2(),\n",
    "                \n",
    "            ]),\n",
    "            'val': A.Compose(\n",
    "                [\n",
    "                    A.SmallestMaxSize(max_size=160),\n",
    "                    #A.CenterCrop(height=128, width=128),\n",
    "                    normalize_A,\n",
    "                    ToTensorV2(),\n",
    "                ]\n",
    "            ),\n",
    "            'test': A.Compose([\n",
    "                A.SmallestMaxSize(max_size=160),\n",
    "                #A.CenterCrop(height=128, width=128),\n",
    "                normalize_A,\n",
    "                ToTensorV2(),\n",
    "            ])\n",
    "        }\n",
    "\n",
    "    image_datasets = {x: CelebaDataset(config.IMG_DIR, attributes_list[x], \n",
    "                                       data_transforms[x]) \n",
    "                      for x in phases}\n",
    "    dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], \n",
    "                                                  batch_size=batch_sizes[x],\n",
    "                                                  pin_memory=True, shuffle=(x == 'train'), \n",
    "                                                  num_workers=config.dl_workers) \n",
    "                   for x in phases}\n",
    "    if print_info:\n",
    "        dataset_sizes = {x: len(image_datasets[x]) for x in phases}\n",
    "        print(f\"Dataset sizes: {dataset_sizes}\")\n",
    "        \n",
    "    if config.evaluate:\n",
    "        class_names = image_datasets['test'].targets\n",
    "    else:\n",
    "        class_names = image_datasets['train'].targets\n",
    "    print(f\"Class Labels: {len(class_names[0])}\")\n",
    "    assert len(attribute_names) == len(class_names[0])\n",
    "    return dataloaders, attribute_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qtfDq7Z2F6Nh",
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "### Model Architecture Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Models: ['FaceAttrMobileNetV2', 'FaceAttrResNeXt', 'FaceAttrResNet']\n"
     ]
    }
   ],
   "source": [
    "model_names = sorted(name for name in models.__dict__\n",
    "                     if callable(models.__dict__[name])) # and name.islower() and not name.startswith(\"__\"))\n",
    "print(f\"Available Models: {model_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(device):\n",
    "    print(\"=> creating model '{}'\".format(config.arch))\n",
    "    if config.arch.startswith('FaceAttrResNet'):\n",
    "        model = models.__dict__[config.arch](resnet_layers = config.pt_layers)\n",
    "    elif config.arch.startswith('FaceAttrResNeXt'):\n",
    "        model = models.__dict__[config.arch](resnet_layers = config.pt_layers)\n",
    "    elif config.arch.startswith('FaceAttrMobileNetV2'):\n",
    "        model = models.__dict__[config.arch]()\n",
    "    #print(model)\n",
    "    model = model.to(device)\n",
    "    return model\n",
    "#print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criterion & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def get_criterion():\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    if config.criterion == 'BinaryFocalLoss':\n",
    "        criterion = losses.BinaryFocalLoss().to(device)\n",
    "    elif config.criterion == 'FocalLoss':\n",
    "        criterion = losses.FocalLossV2().to(device)\n",
    "    return criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(model):\n",
    "    optimizer = torch.optim.SGD(model.parameters(), config.lr,\n",
    "                            momentum=config.momentum,\n",
    "                            weight_decay=config.weight_decay)\n",
    "    if config.optimizer == 'Adam':\n",
    "        optimizer = torch.optim.Adam(model.parameters(), config.lr,\n",
    "                            weight_decay=config.weight_decay)\n",
    "    elif config.optimizer == 'AdamW':\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), config.lr,\n",
    "                            weight_decay=config.weight_decay)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true"
   },
   "source": [
    "### Resume Checkpoint if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resume_checkpoint(model, optimizer, ckp_logger_fname, ckp_resume=None):\n",
    "    if not os.path.isdir(config.CHECKPOINT_DIR):\n",
    "        try: \n",
    "            os.makedirs(config.CHECKPOINT_DIR)\n",
    "        except OSError:\n",
    "            raise\n",
    "            \n",
    "    start_epoch = 0\n",
    "    best_prec1 = 0\n",
    "    if ckp_resume and os.path.isfile(ckp_resume): \n",
    "        print(f\"=> resuming model: {ckp_resume}\")\n",
    "        optimizer, start_epoch, best_prec1 = model.load_ckp(optimizer, ckp_resume)\n",
    "        config.checkpoint = os.path.dirname(ckp_resume)\n",
    "        logger = Logger(ckp_logger_fname, title=model.name, resume=True)\n",
    "    else:\n",
    "        logger = Logger(ckp_logger_fname, title=model.name)\n",
    "        logger.set_names(['Learning Rate', 'Train Loss', 'Valid Loss', 'Train Acc.', 'Valid Acc.'])\n",
    "        \n",
    "        \n",
    "    return best_prec1, start_epoch, logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Validate Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer):\n",
    "    bar = Bar('Processing', max=len(train_loader))\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = [AverageMeter() for _ in range(40)]\n",
    "    top1 = [AverageMeter() for _ in range(40)]\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (X, y) in enumerate(tqdm(train_loader, disable=config.disable_tqdm)):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        # Overlapping transfer if pinned memory\n",
    "        X = X.to(device, non_blocking=True)\n",
    "        y = y.to(device, non_blocking=True)\n",
    "    \n",
    "        # compute output\n",
    "        output = model(X)\n",
    "        # measure accuracy and record loss\n",
    "        loss = []\n",
    "        prec1 = []\n",
    "        for j in range(len(output)): \n",
    "            # output[j]: [N,C] y[:,j]:[N]\n",
    "            # CE Criterion: [] scalar\n",
    "#             print(\"output s: \", output[j].shape)\n",
    "#             print(\"output y: \", y[:, j].shape)\n",
    "            crit = criterion(output[j], y[:, j])\n",
    "#             print(crit.detach())\n",
    "            loss.append(crit)\n",
    "            prec1.append(accuracy(output[j], y[:, j], topk=(1,)))\n",
    "            losses[j].update(loss[j].detach().item(), X.size(0))\n",
    "            top1[j].update(prec1[j][0].item(), X.size(0))\n",
    "            \n",
    "        losses_avg = [losses[k].avg for k in range(len(losses))]\n",
    "        top1_avg = [top1[k].avg for k in range(len(top1))]\n",
    "        loss_avg = sum(losses_avg) / len(losses_avg)\n",
    "        prec1_avg = sum(top1_avg) / len(top1_avg)\n",
    "\n",
    "        # compute gradient and do optimizer step\n",
    "        optimizer.zero_grad()\n",
    "        loss_sum = sum(loss)\n",
    "        loss_sum.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # plot progress\n",
    "        print_line = '({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | Loss: {loss:.4f} | top1: {top1: .4f}'.format(\n",
    "                        batch=i + 1,\n",
    "                        size=len(train_loader),\n",
    "                        data=data_time.avg,\n",
    "                        bt=batch_time.avg,\n",
    "                        total=bar.elapsed_td,\n",
    "                        eta=bar.eta_td,\n",
    "                        loss=loss_avg,\n",
    "                        top1=prec1_avg,\n",
    "                        )\n",
    "        if not config.disable_tqdm and (i+1)% 100 == 0:\n",
    "            print(print_line)\n",
    "        bar.suffix  = print_line\n",
    "        bar.next()\n",
    "    bar.finish()\n",
    "    return (loss_avg, prec1_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion):\n",
    "    bar = Bar('Processing', max=len(val_loader))\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = [AverageMeter() for _ in range(40)]\n",
    "    top1 = [AverageMeter() for _ in range(40)]\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (X, y) in enumerate(tqdm(val_loader, disable=config.disable_tqdm)):\n",
    "            # measure data loading time\n",
    "            data_time.update(time.time() - end)\n",
    "\n",
    "            # Overlapping transfer if pinned memory\n",
    "            X = X.to(device, non_blocking=True)\n",
    "            y = y.to(device, non_blocking=True)\n",
    "\n",
    "            # compute output\n",
    "            output = model(X)\n",
    "            # measure accuracy and record loss\n",
    "            loss = []\n",
    "            prec1 = []\n",
    "            for j in range(len(output)):\n",
    "                loss.append(criterion(output[j], y[:, j]))\n",
    "                prec1.append(accuracy(output[j], y[:, j], topk=(1,)))\n",
    "                \n",
    "                losses[j].update(loss[j].detach().item(), X.size(0))\n",
    "                top1[j].update(prec1[j][0].item(), X.size(0))\n",
    "            losses_avg = [losses[k].avg for k in range(len(losses))]\n",
    "            top1_avg = [top1[k].avg for k in range(len(top1))]\n",
    "            loss_avg = sum(losses_avg) / len(losses_avg)\n",
    "            prec1_avg = sum(top1_avg) / len(top1_avg)\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "            \n",
    "            # plot progress\n",
    "            print_line = '({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | Loss: {loss:.4f} | top1: {top1: .4f}'.format(\n",
    "                            batch=i + 1,\n",
    "                            size=len(val_loader),\n",
    "                            data=data_time.avg,\n",
    "                            bt=batch_time.avg,\n",
    "                            total=bar.elapsed_td,\n",
    "                            eta=bar.eta_td,\n",
    "                            loss=loss_avg,\n",
    "                            top1=prec1_avg,\n",
    "                            )\n",
    "\n",
    "            bar.suffix  = print_line\n",
    "            bar.next()  \n",
    "\n",
    "    if not config.disable_tqdm:\n",
    "        print(print_line)        \n",
    "    bar.finish()\n",
    "    return (loss_avg, prec1_avg, top1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(dataloaders, model, criterion, optimizer, logger, start_epoch, best_prec1, run_name):\n",
    "    # visualization\n",
    "    writer = SummaryWriter(os.path.join(config.tensorboard_dir, run_name))\n",
    "\n",
    "    for epoch in range(start_epoch, config.epochs):\n",
    "        lr = adjust_learning_rate(optimizer, config.lr_decay, epoch, gamma=config.gamma, step=config.step,\n",
    "                                 total_epochs=config.epochs, turning_point=config.turning_point,\n",
    "                                 schedule=config.schedule)\n",
    "\n",
    "        print('\\nEpoch: [%d | %d] LR: %.16f' % (epoch + 1, config.epochs, lr))\n",
    "\n",
    "        # train for one epoch\n",
    "        train_loss, train_acc = train(dataloaders['train'], model, criterion, optimizer)\n",
    "\n",
    "        # evaluate on validation set\n",
    "        val_loss, prec1, _ = validate(dataloaders['val'], model, criterion)\n",
    "\n",
    "        # append logger file\n",
    "        logger.append([lr, train_loss, val_loss, train_acc, prec1])\n",
    "\n",
    "        # tensorboardX\n",
    "        writer.add_scalar('learning rate', lr, epoch + 1)\n",
    "        writer.add_scalars('loss', {'train loss': train_loss, 'validation loss': val_loss}, epoch + 1)\n",
    "        writer.add_scalars('accuracy', {'train accuracy': train_acc, 'validation accuracy': prec1}, epoch + 1)\n",
    "        #for name, param in model.named_parameters():\n",
    "        #    writer.add_histogram(name, param.clone().cpu().data.numpy(), epoch + 1)\n",
    "\n",
    "        is_best = prec1 > best_prec1\n",
    "        best_prec1 = max(prec1, best_prec1)\n",
    "\n",
    "        model.save_ckp({\n",
    "            'epoch': epoch + 1,\n",
    "            'arch': model.name,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'best_prec1': best_prec1,\n",
    "            'optimizer' : optimizer.state_dict()\n",
    "        }, is_best, config.checkpoint_fname,config.bestmodel_fname)\n",
    "\n",
    "    logger.close()\n",
    "    logger.plot()\n",
    "    savefig(config.train_plotfig)\n",
    "    writer.close()\n",
    "\n",
    "    print('Best accuracy:')\n",
    "    print(best_prec1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_run_name_time(model, criterion, optimizer, comments):\n",
    "    try:\n",
    "        if criterion.name:\n",
    "            p_criterion = criterion.name\n",
    "    except:\n",
    "        p_criterion = 'CE'\n",
    "\n",
    "    p_optimizer = f'{str(optimizer).split(\"(\")[0].strip()}'\n",
    "    p_scheduler = f'{config.lr_decay}_lr{config.lr}_wd{config.weight_decay}'\n",
    "    if config.lr_decay == 'step':\n",
    "        p_scheduler += f'_g{config.gamma}_sp{config.step}'\n",
    "    elif config.lr_decay == 'linear2exp':\n",
    "        p_scheduler += f'_g{config.gamma}_tp{config.turning_point}'\n",
    "    elif config.lr_decay == 'schedule':\n",
    "        p_scheduler += f'_g{config.gamma}_sch{config.schedule}'\n",
    "\n",
    "    run_name = f'{model.name}_{config.manual_seed}_s{start_epoch}e{config.epochs}_' \\\n",
    "                + f'tb{config.train_batch}_vb{config.test_batch}_' \\\n",
    "                + f'{p_criterion}_{p_optimizer}_' \\\n",
    "                + f'{comments}_' \\\n",
    "                + f'{p_scheduler}'\n",
    "    \n",
    "    run_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    print(run_name, run_time)\n",
    "    return run_name, run_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PWCHnDeVD4WT",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> creating model 'FaceAttrResNet'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/636 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset sizes: {'train': 162770, 'val': 19867}\n",
      "Class Labels: 40\n",
      "FaceAttrResNet18_42_s0e50_tb256_vb128_CE_Adam_adam_step_lr0.1_wd0.0001_g0.1_sp30 20201005_155511\n",
      "\n",
      "Epoch: [1 | 50] LR: 0.1000000000000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████████▌                                                                   | 100/636 [01:14<04:54,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100/636) Data: 0.123s | Batch: 0.747s | Total: 0:01:14 | ETA: 0:04:56 | Loss: 0.6521 | top1:  79.8028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|█████████████████████████▏                                                      | 200/636 [02:09<03:59,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200/636) Data: 0.062s | Batch: 0.650s | Total: 0:02:09 | ETA: 0:04:00 | Loss: 0.5346 | top1:  80.6099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|█████████████████████████████████████▋                                          | 300/636 [03:05<03:03,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300/636) Data: 0.042s | Batch: 0.617s | Total: 0:03:05 | ETA: 0:03:06 | Loss: 0.4877 | top1:  81.2362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████████████████████████████████████████████████▎                             | 400/636 [04:00<02:11,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400/636) Data: 0.032s | Batch: 0.601s | Total: 0:04:00 | ETA: 0:02:12 | Loss: 0.4592 | top1:  81.7505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|██████████████████████████████████████████████████████████████▉                 | 500/636 [04:55<01:15,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500/636) Data: 0.026s | Batch: 0.591s | Total: 0:04:55 | ETA: 0:01:16 | Loss: 0.4398 | top1:  82.1640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|███████████████████████████████████████████████████████████████████████████▍    | 600/636 [05:50<00:19,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600/636) Data: 0.022s | Batch: 0.584s | Total: 0:05:50 | ETA: 0:00:21 | Loss: 0.4246 | top1:  82.5719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 636/636 [06:13<00:00,  1.70it/s]\n",
      " 64%|███████████████████████████████████████████████████▎                            | 100/156 [00:19<00:05,  9.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100/156) Data: 0.077s | Batch: 0.190s | Total: 0:00:19 | ETA: 0:00:07 | Loss: 9.9125 | top1:  83.7359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 156/156 [00:25<00:00,  6.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving checkpoint 'checkpoints\\checkpoint.pth.tar'\n",
      "=> saving best model 'checkpoints\\model_best.pth.tar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/636 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [2 | 50] LR: 0.1000000000000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████████▌                                                                   | 100/636 [01:07<04:56,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100/636) Data: 0.119s | Batch: 0.670s | Total: 0:01:07 | ETA: 0:04:55 | Loss: 0.3273 | top1:  85.8049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|█████████████████████████▏                                                      | 200/636 [02:02<04:00,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200/636) Data: 0.060s | Batch: 0.610s | Total: 0:02:02 | ETA: 0:03:59 | Loss: 0.3212 | top1:  86.0643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|█████████████████████████████████████▋                                          | 300/636 [02:57<03:04,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300/636) Data: 0.041s | Batch: 0.591s | Total: 0:02:57 | ETA: 0:03:05 | Loss: 0.3169 | top1:  86.2489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████████████████████████████████████████████████▎                             | 400/636 [03:52<02:09,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400/636) Data: 0.031s | Batch: 0.581s | Total: 0:03:52 | ETA: 0:02:11 | Loss: 0.3129 | top1:  86.4126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|██████████████████████████████████████████████████████████████▉                 | 500/636 [04:47<01:14,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500/636) Data: 0.025s | Batch: 0.574s | Total: 0:04:47 | ETA: 0:01:16 | Loss: 0.3098 | top1:  86.5412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|███████████████████████████████████████████████████████████████████████████▍    | 600/636 [05:42<00:19,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600/636) Data: 0.021s | Batch: 0.570s | Total: 0:05:42 | ETA: 0:00:21 | Loss: 0.3069 | top1:  86.6641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 636/636 [06:02<00:00,  1.75it/s]\n",
      " 65%|███████████████████████████████████████████████████▊                            | 101/156 [00:18<00:05,  9.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100/156) Data: 0.079s | Batch: 0.189s | Total: 0:00:18 | ETA: 0:00:06 | Loss: 0.5168 | top1:  81.3459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 156/156 [00:25<00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving checkpoint 'checkpoints\\checkpoint.pth.tar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/636 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [3 | 50] LR: 0.1000000000000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████████▌                                                                   | 100/636 [01:06<04:56,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100/636) Data: 0.119s | Batch: 0.669s | Total: 0:01:06 | ETA: 0:04:56 | Loss: 0.2896 | top1:  87.4086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|█████████████████████████▏                                                      | 200/636 [02:01<03:59,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200/636) Data: 0.060s | Batch: 0.609s | Total: 0:02:01 | ETA: 0:04:01 | Loss: 0.2883 | top1:  87.4773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|█████████████████████████████████████▋                                          | 300/636 [02:56<03:06,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300/636) Data: 0.041s | Batch: 0.589s | Total: 0:02:56 | ETA: 0:03:05 | Loss: 0.2869 | top1:  87.5364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████████████████████████████████████████████████▎                             | 400/636 [03:51<02:10,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400/636) Data: 0.031s | Batch: 0.579s | Total: 0:03:51 | ETA: 0:02:11 | Loss: 0.2858 | top1:  87.5904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|██████████████████████████████████████████████████████████████▉                 | 500/636 [04:46<01:14,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500/636) Data: 0.025s | Batch: 0.573s | Total: 0:04:46 | ETA: 0:01:16 | Loss: 0.2845 | top1:  87.6418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|███████████████████████████████████████████████████████████████████████████▍    | 600/636 [05:41<00:19,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600/636) Data: 0.021s | Batch: 0.569s | Total: 0:05:41 | ETA: 0:00:21 | Loss: 0.2838 | top1:  87.6685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 636/636 [06:01<00:00,  1.76it/s]\n",
      " 65%|███████████████████████████████████████████████████▊                            | 101/156 [00:18<00:06,  8.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100/156) Data: 0.082s | Batch: 0.188s | Total: 0:00:18 | ETA: 0:00:07 | Loss: 1.2216 | top1:  83.9799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 156/156 [00:25<00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving checkpoint 'checkpoints\\checkpoint.pth.tar'\n",
      "=> saving best model 'checkpoints\\model_best.pth.tar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/636 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [4 | 50] LR: 0.1000000000000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████████▌                                                                   | 100/636 [01:07<04:53,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100/636) Data: 0.125s | Batch: 0.670s | Total: 0:01:07 | ETA: 0:04:55 | Loss: 0.2776 | top1:  87.8676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|█████████████████████████▏                                                      | 200/636 [02:02<03:58,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200/636) Data: 0.063s | Batch: 0.611s | Total: 0:02:02 | ETA: 0:03:59 | Loss: 0.2773 | top1:  87.8911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|█████████████████████████████████████▋                                          | 300/636 [02:57<03:04,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300/636) Data: 0.043s | Batch: 0.591s | Total: 0:02:57 | ETA: 0:03:05 | Loss: 0.2766 | top1:  87.9460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████████████████████████████████████████████████▎                             | 400/636 [03:52<02:08,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400/636) Data: 0.033s | Batch: 0.580s | Total: 0:03:52 | ETA: 0:02:10 | Loss: 0.2761 | top1:  87.9736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|██████████████████████████████████████████████████████████████▉                 | 500/636 [04:46<01:14,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500/636) Data: 0.026s | Batch: 0.574s | Total: 0:04:46 | ETA: 0:01:16 | Loss: 0.2756 | top1:  87.9843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|███████████████████████████████████████████████████████████████████████████▍    | 600/636 [05:41<00:19,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600/636) Data: 0.022s | Batch: 0.569s | Total: 0:05:41 | ETA: 0:00:21 | Loss: 0.2754 | top1:  88.0034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 636/636 [06:02<00:00,  1.76it/s]\n",
      " 65%|███████████████████████████████████████████████████▊                            | 101/156 [00:18<00:05,  9.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100/156) Data: 0.083s | Batch: 0.189s | Total: 0:00:18 | ETA: 0:00:07 | Loss: 0.3627 | top1:  85.5799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 156/156 [00:25<00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving checkpoint 'checkpoints\\checkpoint.pth.tar'\n",
      "=> saving best model 'checkpoints\\model_best.pth.tar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/636 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [5 | 50] LR: 0.1000000000000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████████▌                                                                   | 100/636 [01:06<04:55,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100/636) Data: 0.117s | Batch: 0.668s | Total: 0:01:06 | ETA: 0:04:56 | Loss: 0.2740 | top1:  88.1028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|█████████████████████████▏                                                      | 200/636 [02:01<04:00,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200/636) Data: 0.060s | Batch: 0.608s | Total: 0:02:01 | ETA: 0:04:00 | Loss: 0.2728 | top1:  88.1326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|█████████████████████████████████████▋                                          | 300/636 [02:56<03:04,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300/636) Data: 0.040s | Batch: 0.588s | Total: 0:02:56 | ETA: 0:03:05 | Loss: 0.2726 | top1:  88.1390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████████████████████████████████████████████████▎                             | 400/636 [03:51<02:09,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400/636) Data: 0.031s | Batch: 0.578s | Total: 0:03:51 | ETA: 0:02:11 | Loss: 0.2726 | top1:  88.1455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|██████████████████████████████████████████████████████████████▉                 | 500/636 [04:45<01:14,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500/636) Data: 0.025s | Batch: 0.572s | Total: 0:04:45 | ETA: 0:01:16 | Loss: 0.2722 | top1:  88.1578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|███████████████████████████████████████████████████████████████████████████▍    | 600/636 [05:40<00:19,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600/636) Data: 0.021s | Batch: 0.567s | Total: 0:05:40 | ETA: 0:00:21 | Loss: 0.2722 | top1:  88.1625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 636/636 [06:01<00:00,  1.76it/s]\n",
      " 65%|███████████████████████████████████████████████████▊                            | 101/156 [00:19<00:05,  9.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100/156) Data: 0.080s | Batch: 0.189s | Total: 0:00:18 | ETA: 0:00:07 | Loss: 0.9216 | top1:  83.0742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 156/156 [00:25<00:00,  6.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving checkpoint 'checkpoints\\checkpoint.pth.tar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/636 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [6 | 50] LR: 0.1000000000000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████████▌                                                                   | 100/636 [01:07<04:55,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100/636) Data: 0.124s | Batch: 0.671s | Total: 0:01:07 | ETA: 0:04:54 | Loss: 0.2724 | top1:  88.1691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|█████████████████████████▏                                                      | 200/636 [02:01<03:59,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200/636) Data: 0.063s | Batch: 0.608s | Total: 0:02:01 | ETA: 0:03:59 | Loss: 0.2721 | top1:  88.1569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|█████████████████████████████████████▋                                          | 300/636 [02:56<03:03,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300/636) Data: 0.043s | Batch: 0.587s | Total: 0:02:56 | ETA: 0:03:05 | Loss: 0.2718 | top1:  88.1653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████████████████████████████████████████████████▎                             | 400/636 [03:50<02:08,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400/636) Data: 0.032s | Batch: 0.577s | Total: 0:03:50 | ETA: 0:02:10 | Loss: 0.2715 | top1:  88.1771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|██████████████████████████████████████████████████████████████▉                 | 500/636 [04:45<01:14,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500/636) Data: 0.026s | Batch: 0.571s | Total: 0:04:45 | ETA: 0:01:16 | Loss: 0.2713 | top1:  88.1926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|███████████████████████████████████████████████████████████████████████████▍    | 600/636 [05:40<00:19,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600/636) Data: 0.022s | Batch: 0.567s | Total: 0:05:40 | ETA: 0:00:21 | Loss: 0.2711 | top1:  88.2001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 636/636 [06:00<00:00,  1.76it/s]\n",
      " 65%|███████████████████████████████████████████████████▊                            | 101/156 [00:18<00:05,  9.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100/156) Data: 0.082s | Batch: 0.188s | Total: 0:00:18 | ETA: 0:00:06 | Loss: 0.7442 | top1:  78.4480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 156/156 [00:24<00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving checkpoint 'checkpoints\\checkpoint.pth.tar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/636 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [7 | 50] LR: 0.1000000000000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████████▌                                                                   | 100/636 [01:06<05:19,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100/636) Data: 0.117s | Batch: 0.667s | Total: 0:01:06 | ETA: 0:05:06 | Loss: 0.2720 | top1:  88.1715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|█████████████████████████▏                                                      | 200/636 [02:02<04:00,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200/636) Data: 0.059s | Batch: 0.610s | Total: 0:02:02 | ETA: 0:04:02 | Loss: 0.2708 | top1:  88.2477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|█████████████████████████████████████▋                                          | 300/636 [02:56<03:04,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300/636) Data: 0.040s | Batch: 0.589s | Total: 0:02:56 | ETA: 0:03:04 | Loss: 0.2709 | top1:  88.2430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████████████████████████████████████████████████▎                             | 400/636 [03:51<02:08,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400/636) Data: 0.030s | Batch: 0.578s | Total: 0:03:51 | ETA: 0:02:10 | Loss: 0.2713 | top1:  88.2210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|██████████████████████████████████████████████████████████████▉                 | 500/636 [04:45<01:13,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500/636) Data: 0.025s | Batch: 0.572s | Total: 0:04:45 | ETA: 0:01:15 | Loss: 0.2713 | top1:  88.2188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|███████████████████████████████████████████████████████████████████████████▍    | 600/636 [05:40<00:19,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600/636) Data: 0.021s | Batch: 0.568s | Total: 0:05:40 | ETA: 0:00:21 | Loss: 0.2712 | top1:  88.2273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 636/636 [06:01<00:00,  1.76it/s]\n",
      " 65%|███████████████████████████████████████████████████▊                            | 101/156 [00:18<00:05,  9.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100/156) Data: 0.082s | Batch: 0.189s | Total: 0:00:18 | ETA: 0:00:07 | Loss: 0.5849 | top1:  82.2865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 156/156 [00:25<00:00,  6.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving checkpoint 'checkpoints\\checkpoint.pth.tar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/636 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [8 | 50] LR: 0.1000000000000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████████▌                                                                   | 100/636 [01:06<04:52,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100/636) Data: 0.119s | Batch: 0.664s | Total: 0:01:06 | ETA: 0:04:53 | Loss: 0.2723 | top1:  88.1742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|█████████████████████████▏                                                      | 200/636 [02:01<03:56,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200/636) Data: 0.060s | Batch: 0.605s | Total: 0:02:01 | ETA: 0:03:58 | Loss: 0.2716 | top1:  88.2133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|█████████████████████████████████████▋                                          | 300/636 [02:55<03:04,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300/636) Data: 0.041s | Batch: 0.585s | Total: 0:02:55 | ETA: 0:03:05 | Loss: 0.2717 | top1:  88.2161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████████████████████████████████████████████████▎                             | 400/636 [03:50<02:09,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400/636) Data: 0.031s | Batch: 0.576s | Total: 0:03:50 | ETA: 0:02:10 | Loss: 0.2718 | top1:  88.2040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|██████████████████████████████████████████████████████████████▉                 | 500/636 [04:44<01:15,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500/636) Data: 0.025s | Batch: 0.570s | Total: 0:04:44 | ETA: 0:01:15 | Loss: 0.2719 | top1:  88.2003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|███████████████████████████████████████████████████████████████████████████▍    | 600/636 [05:39<00:19,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600/636) Data: 0.021s | Batch: 0.566s | Total: 0:05:39 | ETA: 0:00:21 | Loss: 0.2721 | top1:  88.1916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 636/636 [06:00<00:00,  1.77it/s]\n",
      " 65%|███████████████████████████████████████████████████▊                            | 101/156 [00:18<00:05,  9.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100/156) Data: 0.080s | Batch: 0.187s | Total: 0:00:18 | ETA: 0:00:06 | Loss: 2.8550 | top1:  81.2352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 156/156 [00:24<00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving checkpoint 'checkpoints\\checkpoint.pth.tar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/636 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [9 | 50] LR: 0.1000000000000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████████▌                                                                   | 100/636 [01:06<04:50,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100/636) Data: 0.117s | Batch: 0.661s | Total: 0:01:06 | ETA: 0:04:53 | Loss: 0.2713 | top1:  88.2132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|█████████████████████████▏                                                      | 200/636 [02:00<03:56,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200/636) Data: 0.060s | Batch: 0.603s | Total: 0:02:00 | ETA: 0:03:58 | Loss: 0.2719 | top1:  88.2229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|█████████████████████████████████████▋                                          | 300/636 [02:55<03:04,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300/636) Data: 0.040s | Batch: 0.584s | Total: 0:02:55 | ETA: 0:03:05 | Loss: 0.2717 | top1:  88.2222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████████████████████████████████████████████████▎                             | 400/636 [03:49<02:09,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400/636) Data: 0.031s | Batch: 0.574s | Total: 0:03:49 | ETA: 0:02:09 | Loss: 0.2717 | top1:  88.2201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|██████████████████████████████████████████████████████████████▉                 | 500/636 [04:44<01:13,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500/636) Data: 0.025s | Batch: 0.568s | Total: 0:04:44 | ETA: 0:01:15 | Loss: 0.2720 | top1:  88.1995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|███████████████████████████████████████████████████████████████████████████▍    | 600/636 [05:38<00:19,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600/636) Data: 0.021s | Batch: 0.564s | Total: 0:05:38 | ETA: 0:00:21 | Loss: 0.2719 | top1:  88.2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 636/636 [05:59<00:00,  1.77it/s]\n",
      " 65%|███████████████████████████████████████████████████▊                            | 101/156 [00:18<00:05,  9.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100/156) Data: 0.080s | Batch: 0.188s | Total: 0:00:18 | ETA: 0:00:06 | Loss: 0.7266 | top1:  82.4016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 156/156 [00:25<00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving checkpoint 'checkpoints\\checkpoint.pth.tar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/636 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [10 | 50] LR: 0.1000000000000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████████▌                                                                   | 100/636 [01:06<04:52,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100/636) Data: 0.122s | Batch: 0.665s | Total: 0:01:06 | ETA: 0:04:53 | Loss: 0.2698 | top1:  88.2938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|█████████████████████████▏                                                      | 200/636 [02:00<03:58,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200/636) Data: 0.062s | Batch: 0.604s | Total: 0:02:00 | ETA: 0:04:00 | Loss: 0.2716 | top1:  88.2021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|█████████████████████████████████████▋                                          | 300/636 [02:55<03:03,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300/636) Data: 0.042s | Batch: 0.585s | Total: 0:02:55 | ETA: 0:03:04 | Loss: 0.2718 | top1:  88.1982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████████████████████████████████████████████████▎                             | 400/636 [03:50<02:07,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400/636) Data: 0.032s | Batch: 0.575s | Total: 0:03:50 | ETA: 0:02:10 | Loss: 0.2717 | top1:  88.2085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|██████████████████████████████████████████████████████████████▉                 | 500/636 [04:44<01:13,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500/636) Data: 0.026s | Batch: 0.569s | Total: 0:04:44 | ETA: 0:01:15 | Loss: 0.2716 | top1:  88.2101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|███████████████████████████████████████████████████████████████████████████▍    | 600/636 [05:39<00:19,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600/636) Data: 0.022s | Batch: 0.565s | Total: 0:05:39 | ETA: 0:00:21 | Loss: 0.2715 | top1:  88.2241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 636/636 [05:59<00:00,  1.77it/s]\n",
      " 64%|███████████████████████████████████████████████████▎                            | 100/156 [00:18<00:06,  8.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100/156) Data: 0.079s | Batch: 0.187s | Total: 0:00:18 | ETA: 0:00:07 | Loss: 0.6051 | top1:  81.3541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 156/156 [00:24<00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving checkpoint 'checkpoints\\checkpoint.pth.tar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/636 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [11 | 50] LR: 0.1000000000000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████████▌                                                                   | 100/636 [01:06<04:51,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100/636) Data: 0.118s | Batch: 0.666s | Total: 0:01:06 | ETA: 0:04:52 | Loss: 0.2709 | top1:  88.2080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|█████████████████████████▏                                                      | 200/636 [02:01<03:58,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200/636) Data: 0.060s | Batch: 0.605s | Total: 0:02:01 | ETA: 0:03:59 | Loss: 0.2703 | top1:  88.2635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|█████████████████████████████████████▋                                          | 300/636 [02:55<03:02,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300/636) Data: 0.040s | Batch: 0.585s | Total: 0:02:55 | ETA: 0:03:05 | Loss: 0.2705 | top1:  88.2636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████████████████████████████████████████████████▎                             | 400/636 [03:50<02:08,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400/636) Data: 0.031s | Batch: 0.575s | Total: 0:03:50 | ETA: 0:02:09 | Loss: 0.2708 | top1:  88.2489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|██████████████████████████████████████████████████████████████▉                 | 500/636 [04:44<01:14,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500/636) Data: 0.025s | Batch: 0.569s | Total: 0:04:44 | ETA: 0:01:15 | Loss: 0.2708 | top1:  88.2430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|███████████████████████████████████████████████████████████████████████████▍    | 600/636 [05:39<00:19,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600/636) Data: 0.021s | Batch: 0.565s | Total: 0:05:39 | ETA: 0:00:21 | Loss: 0.2708 | top1:  88.2401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 636/636 [05:59<00:00,  1.77it/s]\n",
      " 65%|███████████████████████████████████████████████████▊                            | 101/156 [00:18<00:05,  9.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100/156) Data: 0.081s | Batch: 0.189s | Total: 0:00:18 | ETA: 0:00:07 | Loss: 1.6716 | top1:  73.7031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 156/156 [00:25<00:00,  6.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving checkpoint 'checkpoints\\checkpoint.pth.tar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/636 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [12 | 50] LR: 0.1000000000000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████████▌                                                                   | 100/636 [01:06<04:51,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100/636) Data: 0.119s | Batch: 0.664s | Total: 0:01:06 | ETA: 0:04:52 | Loss: 0.2708 | top1:  88.2219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|█████████████████████████▏                                                      | 200/636 [02:00<03:57,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200/636) Data: 0.060s | Batch: 0.604s | Total: 0:02:00 | ETA: 0:03:59 | Loss: 0.2713 | top1:  88.1963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|█████████████████████████████████████▋                                          | 300/636 [02:55<03:03,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300/636) Data: 0.041s | Batch: 0.584s | Total: 0:02:55 | ETA: 0:03:03 | Loss: 0.2711 | top1:  88.2082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████████████████████████████████████████████████▎                             | 400/636 [03:49<02:09,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400/636) Data: 0.031s | Batch: 0.574s | Total: 0:03:49 | ETA: 0:02:10 | Loss: 0.2707 | top1:  88.2315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|██████████████████████████████████████████████████████████████▉                 | 500/636 [04:44<01:14,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500/636) Data: 0.025s | Batch: 0.568s | Total: 0:04:44 | ETA: 0:01:15 | Loss: 0.2710 | top1:  88.2193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|███████████████████████████████████████████████████████████████████████████▍    | 600/636 [05:38<00:19,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600/636) Data: 0.021s | Batch: 0.564s | Total: 0:05:38 | ETA: 0:00:21 | Loss: 0.2711 | top1:  88.2164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 636/636 [05:59<00:00,  1.77it/s]\n",
      " 65%|███████████████████████████████████████████████████▊                            | 101/156 [00:19<00:05,  9.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100/156) Data: 0.084s | Batch: 0.190s | Total: 0:00:18 | ETA: 0:00:07 | Loss: 1.1450 | top1:  78.7393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 156/156 [00:25<00:00,  6.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving checkpoint 'checkpoints\\checkpoint.pth.tar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/636 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [13 | 50] LR: 0.1000000000000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████████▌                                                                   | 100/636 [01:06<04:52,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100/636) Data: 0.117s | Batch: 0.663s | Total: 0:01:06 | ETA: 0:04:54 | Loss: 0.2710 | top1:  88.2242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|█████████████████████████▏                                                      | 200/636 [02:00<03:58,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200/636) Data: 0.059s | Batch: 0.604s | Total: 0:02:00 | ETA: 0:03:59 | Loss: 0.2704 | top1:  88.2528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|█████████████████████████████████████▋                                          | 300/636 [02:55<03:02,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300/636) Data: 0.040s | Batch: 0.585s | Total: 0:02:55 | ETA: 0:03:04 | Loss: 0.2713 | top1:  88.2217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████████████████████████████████████████████████▎                             | 400/636 [03:50<02:08,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400/636) Data: 0.030s | Batch: 0.575s | Total: 0:03:50 | ETA: 0:02:10 | Loss: 0.2714 | top1:  88.2236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|██████████████████████████████████████████████████████████████▉                 | 500/636 [04:44<01:14,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500/636) Data: 0.025s | Batch: 0.570s | Total: 0:04:44 | ETA: 0:01:15 | Loss: 0.2715 | top1:  88.2224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|███████████████████████████████████████████████████████████████████████████▍    | 600/636 [05:39<00:19,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600/636) Data: 0.021s | Batch: 0.566s | Total: 0:05:39 | ETA: 0:00:21 | Loss: 0.2719 | top1:  88.2049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 636/636 [05:59<00:00,  1.77it/s]\n",
      " 65%|███████████████████████████████████████████████████▊                            | 101/156 [00:19<00:06,  8.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100/156) Data: 0.081s | Batch: 0.191s | Total: 0:00:19 | ETA: 0:00:07 | Loss: 0.9200 | top1:  77.4381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 156/156 [00:25<00:00,  6.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving checkpoint 'checkpoints\\checkpoint.pth.tar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/636 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [14 | 50] LR: 0.1000000000000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████████▌                                                                   | 100/636 [01:06<04:54,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100/636) Data: 0.120s | Batch: 0.668s | Total: 0:01:06 | ETA: 0:04:54 | Loss: 0.2725 | top1:  88.1577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|█████████████████████████▏                                                      | 200/636 [02:01<04:00,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200/636) Data: 0.061s | Batch: 0.609s | Total: 0:02:01 | ETA: 0:04:00 | Loss: 0.2717 | top1:  88.1947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|█████████████████████████████████████▋                                          | 300/636 [02:58<03:11,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300/636) Data: 0.041s | Batch: 0.596s | Total: 0:02:58 | ETA: 0:03:08 | Loss: 0.2716 | top1:  88.2067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████████████████████████████████████████████▋                                  | 363/636 [03:33<02:30,  1.82it/s]"
     ]
    }
   ],
   "source": [
    "# config.epoch = 1\n",
    "start_time = time.time()\n",
    "model = create_model(device)\n",
    "dataloaders, attribute_names  = load_dataloaders()\n",
    "criterion = get_criterion()\n",
    "optimizer = get_optimizer(model)\n",
    "\n",
    "if config.evaluate:\n",
    "    best_prec1, _, _ = resume_checkpoint(model, optimizer, config.ckp_logger_fname, config.checkpoint_fname) # checkpoint_fname bestmodel_fname\n",
    "    test_loss, prec1, top1 = validate(dataloaders['test'], model, criterion)\n",
    "    print(f\"=> Best test accuracy: {prec1}, Model val acc: {best_prec1}\")\n",
    "    print_attribute_acc(top1, attribute_names)\n",
    "else:\n",
    "    best_prec1, start_epoch, logger = resume_checkpoint(model, optimizer, config.ckp_logger_fname, config.ckp_resume)\n",
    "    run_name, run_time = get_run_name_time(model, criterion, optimizer, comments)\n",
    "    trainer(dataloaders, model, criterion, optimizer, logger, start_epoch, best_prec1, run_name)\n",
    "end_time = time.time()\n",
    "time_taken = time.strftime(\"%H:%M:%S\", time.gmtime(end_time - start_time))\n",
    "print(f\"total time taken: {time_taken}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not config.evaluate:\n",
    "    config.evaluate = True\n",
    "    model = create_model(device)\n",
    "    dataloaders, attribute_names = load_dataloaders()\n",
    "    criterion = get_criterion()\n",
    "    optimizer = get_optimizer(model)\n",
    "\n",
    "    best_prec1, _, _ = resume_checkpoint(model, optimizer, config.ckp_logger_fname, config.bestmodel_fname)# config.bestmodel_fname  config.checkpoint_fname\n",
    "    print(model)\n",
    "    test_loss, prec1, top1 = validate(dataloaders['test'], model, criterion)\n",
    "    print(f\"=> Best test accuracy: {prec1}, Model val acc: {best_prec1}\")\n",
    "    print_attribute_acc(top1, attribute_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save & Backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for notebook to save\n",
    "%autosave 1\n",
    "time.sleep(150)\n",
    "%autosave 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backup_everything(run_time, run_name, title):\n",
    "    # backup checkpoints\n",
    "    run_dir = os.path.join(config.BACKUP_DIR, run_name, run_time)\n",
    "    create_dir_ifne(run_dir)\n",
    "    fromDirectory = config.CHECKPOINT_DIR\n",
    "    toDirectory = run_dir\n",
    "    copy_tree(fromDirectory, toDirectory)\n",
    "    # backup notebook html\n",
    "    nb_name = title + '.ipynb'\n",
    "    html_name = title + '.html'\n",
    "    save_name = os.path.join(run_dir, html_name)\n",
    "    !jupyter nbconvert --to html $nb_name\n",
    "    !move $html_name $save_name\n",
    "    \n",
    "backup_everything(run_time, run_name, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.auto_hibernate and False:\n",
    "    os.system('shutdown -h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOYWQroywTLOsSvW/4lPmBg",
   "collapsed_sections": [],
   "name": "ai6126-project1-colab-v0.1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
