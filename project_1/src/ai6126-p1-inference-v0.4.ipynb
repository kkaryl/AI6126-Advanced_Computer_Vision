{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI6126 ACV P1 - Inference Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_ver = 0.3\n",
    "title = f'ai6126-p1-inference-v{nb_ver}'\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Versioning and References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changelogs\n",
    "+ V0.1 - Added inference codes\n",
    "+ V0.2 - Added analysis\n",
    "+ V0.3 - Added prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "+ None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Inference Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import shutil\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import copy\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "\n",
    "from tqdm import tqdm\n",
    "import config\n",
    "from celeba_dataset import CelebaDataset, CelebaTestset\n",
    "import models\n",
    "from utils import Logger, ModelTimer, AverageMeter, accuracy, print_attribute_acc\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "# set the backend of matplotlib to the 'inline' backend\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check PyTorch version and cuda status\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "\n",
    "# define device\n",
    "device = torch.device(\"cuda:\"+config.gpu_id if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\") # force cpu\n",
    "print(device)\n",
    "\n",
    "ISJUPYTER = False\n",
    "if 'ipykernel' in sys.modules:\n",
    "    ISJUPYTER = True\n",
    "    # set the backend of matplotlib to the 'inline' backend\n",
    "    %matplotlib inline\n",
    "    config.disable_tqdm = False\n",
    "    \n",
    "print(f\"disable_tqdm: {config.disable_tqdm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.TESTSET_DIR = '../data/testset2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed for reproducibility\n",
    "def seed_everything(seed=None):\n",
    "    if seed is None:\n",
    "        seed = random.randint(1, 10000) # create random seed\n",
    "        print(f'random seed used: {seed}')\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    if 'torch' in sys.modules:\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "seed_everything(seed=config.manual_seed)#config.manual_seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_H = 198 #158 218 148 198\n",
    "IMAGE_W = 158 #178 148 158"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation and testing\n",
    "def load_dataloaders(print_info=True, albu_transforms = True, img_h=218, img_w=158):\n",
    "    phases = ['val', 'test'] #'train'\n",
    "\n",
    "    attribute_names = ['5_o_Clock_Shadow', 'Arched_Eyebrows', 'Attractive', 'Bags_Under_Eyes', 'Bald', \n",
    "                       'Bangs', 'Big_Lips', 'Big_Nose', 'Black_Hair', 'Blond_Hair', 'Blurry', 'Brown_Hair', \n",
    "                       'Bushy_Eyebrows', 'Chubby', 'Double_Chin', 'Eyeglasses', 'Goatee', 'Gray_Hair',\n",
    "                       'Heavy_Makeup', 'High_Cheekbones', 'Male', 'Mouth_Slightly_Open', 'Mustache', \n",
    "                       'Narrow_Eyes', 'No_Beard', 'Oval_Face', 'Pale_Skin', 'Pointy_Nose', 'Receding_Hairline',\n",
    "                       'Rosy_Cheeks', 'Sideburns', 'Smiling', 'Straight_Hair', 'Wavy_Hair', 'Wearing_Earrings', \n",
    "                       'Wearing_Hat', 'Wearing_Lipstick', 'Wearing_Necklace', 'Wearing_Necktie', 'Young']\n",
    "    \n",
    "    attributes_list = {\n",
    "        'train': config.TRAIN_ATTRIBUTE_LIST,\n",
    "        'val': config.VAL_ATTRIBUTE_LIST,\n",
    "        'test': config.TEST_ATTRIBUTE_LIST\n",
    "    }\n",
    "\n",
    "    batch_sizes = {\n",
    "        'train': config.train_batch,\n",
    "        'val': config.test_batch,\n",
    "        'test': config.test_batch\n",
    "    }\n",
    "\n",
    "    if not albu_transforms:\n",
    "        normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                                         std=[0.229, 0.224, 0.225])\n",
    "        data_transforms = {\n",
    "            'train': transforms.Compose([\n",
    "                transforms.CenterCrop((img_h, img_w)), #new\n",
    "                transforms.RandomHorizontalFlip(p=0.5),\n",
    "                #transforms.RandomRotation(degrees=10), #new\n",
    "                transforms.ToTensor(),\n",
    "                normalize,\n",
    "                #transforms.RandomErasing()\n",
    "            ]),\n",
    "            'val': transforms.Compose([\n",
    "                #transforms.Resize(178), #new\n",
    "                transforms.CenterCrop((img_h, img_w)),\n",
    "                transforms.ToTensor(),\n",
    "                normalize\n",
    "            ]),\n",
    "            'test': transforms.Compose([\n",
    "                #transforms.Resize(178), #new\n",
    "                transforms.CenterCrop((img_h, img_w)),\n",
    "                transforms.ToTensor(),\n",
    "                normalize\n",
    "            ])\n",
    "        }\n",
    "    else:\n",
    "        normalize_A = A.Normalize(mean=(0.485, 0.456, 0.406), \n",
    "                                  std=(0.229, 0.224, 0.225))\n",
    "        data_transforms = {\n",
    "            'train': A.Compose([\n",
    "                A.CenterCrop(height=img_h, width=img_w),\n",
    "                A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, \n",
    "                                 rotate_limit=15, p=0.5), # AFFACT https://arxiv.org/pdf/1611.06158.pdf\n",
    "                A.HorizontalFlip(p=0.5),\n",
    "                #A.HueSaturationValue(hue_shift_limit=14, sat_shift_limit=14, val_shift_limit=14, p=0.5),\n",
    "                #A.FancyPCA(alpha=0.1, p=0.5), #http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf\n",
    "                A.RandomBrightnessContrast(p=0.5),\n",
    "                A.GaussNoise(var_limit=10.0, p=0.5), \n",
    "                #A.GaussianBlur(p=0.1), # AFFACT https://arxiv.org/pdf/1611.06158.pdf\n",
    "                #A.CoarseDropout(max_holes=1, max_height=74, max_width=74, \n",
    "                #               min_height=49, min_width=49, fill_value=0, p=0.2), #https://arxiv.org/pdf/1708.04896.pdf\n",
    "                normalize_A,\n",
    "                ToTensorV2(),\n",
    "                \n",
    "            ]),\n",
    "            'val': A.Compose([\n",
    "                #Rescale an image so that minimum side is equal to max_size 178 (shortest edge of Celeba)\n",
    "                #A.SmallestMaxSize(max_size=178), \n",
    "                A.CenterCrop(height=img_h, width=img_w),\n",
    "                normalize_A,\n",
    "                ToTensorV2(),\n",
    "            ]),\n",
    "            'test': A.Compose([\n",
    "                #A.SmallestMaxSize(max_size=178),\n",
    "                A.CenterCrop(height=img_h, width=img_w),\n",
    "                normalize_A,\n",
    "                ToTensorV2(),\n",
    "            ])\n",
    "        }\n",
    "\n",
    "    image_datasets = {x: CelebaDataset(config.IMG_DIR, attributes_list[x], \n",
    "                                       data_transforms[x], albu=albu_transforms) \n",
    "                      for x in phases}\n",
    "    dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], \n",
    "                                                  batch_size=batch_sizes[x],\n",
    "                                                  pin_memory=True, shuffle=(x == 'train'), \n",
    "                                                  num_workers=config.dl_workers) \n",
    "                   for x in phases}\n",
    "    if print_info:\n",
    "        dataset_sizes = {x: len(image_datasets[x]) for x in phases}\n",
    "        print(f\"Dataset sizes: {dataset_sizes}\")\n",
    "        \n",
    "    class_names = image_datasets['test'].targets\n",
    "    \n",
    "    print(f\"Class Labels: {len(class_names[0])}\")\n",
    "    assert len(attribute_names) == len(class_names[0])\n",
    "    return dataloaders, attribute_names\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders, attribute_names = load_dataloaders(albu_transforms = True, img_h=IMAGE_H, img_w=IMAGE_W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_testset(print_info=True, albu_transforms = False, img_h=218, img_w=158):    \n",
    "    attribute_names = ['5_o_Clock_Shadow', 'Arched_Eyebrows', 'Attractive', 'Bags_Under_Eyes', 'Bald', \n",
    "                   'Bangs', 'Big_Lips', 'Big_Nose', 'Black_Hair', 'Blond_Hair', 'Blurry', 'Brown_Hair', \n",
    "                   'Bushy_Eyebrows', 'Chubby', 'Double_Chin', 'Eyeglasses', 'Goatee', 'Gray_Hair',\n",
    "                   'Heavy_Makeup', 'High_Cheekbones', 'Male', 'Mouth_Slightly_Open', 'Mustache', \n",
    "                   'Narrow_Eyes', 'No_Beard', 'Oval_Face', 'Pale_Skin', 'Pointy_Nose', 'Receding_Hairline',\n",
    "                   'Rosy_Cheeks', 'Sideburns', 'Smiling', 'Straight_Hair', 'Wavy_Hair', 'Wearing_Earrings', \n",
    "                   'Wearing_Hat', 'Wearing_Lipstick', 'Wearing_Necklace', 'Wearing_Necktie', 'Young']\n",
    "    \n",
    "    if not albu_transforms:\n",
    "        normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                                         std=[0.229, 0.224, 0.225])\n",
    "        \n",
    "        test_transforms = transforms.Compose([\n",
    "            transforms.Resize((218, 218)), \n",
    "            transforms.CenterCrop((img_h, img_w)),\n",
    "            transforms.ToTensor(),\n",
    "            normalize\n",
    "        ])\n",
    "        \n",
    "    if albu_transforms:\n",
    "        normalize_A = A.Normalize(mean=(0.485, 0.456, 0.406), \n",
    "                              std=(0.229, 0.224, 0.225))\n",
    "        \n",
    "        test_transforms = A.Compose([\n",
    "            #A.SmallestMaxSize(max_size=178),\n",
    "            A.LongestMaxSize(max_size=250),\n",
    "            A.PadIfNeeded(min_height=218, min_width=218),\n",
    "            \n",
    "            A.CenterCrop(height=img_h, width=img_w),\n",
    "            normalize_A,\n",
    "            ToTensorV2(),\n",
    "        ]) \n",
    "        \n",
    "    test_dataset = CelebaTestset(config.TESTSET_DIR, transform=test_transforms)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=config.test_batch, \n",
    "                                             pin_memory=True, shuffle=False, num_workers=config.dl_workers)\n",
    "    if print_info:\n",
    "        print(f\"Testset size: {len(test_dataset)}\")\n",
    "        print(f\"Number of Celebs: {len(test_dataset.celeba_ctr.keys())}\")\n",
    "        \n",
    "    return test_dataset, test_loader, attribute_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset, test_loader, attribute_names = load_testset(albu_transforms = True, img_h=IMAGE_H, img_w=IMAGE_W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    real_batch = next(iter(test_loader))\n",
    "    plt.figure(figsize=(12,12))\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Private Testset Images\")\n",
    "    plt.imshow(np.transpose(torchvision.utils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(arch, layers, device):\n",
    "    print(\"=> creating model '{}'\".format(arch))\n",
    "    if arch.startswith('FaceAttrResNet'):\n",
    "        model = models.__dict__[arch](resnet_layers = layers)\n",
    "    elif arch.startswith('FaceAttrResNeXt'):\n",
    "        model = models.__dict__[arch](resnet_layers = layers)\n",
    "    elif arch.startswith('FaceAttrMobileNetV2'):\n",
    "        model = models.__dict__[arch]()\n",
    "    model = model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_checkpoint(modelname, opt_name, bias_decay=False, ckp_resume=None):\n",
    "    best_prec1 = 0\n",
    "\n",
    "    if ckp_resume and os.path.isfile(ckp_resume): \n",
    "        print(f\"=> resuming model: {ckp_resume}\")\n",
    "        checkpoint = torch.load(ckp_resume)\n",
    "        print(checkpoint['arch'])\n",
    "        try:\n",
    "            total_time = checkpoint['total_time']\n",
    "        except:\n",
    "            total_time = 0\n",
    "        try:\n",
    "            lr = checkpoint['lr']\n",
    "        except:\n",
    "            lr = 0.1\n",
    "        is_best=False\n",
    "        state = {\n",
    "            'epoch': checkpoint['epoch'],\n",
    "            'arch': modelname,\n",
    "            'state_dict': checkpoint['state_dict'],\n",
    "            'best_prec1': checkpoint['best_prec1'],\n",
    "            'opt_name': opt_name,\n",
    "            'optimizer' : checkpoint['optimizer'],\n",
    "            'lr': lr,\n",
    "            'total_time': total_time,\n",
    "            'bias_decay': bias_decay\n",
    "        }\n",
    "        torch.save(state, ckp_resume)\n",
    "        \n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#format_checkpoint('FaceAttrResNeXt_50', 'SGD', False, ckp_resume=\"inf\\\\FaceAttrResNeXt50_42_s58e60_tb100_vb100_CE_SGD_next_step_lr0.1_wd0.0001_g0.1_sp30_M\\\\20201005_165042\\\\model_best.pth.tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_inference_model(device, ckp_resume):\n",
    "    if not (ckp_resume and os.path.isfile(ckp_resume)):\n",
    "        print(\"[W] Checkpoint not found for inference.\")\n",
    "        raise \n",
    "    \n",
    "    print(f\"=> loading checkpoint: {ckp_resume}\")\n",
    "    checkpoint = torch.load(ckp_resume)\n",
    "    try:\n",
    "        total_time = checkpoint['total_time']\n",
    "        model_timer = ModelTimer(total_time)\n",
    "        print(f\"=> model trained time: {model_timer}\")\n",
    "    except:\n",
    "        print(f\"=> old model\")\n",
    "    best_prec1 = checkpoint['best_prec1']\n",
    "    print(f\"=> model best val: {best_prec1}\")\n",
    "\n",
    "    print(f\"=> resuming model: {checkpoint['arch']}\")\n",
    "    model = create_model(checkpoint['arch'].split('_')[0], \n",
    "                         int(checkpoint['arch'].split('_')[1]), \n",
    "                         device)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "              \n",
    "    return best_prec1, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.INFERENCE_DIR = 'inf'\n",
    "lfile = 'model_best.pth.tar'\n",
    "inf_models = {}\n",
    "ctr = 0\n",
    "for dirt in os.listdir(config.INFERENCE_DIR):\n",
    "    dirpath = os.path.join(config.INFERENCE_DIR, dirt)\n",
    "    for run in os.listdir(dirpath):\n",
    "        runpath = os.path.join(dirpath, run)\n",
    "        if os.path.isdir(runpath): \n",
    "            for filename in os.listdir(runpath):\n",
    "                if filename == lfile:\n",
    "                    best_prec1, model = load_inference_model(device, os.path.join(runpath,lfile))\n",
    "                    del model\n",
    "                    inf_models[ctr] = (os.path.join(runpath,lfile), dirt, run, best_prec1)\n",
    "                    ctr += 1\n",
    "                \n",
    "print(f'==> {len(inf_models)} inference model(s) found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keydict = {mid: (name, acc) for mid, (_, name, _, acc) in inf_models.items()}\n",
    "pprint(f'{keydict}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_FILES = False\n",
    "selected_model = int(input(\"Enter model index: \"))\n",
    "p_run = inf_models[selected_model][2]\n",
    "p_model_name = inf_models[selected_model][1]\n",
    "run_dir = os.path.join(config.INFERENCE_DIR, p_model_name)\n",
    "p_model_acc, p_model = load_inference_model(device, inf_models[selected_model][0]) \n",
    "#print(f\"=> best model val: {p_model_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model):\n",
    "    top1 = [AverageMeter() for _ in range(40)]\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (X, y) in enumerate(tqdm(val_loader)):\n",
    "            # Overlapping transfer if pinned memory\n",
    "            X = X.to(device, non_blocking=True)\n",
    "            y = y.to(device, non_blocking=True)\n",
    "            \n",
    "            # compute output\n",
    "            output = model(X)\n",
    "            # measure accuracy\n",
    "            prec1 = []\n",
    "            for j in range(len(output)):\n",
    "                prec1.append(accuracy(output[j], y[:, j], topk=(1,)))\n",
    "                top1[j].update(prec1[j][0].item(), X.size(0))\n",
    "\n",
    "            top1_avg = [top1[k].avg for k in range(len(top1))]\n",
    "            prec1_avg = sum(top1_avg) / len(top1_avg)\n",
    "        \n",
    "    return (prec1_avg, top1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_prec1, val_top1 = validate(dataloaders['val'], p_model)\n",
    "print(f\"=> Best val accuracy: {val_prec1}\")\n",
    "v_attr_acc = print_attribute_acc(val_top1, attribute_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prec1, test_top1 = validate(dataloaders['test'], p_model)\n",
    "print(f\"=> Best test accuracy: {test_prec1}\")\n",
    "test_attr_acc = print_attribute_acc(test_top1, attribute_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE_FILES:\n",
    "    json_save_dir = os.path.join(run_dir, p_run)\n",
    "    vpfile = os.path.join(json_save_dir, \"val_preds.json\")\n",
    "    json.dump(v_attr_acc, open(vpfile,'w'))\n",
    "    tpfile = os.path.join(json_save_dir, \"test_preds.json\")\n",
    "    json.dump(test_attr_acc, open(tpfile,'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxk = 1\n",
    "preds = pd.DataFrame(index=test_dataset.imagenames, columns=attribute_names)\n",
    "preds.index.name = \"Images\"\n",
    "p_model.eval()\n",
    "\n",
    "for X, names in tqdm(test_loader, disable=False):\n",
    "    inputs = X.to(device, non_blocking=True)\n",
    "\n",
    "    top_k_preds = []\n",
    "    with torch.no_grad():\n",
    "        outputs = p_model(inputs) # 40, BS\n",
    "    \n",
    "        for attr_scores in outputs:\n",
    "            _, attr_preds = attr_scores.topk(maxk, 1, True, True)\n",
    "            top_k_preds.append(attr_preds.t())\n",
    "            \n",
    "    all_preds = torch.cat(top_k_preds, dim=0) \n",
    "\n",
    "    all_preds = all_preds.permute(1,0).cpu()\n",
    "    all_preds[all_preds == 0] = -1\n",
    "    for j in range(len(names)):\n",
    "        preds.loc[names[j], :] = all_preds[j]\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE_FILES:\n",
    "    pfile = os.path.join(run_dir, \"predictions.csv\")\n",
    "    preds.to_csv(pfile, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_df = pd.DataFrame(index = attribute_names)\n",
    "stat_df.loc[:,'Testset'] = (preds.iloc[:,:] == 1).mean(axis=0)*100\n",
    "stat_df = stat_df.sort_values('Testset', ascending=False)\n",
    "fig, ax = plt.subplots()\n",
    "stat_df.plot(title='CelebA Private Testset Prediction Frequency Distribution', \n",
    "             kind='bar', figsize=(20, 5), ax=ax, color='green')\n",
    "for p in ax.patches:\n",
    "    value = round(p.get_height(),2)\n",
    "    ax.annotate(str(value), xy=(p.get_x(), p.get_height()))\n",
    "plt.savefig('private_test.png',dpi=160, bbox_inches='tight')\n",
    "print(preds[(preds['Young']==1) & (preds['Gray_Hair']==1)].index)\n",
    "print(preds[(preds['Male']==-1) & (preds['Mustache']==1)].index)\n",
    "print(preds[(preds['Male']==-1) & (preds['Goatee']==1)].index)\n",
    "print(preds[(preds['Gray_Hair']==1) & (preds['Blond_Hair']==1)].index)\n",
    "print(preds[(preds['Male']==-1) & (preds['No_Beard']==-1)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(preds[(preds['Rosy_Cheeks']==1) & (preds['Rosy_Cheeks']==1)].index)\n",
    "print(len(preds[(preds['Rosy_Cheeks']==1) & (preds['Rosy_Cheeks']==1)].index))\n",
    "print(preds[(preds['Wearing_Necklace']==1) & (preds['Wearing_Necklace']==1)].index)\n",
    "print(len(preds[(preds['Wearing_Necklace']==1) & (preds['Wearing_Necklace']==1)].index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_normalize = transforms.Normalize(\n",
    "   mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225],\n",
    "   std=[1/0.229, 1/0.224, 1/0.225]\n",
    ")\n",
    "\n",
    "def get_celeb_prediction(preds, name, first_img=True):\n",
    "    celeb_preds = preds[preds.index.str.contains(name)]\n",
    "    celeb_first = celeb_preds.index[0]\n",
    "    celeb_stat = pd.DataFrame(index = attribute_names)\n",
    "    celeb_stat.loc[:,name] = (celeb_preds.iloc[:,:] == 1).mean(axis=0)*100\n",
    "    mycolor = 'skyblue' if celeb_stat.loc['Male',name] >= 50 else 'magenta'\n",
    "    celeb_stat = celeb_stat.sort_values(name, ascending=False)\n",
    "    ncols = 3 if first_img else 2\n",
    "    ax = plt.subplot2grid((1, ncols), (0, 0), colspan=2)\n",
    "    celeb_stat.plot(title=name+' Prediction Frequency Distribution', \n",
    "                 kind='bar', figsize=(20, 5), color=mycolor, ax=ax)\n",
    "    for p in ax.patches:\n",
    "        value = round(p.get_height(),2)\n",
    "        ax.annotate(str(value), xy=(p.get_x(), p.get_height()))\n",
    "    if first_img:\n",
    "        ax2 = plt.subplot2grid((1, ncols), (0, 2), colspan=1)\n",
    "        index = test_dataset.imagenames.index(celeb_first)    \n",
    "        s_img = inv_normalize(test_dataset[index][0]).permute(1, 2, 0)\n",
    "        ax2.imshow(s_img)\n",
    "        ax2.set_axis_off()\n",
    "        plt.title(celeb_first)\n",
    "        plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_celeb_prediction(preds, name = '1', first_img=True) # Male, Gray_Hair, Blonde, Necktie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_celeb_prediction(preds, name = '2', first_img=True)  # Male, Gray_Hair, Necktie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prediction_with_image(preds, index=None, off_neg=True):\n",
    "    if index == None:\n",
    "        index = np.random.randint(0, len(preds))\n",
    "        print(f\"=> random index: {index}\")\n",
    "    \n",
    "    if type(index) == int:\n",
    "        p_attrs = preds.iloc[index,:]\n",
    "        p_img = preds.index[index]\n",
    "    else:\n",
    "        p_attrs = preds.loc[index, :]\n",
    "        p_img = index\n",
    "        index = test_dataset.imagenames.index(index)   \n",
    "\n",
    "#     if off_neg:\n",
    "#         p_attrs[p_attrs == -1] = 0\n",
    "    p_attrs = p_attrs.sort_values(0, ascending=True)\n",
    "    fig, (ax, ax2) = plt.subplots(ncols=2)\n",
    "    my_color=np.where(p_attrs>=0, 'green', 'orange')\n",
    "    if off_neg:\n",
    "        p_attrs[p_attrs == 1].plot(kind='bar',ax=ax, figsize=(8, 5), color=my_color)\n",
    "    else:\n",
    "        p_attrs.plot(kind='barh',ax=ax, figsize=(12, 8), color=my_color)\n",
    "    \n",
    "    s_img = inv_normalize(test_dataset[index][0]).permute(1, 2, 0)\n",
    "    ax2.imshow(s_img)\n",
    "    ax2.set_axis_off()\n",
    "    plt.title(p_img)\n",
    "    plt.show()\n",
    "    \n",
    "plot_prediction_with_image(preds, 0)\n",
    "plot_prediction_with_image(preds, 1)\n",
    "# plot_prediction_with_image(preds, 2)\n",
    "plot_prediction_with_image(preds, 3)\n",
    "plot_prediction_with_image(preds, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prediction_with_image(preds, 'Jennifer_Capriati_0003.jpg') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prediction_with_image(preds, index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prediction_with_image(preds, index=-5) # Hard-to-predict female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prediction_with_image(preds, index=3) # Young, Smile, Blond, Male, Mouth open, No Beard, High Cheekbone, Wavy Hair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prediction_with_image(preds, index=201) # Young, Male, Mouth open, Nobeard, Black hair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ISJUPYTER:\n",
    "    # Wait for notebook to save\n",
    "    %autosave 1\n",
    "    time.sleep(121)\n",
    "    %autosave 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backup_everything(run_dir, title, backup_nb=ISJUPYTER):\n",
    "    if backup_nb:\n",
    "        print(f\"=> backing up notebook... \")\n",
    "        # backup notebook html\n",
    "        nb_name = title + '.ipynb'\n",
    "        html_name = title + '.html'\n",
    "        save_name = os.path.join(run_dir, html_name)\n",
    "        !jupyter nbconvert --to html $nb_name\n",
    "        shutil.move(html_name, save_name)\n",
    "    \n",
    "backup_everything(run_dir, title, backup_nb=ISJUPYTER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
